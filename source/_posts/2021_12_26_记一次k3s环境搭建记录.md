---
title: 记一次k3s环境搭建记录
abbrlink: 21_month_day_记一次k3s环境搭建记录
date: 2021-12-26 12:45:47
tags:
---

### 背景

生产环境中，我们很早在使用 k8s 作为基础设施了，后来，企业项目要做私有化部署，就把目光转向 `k3s` 了。
k3s 是一个轻量级的 k8s，几乎实现了所有 k8s 的特性，除了一些边缘的场景，基本可以把 k3s 当做 k8s 去使用。

### 一些备选方案

早期部署 k8s 环境是十分繁杂的，各个组件都是二进制方式部署，如果遇到问题，排查起来需要的预备知识非常多，因此，大部分企业在使用 k8s 时，都是直接选择云服务商提供的 k8s 集群，阿里云、腾讯云、亚马逊等等都提供了非常完善的 k8s 集群。
那作为个人想要玩一玩 k8s ，我们可以怎么搞呢？ 其实社区已经出了非常多的用于简化 k8s 环境搭建的项目，下面列举一些：
1. 使用 ansible 等工具简化搭建，例如 [kubespray](https://github.com/kubernetes-sigs/kubespray)、[kubeasz](https://github.com/easzlab/kubeasz)、[Kops](https://github.com/kubernetes/kops)、[kubeadm](https://github.com/kubernetes/kubeadm)
3. [minikube](https://github.com/kubernetes/minikube)、[kind](https://github.com/kubernetes-sigs/kind)、[microk8s](https://github.com/ubuntu/microk8s)、[k3s](https://github.com/k3s-io/k3s) 等轻量级 k8s 实现。
4. [rancher](https://github.com/ubuntu/microk8s)、[kubeoperator](https://github.com/KubeOperator/KubeOperator) 这类可视化操作方式
5. 如果你只是想在自己电脑上玩一下，可以直接使用 docker 客户端提供的 k8s 集群，或者用 [k3d](https://github.com/rancher/k3d) (k3s in docker) 、[minikube](https://github.com/kubernetes/minikube)、[kind](https://github.com/kubernetes-sigs/kind)

值得一提的是， k3s 和 microk8s 是为生成环境设计的 k8s 实现，是为了在资源有限的情况下使用 k8s 集群的一种方案，例如 边缘计算、iot 等场景。(可以搜索和 kubeedge 等结合的内容)


### 搭建操作

因为更加看好 k3s 的生态，因此选用 k3s 作为基础设施。在 k3s 的搭建上，使用官方的搭建脚本已经比较简单了，不过还是有一些为了更加简化搭建过程而出现的项目，例如 [k3sup](https://github.com/alexellis/k3sup) 、 [autok3s](https://github.com/cnrancher/autok3s) 这两者都提供了远程安装 k3s 的能力，不过后者还有图形化界面。 从搭建难度上，这两者对我而言没啥差别，因此我直接选择了 k3sup。

1. 在本地下载 k3sup 

```shell
curl -sLS https://get.k3sup.dev | sh
```

2. 在阿里云上开两台机器，并配置公钥
```shell
ssh-copy-id root@xxx.xx.xx.xx
```

3. 在机器 1 上部署 master 节点
```shell
k3sup install --user root --ip xx.xx.xx.xx --k3s-version v1.19.7+k3s1  --no-extras --tls-san "xx.xx.xx.xx" --context k3s --merge
```

4. 在机器 2 上部署 slave 节点
```shell
k3sup join --user root --ip xx.xx.xx.xx --k3s-version v1.19.7+k3s1 --server-ip xx.xx.xx.xx
```

5. 查看结果
```shell
[root@longk3s001 ~]# kubectl  get node
NAME         STATUS   ROLES    AGE    VERSION
longk3s001   Ready    master   129m   v1.19.7+k3s1
longk3s002   Ready    <none>   112m   v1.19.7+k3s1
```

以上，基本的 k3s 环境就搭建完成成功了

### 解决远程访问问题

在集群外访问集群内的通用方案，基本可以分为： 

1. loadBalancer
2. nodePort
3. ingress
4. hostNetwork

一般来说，云厂商提供的 k8s 集群，都是采用 loadBalancer 的方式，云厂商会自动提供公网 ip (当然也可以是内网 ip)。 而对于自建的 k8s 集群，则没有现成的 lb，要么使用其他方式，要么，自建 lb。

1. 自建 lb 可以采用 [metalLB](https://github.com/metallb/metallb)
2. 使用 nodePort 是一个比较简便的方式，直接改 service 类型即可。但问题是要记各个服务的 nodePort 是多少，比较麻烦，服务多了之后，根本不记得哪个 port 对应哪个服务。
3. 使用 ingress 是一个很不错的方式，相当于在所有服务前加了一个反向代理服务器，比如 nginx。ingress 的使用能比较好地解决端口复用问题，可以根据 二级域名、访问路径、header 等各种标识对流量进行分发，基本上可以认为，对于企业级项目，用 ingress 就对了。不过，ingress 的相关配置是一个需要学习的内容，尤其是关于 ssl 证书，之后专门出一篇文章记录一下。
4. 使用 hostNetwork 相当于直接使用宿主机的网络，也就是说，一个服务若开了 8080 端口，则会直接在宿主机上监听 8080 端口。一般来说，hostNetwork 适用于一个集群仅服务于一个主服务的项目。但有一种很好的方式，可以解决 没有 lb 的问题，那就是 使用 ingress 作为流量分发，同时对 ingress 使用 hostNetwork，并且，对于 ingress 使用 daemonset 进行部署，这样就类似于将 ingress 作为 lb 来使用了。

我也直接采用 4 中的方案。相关的信息可以参考 [ingress-nginx](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.29.0/docs/deploy/baremetal.md)

记录一下基本过程：
1. 进入到 nginx-ingress 的[文档中](https://github.com/kubernetes/ingress-nginx/blob/nginx-0.29.0/docs/deploy/index.md)

2. 获取清单
```shell
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml
```

3. 修改 deployment 资源
```shell
# 1. 修改 Deployment 为 DaemonSet
# 2. spec.template.spec 增加  hostNetwork: true
```

4. 启用配置
```shell
kubectl apply -f mandatory.yaml
```

这之后就按照自己的需要，部署自己的服务即可。

TODO:
1. 增加 k8s 集群面板对比
2. 增加 k8s ssl相关配置操作记录
3. 增加 k8s 日志、监控、追踪、告警 相关操作记录
4. 增加对一个服务的相关操作
