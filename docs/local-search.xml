<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>简单耗用的加解密工具</title>
    <link href="/longblog/posts/undefined.html"/>
    <url>/longblog/posts/undefined.html</url>
    
    <content type="html"><![CDATA[<p>有时候，我们希望传输一个文件给他人，但这个文件涉及到一些隐私，不希望泄漏出去。但由于平常传输的工具都是各类大众 IM 工具，例如 钉钉、飞书、企业微信 等，这些工具都会将消息长期存储，加大了隐私泄漏的风险。 因此，我们希望对文件进行加密，传输完成后由对端同学进行解密打开。</p><p>几乎在所有的电脑上，都存在 openssl 这个工具，因此，我们可以简单地使用 <code>openssl</code> 进行加解密。 对于文件夹，可以直接使用 <code>zip</code> ，也可以使用 <code>tar</code> 。</p><h3 id="对文件进行加密"><a href="#对文件进行加密" class="headerlink" title="对文件进行加密"></a>对文件进行加密</h3><p><code>openssl enc -e -aes256 -in xxx1 -out xxx2</code></p><h3 id="对文件进行解密"><a href="#对文件进行解密" class="headerlink" title="对文件进行解密"></a>对文件进行解密</h3><p><code>openssl enc -d -aes256 -in xxx2 -out xxx1</code></p><h3 id="对文件夹进行加密-zip"><a href="#对文件夹进行加密-zip" class="headerlink" title="对文件夹进行加密(zip)"></a>对文件夹进行加密(zip)</h3><p><code>zip -re xxx.zip xxx</code><br><code>zip -rP password xxx.zip xxx</code></p><blockquote><p>注意，zip 的参数后跟的先是  目标文件名，再试带压缩文件名</p></blockquote><h3 id="对文件夹进行解密-zip"><a href="#对文件夹进行解密-zip" class="headerlink" title="对文件夹进行解密 (zip)"></a>对文件夹进行解密 (zip)</h3><p><code>unzip -P password xxx.zip</code><br><code>unzip xxx.zip</code></p><h3 id="对文件夹进行加密-tar"><a href="#对文件夹进行加密-tar" class="headerlink" title="对文件夹进行加密 (tar)"></a>对文件夹进行加密 (tar)</h3><p><code>tar -zcf - tt |openssl enc -e -k password &gt; xx.tar.gz</code></p><h3 id="对文件夹进行解密-tar"><a href="#对文件夹进行解密-tar" class="headerlink" title="对文件夹进行解密 (tar)"></a>对文件夹进行解密 (tar)</h3><p><code>dd if=xx.tar.gz |openssl enc -d -k password|tar -zxf -</code></p><p>如果把这几条命令进行简单封装，就是一个简单易用的加解密工具了</p><p>密码的问题在于双方是一样的，因此有些场景可以用公私钥进行加解密。</p><h3 id="创建一个私钥"><a href="#创建一个私钥" class="headerlink" title="创建一个私钥"></a>创建一个私钥</h3><p><code>openssl genrsa -out rsa.key 2048</code></p><h3 id="从私钥提取公钥"><a href="#从私钥提取公钥" class="headerlink" title="从私钥提取公钥"></a>从私钥提取公钥</h3><p><code>openssl rsa -in rsa.key -pubout -out pub.key</code></p><h3 id="用公钥加密"><a href="#用公钥加密" class="headerlink" title="用公钥加密"></a>用公钥加密</h3><p><code>openssl rsautl -encrypt -inkey pub.key -pubin -in xxx1 -out xxx2</code></p><h3 id="用私钥解密"><a href="#用私钥解密" class="headerlink" title="用私钥解密"></a>用私钥解密</h3><p><code>openssl rsautl -decrypt -inkey rsa.key -in xxx2 -out xxx3</code></p><h3 id="其他好玩的"><a href="#其他好玩的" class="headerlink" title="其他好玩的"></a>其他好玩的</h3><p>可以看一下这个项目 <a href="https://github.com/fbngrm/Matroschka">https://github.com/fbngrm/Matroschka</a><br>这是一个把一张图片藏在另一张图片中的工具，当然，不仅藏图片，你可以用这种方式藏任何东西。</p>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>shell</tag>
      
      <tag>openssl</tag>
      
      <tag>tar</tag>
      
      <tag>加解密</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何做好持续的自我教育</title>
    <link href="/longblog/posts/22_08_10_10_52_how_to_educate_ourselves_consistently.html"/>
    <url>/longblog/posts/22_08_10_10_52_how_to_educate_ourselves_consistently.html</url>
    
    <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>人之所以会有差别，一方面我们无法忽视出身环境带来的差异，另一方面，我们也无法忽视后天学习带来的改变。 站在个人的角度，我们无法决定我们的出身，就像打牌时我们无法决定手中的牌一样，在人生这场游戏中，开局就是这样。</p><p>每个人都希望有一个好的游戏结局，难道只有好的开局才能迎来好的结局吗？</p><p>玩过一些竞技游戏的同学都知道一个词，叫做 “逆风局”，指的就是如何有效利用各种资源，在开局不顺时，采取苟着求发展，待积累足够，再对外输出。</p><h2 id="如何玩好人生这场游戏"><a href="#如何玩好人生这场游戏" class="headerlink" title="如何玩好人生这场游戏"></a>如何玩好人生这场游戏</h2><p>人生也一样，持续发展 才是硬道理。</p><p>人生发展和一些游戏里的发展有些不同，游戏的发展大多就是 经验、资金、物资、装备 之类的，往往比较清晰而固定，而人生的发展，却需要自己去判断 去提升什么、去积累什么、去组合什么。</p><p>终身学习的过程，实际上就是持续 <code>自我教育</code> 的过程，<code>教育</code> 也就需要 <code>教育的目的和方向</code>，作为一名教师，教书育人的前提，是他知道 <code>什么是对的</code>、<code>什么是好的</code>、<code>什么是被受教育者需要的</code>。 那么，自我教育，也就需要知道  <code>有哪些领域的知识？``哪些领域的知识是重要的？``哪些领域的知识是被我所需要的？</code></p><p>要能很好地回答上面的问题，就要求这个人具备比较宽广的 视野，要具备多领域的基本认知，要有思考力去思考这些领域知识对于人的价值，要善于持续接触新知识。</p><p>既然，这已经是人生这场游戏中的关键操作，那么，就值得我们花费更多的时间和精力在这个课题上，去扩展我们的视野，去提升我们自我教育的能力，去找到我们该学习什么、该积累什么，去玩好这场名为 “人生” 的游戏。</p><h2 id="如何行动"><a href="#如何行动" class="headerlink" title="如何行动"></a>如何行动</h2><p>落实到目标，我们需要做这些事:</p><ul><li>去扩展知识领域认知，找到那些我们认为重要的知识领域</li><li>积累知识领域内容来源，持续阅读、思考、实践</li><li>思考 我们的人生竞争优势是什么？我们如何打造人生竞争优势？</li></ul><p>落实到具体行动，我们可以做这些事：</p><ul><li><input disabled="" type="checkbox"> 先通过自主思考，整理出我们认为的知识领域需要哪些？或者说要解决哪些问题？</li><li><input disabled="" type="checkbox"> 查阅教育学相关理论，认为教育需要提升哪些领域知识？</li><li><input disabled="" type="checkbox"> 查阅网络资料，收集各类认知提升的相关领域知识。</li></ul><p>为了保证行动的落地效率，需要有项目管理机制：</p><ol><li>将该主题列入到 生活 OKR 中</li><li>具体行动要做好 deadline 管理</li><li>每个具体的行动，都需要产出留档资料</li></ol><hr><blockquote><p>In wartime, truth is so precious that she should always be attended by a bodyguard of lies.<br>— <cite>Winston Churchill</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>持续学习</tag>
      
      <tag>持续成长</tag>
      
      <tag>自我教育</tag>
      
      <tag>教育</tag>
      
      <tag>人生选择</tag>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聊聊心力</title>
    <link href="/longblog/posts/22_08_08_16_20_thoughts_of_heart_strength.html"/>
    <url>/longblog/posts/22_08_08_16_20_thoughts_of_heart_strength.html</url>
    
    <content type="html"><![CDATA[<p>当我们后知后觉地找到了一个自认为 “有价值” 的目标后，就开始了漫长的征途，朝着目标前行。就像长跑一样，知道了自己是参加的 10km 跑后，就沿着跑道一步步前行。</p><p>当人有了目标之后，就会产生一系列的精神活动。</p><p>有一种精神活动，是通过想象自己已经达到了目标，产生一些快乐，可以认为是提前享受成功喜悦的快乐。这种快乐很有价值，能激励我们继续向着目标前行，但同样，也容易产生一种错觉，觉得自己很快就能达到目标。</p><p>另一种精神活动是，会经常去对标这个目标，看看自己距离目标还有多远。这种活动的价值，在于认清现状，找到真正该做的事。但也容易产生 心理落差，预期的前进速度和现实的前进速度的差距，就是落差，当一个人的期待越高，落差就会越大，认清现实后，摔下来也就越疼。</p><p>有时候，当我们遭受一些挫折，会有 无力、身心疲惫、累觉不爱 等等感受。我们会本能地选择逃避，只想躺在沙发上，随便刷刷手机；或躺在床上，闷头大睡；或玩游戏、或看肥皂剧；只要能不让自己去想那些烦心事儿，做什么都无所谓……</p><p>走向目标的路上有着种种 挫折，这些都会让我们产生 <code>挫败感</code>。 挫折 是每个人都在每个目标上，都一定会遇到的，但这些挫折会成为你成长道路上的 垫脚石 还是 绊脚石，对不同的人却是不同的，这取决于我们看待问题的 态度。</p><p>趋利避害，是人的天性。但天性很多时候只能解决 眼前的 问题，却无法解决长远的问题，持续的逃避，只能让我们止步不前，无法继续通往期待的彼岸。</p><p>有很多概念都在描述人在处理挫折时的能力，比如 <code>心力</code> 、<code>逆商</code>、<code>钝感力</code> 等等，基本都只有一些感性上的解释，不过不阻碍我们找到一些好的方法，让我们保持持续的活力。</p><p><a href="https://wiki.mbalib.com/wiki/%E9%92%9D%E6%84%9F%E5%8A%9B">钝感力</a>，大概是指 <code>迟钝的力量，能从容面对生活中的挫折和伤痛，坚定地朝着自己的方向前进</code>，是在面对困难时，还能厚着脸皮对抗外界的能力，是一种积极向上的人生态度。</p><p><a href="https://wiki.mbalib.com/wiki/%E9%80%86%E5%95%86">逆商</a>，通常和 智商、情商 并称为 3Q，是指人们在面对挫折、摆脱困境和超越困难的能力。</p><p>心力，我们大致可以用来表示自己当前的精神储备，心力会被消耗，也会被累积。我们可以通过 远离消耗心力的事 来避免心力被消耗殆尽，例如和一些负能量的人保持距离、避免一些没必要的争论、不开无效的会议、少看自己改变不了的社会负面信息 等等。也可以做一些增加心力的事，例如 向正能量的人靠近、和爱的人聊聊开心的事、做自己感兴趣的事、运动、沐浴清风 等等。</p><p>周末心力降到 0 ，没有心思写文章、学算法，甚至不想吃饭。于是我打开了 B 站， 看了下之前一直没看的 《从零开始的异世界生活》，看的过程不细聊了。</p><p>现在回想起来，486 就是一个 心力管理 的典型案例啊。他的心力来源于两个方面： 内在的善良 以及 外在的友人的鼓励。他持续地受到现实的各种打击，也痛苦过，也崩溃过，但在一次一次的痛苦后，又一次一次地爬起来，继续朝着目标前进。</p><p>当我去思考，我们更底层的能量究竟来自于哪里？我发现这和思考 “人生的意义是什么” 一样得不到答案。</p><p>不敢太深究，但在两个维度上，可以用这两个词来解释:  信念、习惯。</p><p>习惯，是日常生活中，保证个人状态的，例如 当你看到散乱的桌面，你是习惯与心烦意乱，还是顺手收拾，还是选择性无视？ 当你受到他人的质疑，你是开始自我怀疑，还是据理力争，还是无力力争，还是自我反思后总结优劣？</p><p>习惯是日常的，也是影响深远的，同时也是我们比较好改变的，改变的关键在于: 识别消耗心力的不良习惯。 </p><p>信念，包含浅层次的 观念，以及深层次的信念。众多的观念构成了一个人价值观的一部分，让他能对遇到的事形成自己的解释，当形成了体系性的解释时，就相当于有了信念。有些人的信念来自于他人，比如追随一个偶像；有些人的信念来自于更抽象的愿景，比如实现共产主义；也有些人的信念来源于一些更靠近每个人的，比如亲情、爱情等。</p><p>当我们看到 一个人很乐观，就不禁去想，他为什么那么乐观？比如前段时间火了的 二舅。当你去问一个乐观的人，你觉得自己不幸吗？你很可能会得到一些共同的回答，比如 我现在健健康康，家人也很和睦，虽然没有太多积蓄，但都在工作，都有收入，跟很多人相比，我已经是很幸运的了。</p><ul><li>佛说，人生有三大苦，怨憎会，爱别离，求不得。</li><li>佛还说，放下，便是拥有。</li><li>道德经中也说，知足者常乐。</li></ul><p>我们可以看到，乐还是苦，有时候是你对自己 所求的 和 所拥有的 之间的比较，当你所求降低，再多关注自己所拥有的，或许会感到更多的幸福。</p><p>有时候我也在想，人活这一生要追求什么？<br>之前看 《凡人》，看到师傅说：活得久了，就愈发觉得，这世上有些东西，比自己的性命还重要。又说：我所修的道，是念头通达。画面内是师傅为了自己所求的道慨然赴死，屏幕前是我内心激动不已，泪光闪动。</p><p>或许，长远来看，我们所追求的是内心的平静，为了守护这份平静，即使拼上一切，即使身死道消，也在所不惜。</p><p>追求内心的平静，并不是 避世 也不是 摆烂，因为内心总有一个声音，虽时强时弱，但你仔细聆听，就一定能听到，它在说着：去做吧，去做你热爱的事，不要害怕，不要胆怯！</p><p>有时候又在想，人活着，不总得拼一拼嘛？才不枉来这世上走了一遭。没拼过，有如何能在夜半十分安然入睡？没拼过，又如何能在垂暮之年笑谈人生？谋事在人，成事在天，不去试一试，谁能知道结果如何？追求自己所热爱的，投入自己的时间、精力、生命，又有何可惜？时间，不总得花在什么事情上吗？</p><p>回看前面几句话，我又有了新的认识。</p><ul><li>求不得，并非让我们 不再求，而是 求，得与不得，得之我幸，不得我命。</li><li>放下的，是执着于结果的心，拥有的，是内心的平静与享受过程的乐趣。</li><li>知足者，对我们不能掌控的事知足，对我们能掌控的事，永不知足！永不停歇！</li></ul><p>究竟要怎么把上面说的这些和当前的状态联系起来，还需要探索，或者说，这是一件需要持续探索的事。</p><hr><blockquote><p>You are the only person on earth who can use your ability.<br>— <cite>Zig Ziglar</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>心力</tag>
      
      <tag>价值观</tag>
      
      <tag>信念</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>kratos源码走读记录</title>
    <link href="/longblog/posts/22_07_29_11_19_codes_reading_of_go_kratos.html"/>
    <url>/longblog/posts/22_07_29_11_19_codes_reading_of_go_kratos.html</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/go-kratos/kratos">go-kratos</a> 是 B 站开源的微服务框架，是 golang 体系下几大微服务框架之一，有阅读源码的必要。</p><h3 id="api"><a href="#api" class="headerlink" title="api"></a>api</h3><p>?? metadata server</p><h3 id="cmd"><a href="#cmd" class="headerlink" title="cmd"></a>cmd</h3><p>命令行工具，三个部分：</p><ul><li>创建 proto、api 等的基础工具</li><li>基于 protoc 的 http server 代码生成 ( grpc 框架的 http 方案，可以对比一下其他方案 )</li><li>基于 protoc 的 errors 代码生成 ( 这个很有特色，详见 errors 包 )</li></ul><h3 id="config"><a href="#config" class="headerlink" title="config"></a>config</h3><p>配置管理<br>几个特点：</p><ul><li>全部基于接口设计</li><li>option 模式，可以修改  source、decoder、resolver 的具体实现</li><li>支持多个 source 及合并</li><li>resolver 支持模板处理</li><li>watch 机制，支持向上的变更监听</li><li>observe 机制，支持向下的变更通知</li></ul><p>一个想法： 基于接口的开发，很流畅</p><ul><li><input disabled="" type="checkbox"> 对比一下和 viper 、go-zero、goframe、go-kit 的配置方案</li></ul><h3 id="contrib"><a href="#contrib" class="headerlink" title="contrib"></a>contrib</h3><p>三方项目的支持<br>config:  apollo、consul、etcd、configmap、nacos、polaris<br>原来使用 volume 挂载的方式使用 configmap，需要 deployment  去申明这些东西，比较麻烦，实际上，直接在 k8s 中用 sdk 读 configmap 确实挺方便。</p><p>encoding: <a href="https://msgpack.org/index.html">msgpack</a> #序列化</p><p>metrics: datadog、promethues  (看看 metrics 还有其他什么方案吗)</p><p>opensergo: 一个ali、字节、bilibili 一起搞的服务治理框架，<a href="https://developer.aliyun.com/article/889635?utm_content=m_1000337652">参考文档</a></p><p>registry:  consul、 discovery、etcd、eureka、k8s、nacos、polaris、zk</p><h3 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h3><p>用于序列化和反序列化。<br>提供了 json、xml、yaml、proto、form 的方式。<br>json 和 proto 都用的 pb 的 marshal 和 unmarshal。<br>xml 用的标准库。<br>yaml 用的 <code>gopkg.in/yaml.v3</code><br>form 用的 <code>gggo-playground/form/v4</code> ，并且为 proto.Message 做了专门的适配。</p><h3 id="errors"><a href="#errors" class="headerlink" title="errors"></a>errors</h3><p>errors 的设计挺有意思，可以再参考下。<br>使用 proto 文件管理，自动生成代码。<br>有很多 error 体系都是自己的 封装，可以参考下 goframe 的 errors 、gopkg/errors 的设计。</p><h3 id="internal"><a href="#internal" class="headerlink" title="internal"></a>internal</h3><p>一些内部工具。</p><p>group 包下的 example_test.go 的使用比较有意思，可以参考 这种 test 的方式。</p><h3 id="log"><a href="#log" class="headerlink" title="log"></a>log</h3><p>log 的接口有两层，一层是 <code>log(level, kv...)</code> ，另一层是 <code>helper</code> ，日常使用 helper。<br>contrib 中实现了对 ali、fluent、zap、logrus 的对接。主要还是做输出的管理。</p><h3 id="metadata"><a href="#metadata" class="headerlink" title="metadata"></a>metadata</h3><p>简单的 metadata 封装，其实就是一个 <code>map[string]string</code></p><h3 id="metrics"><a href="#metrics" class="headerlink" title="metrics"></a>metrics</h3><p>简单的 metrics 接口定义。 具体实现在 contrib 包中。</p><h3 id="middleware"><a href="#middleware" class="headerlink" title="middleware"></a>middleware</h3><p>一些常用的 server 中间件。</p><h3 id="registry"><a href="#registry" class="headerlink" title="registry"></a>registry</h3><p>简单的注册中心接口定义，具体的实现在 contrib 中。<br>?? 不知道现在是 全量同步，还是增量同步。</p><h3 id="selector"><a href="#selector" class="headerlink" title="selector"></a>selector</h3><p>一些 balancer 的方法，例如 随机、轮询。</p><h3 id="third-party"><a href="#third-party" class="headerlink" title="third_party"></a>third_party</h3><p>一些三方的 proto 定义。</p><h3 id="transport"><a href="#transport" class="headerlink" title="transport"></a>transport</h3><p>http 框架封装 和 grpc 框架封装。 预期 ws 框架封装也可以进来。</p><p>http 路由使用的 mux 。</p><h2 id="整体感受"><a href="#整体感受" class="headerlink" title="整体感受"></a>整体感受</h2><p>kratos 的代码非常清晰简洁，没有太多复杂的设计。<br>代码风格一致性很好，外层定义接口，内层多个实现。常用 option 模式。</p><p>之后要再实际用 kratos 写几个小 demo 。<br>要看看 kratos 的返回值定义，以及 api 文档方面的解决方案。</p><ul><li><input disabled="" type="checkbox"> 使用 go-kratos 写几个小 demo</li></ul><hr><blockquote><p>Life’s most persistent and urgent question is, ‘What are you doing for others?’<br>— <cite>Martin Luther King Jr.</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>readingcodes</tag>
      
      <tag>微服务</tag>
      
      <tag>框架</tag>
      
      <tag>kratos</tag>
      
      <tag>go-kratos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一个基于disk的队列型存储引擎</title>
    <link href="/longblog/posts/22_07_28_00_40_a_queue_storage_based_on_disk.html"/>
    <url>/longblog/posts/22_07_28_00_40_a_queue_storage_based_on_disk.html</url>
    
    <content type="html"><![CDATA[<p>我们有一种场景，将用户在画布上的操作保存下来。<br><code>操作</code> 的模型已经使用特定的序列化方法变成二进制。<br>操作有特定的顺序。<br>对每个操作，都需要去校验操作的合法性。<br>合法操作才会被确认，不合法的，会被忽略(一种策略，也可以是删除)。<br>获取时，需要按 ① 特定字段  ② offset ③ ID ④ 时间 获取，且有范围获取。<br>数据大小，大多为 100B ，但存在 50MB 的可能。</p><p>这和 writeahead log 类似。<br>其他客户端，类似于订阅 binlog。</p><p>从技术上看这个问题，有以下思路：</p><ol><li>这整体是一个队列</li><li>同时兼容 kv 的索引</li><li>需要持久化</li></ol><p>队列的问题域：</p><ol><li>队列大小<ol><li>轮转</li><li>压缩</li></ol></li></ol><p>存储的问题域：</p><ol><li>存储介质<ol><li>磁盘存储</li><li>数据库存储</li></ol></li><li>序列化问题</li><li>缓存问题<ol><li>内存缓存</li><li>本地缓存</li></ol></li></ol><p>索引的问题域：</p><ol><li>索引建立</li><li>索引更新</li><li>索引重构</li><li>全量索引与稀疏索引</li><li>索引的存储形态</li></ol><p>其他问题域：</p><ol><li>锁问题</li><li>迁移问题</li><li>schema 变更问题</li><li>事务支持</li></ol><p>业务的时序图应当为：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs"><br></code></pre></td></tr></table></figure><p>面向接口编程，识别 entity ，识别关系。</p><hr><blockquote><p>It is no use saying, ‘We are doing our best.’ You have got to succeed in doing what is necessary.<br>— <cite>Winston Churchill</cite></p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>grpc的源码走读</title>
    <link href="/longblog/posts/22_07_26_17_34_reading_grpc_codes.html"/>
    <url>/longblog/posts/22_07_26_17_34_reading_grpc_codes.html</url>
    
    <content type="html"><![CDATA[<h2 id="各包的作用"><a href="#各包的作用" class="headerlink" title="各包的作用"></a>各包的作用</h2><h3 id="admin"><a href="#admin" class="headerlink" title="admin"></a>admin</h3><ol><li>初始化了默认的 channelz 监控，详见 channelz</li><li>对外暴露了注册监控 server 的方法</li></ol><h3 id="attributes"><a href="#attributes" class="headerlink" title="attributes"></a>attributes</h3><p>提供了一个简单封装的 immutable kv store 。</p><h3 id="authz"><a href="#authz" class="headerlink" title="authz"></a>authz</h3><p>认证拦截器，提供了 rbac。<br>rbac 模型，使用的是 “github.com/envoyproxy/go-control-plane/envoy/config/rbac/v3” 这个包，这是 envoy 的模块。</p><p>提供了基于文件的拦截器。<br>可以预见，这部分内容，和 envoy 结合会比较紧密。</p><h3 id="backoff"><a href="#backoff" class="headerlink" title="backoff"></a>backoff</h3><p>提供了失败处理的默认 Config，被全局各处引用。重试延迟配置。</p><h3 id="balancer"><a href="#balancer" class="headerlink" title="balancer"></a>balancer</h3><p>使用 注册 的方式，采用 builder 的模式。<br>balancer 包含两个部分，其一 balancer ， 其二 picker。<br>balancer、picker、resolver 均会被 warpper 包裹，用来保证 grpc 内部新增能力。<br>internal 包中的 balancer ，实现了 优雅切换 的功能，是 wapper 中的重要能力。</p><p>k8s 的 resolver 部分，可以参考 <a href="#">Post not found: 技术总结/grpc的负载均衡 grpc的负载均衡</a> </p><h3 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h3><p>提供了一系列用于做基准测试的程序。</p><h3 id="binarylog"><a href="#binarylog" class="headerlink" title="binarylog"></a>binarylog</h3><p>提供了类似于 mysql 的 binlog 机制。提供了方法过滤机制 (config中)。可以把 binlog 写到一个远端地址 (sink)。</p><p>具体实现在 internal 的 binarylog 中。</p><h3 id="channelz"><a href="#channelz" class="headerlink" title="channelz"></a>channelz</h3><p>对外提供 grpc 服务状态指标，和 metrics 的目标一样，本身也是一个 service (和自己写的 grpc service 一样)，提供了几个方法：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> ChannelzServer <span class="hljs-keyword">interface</span> &#123;<br><span class="hljs-comment">// Gets all root channels (i.e. channels the application has directly</span><br><span class="hljs-comment">// created). This does not include subchannels nor non-top level channels.</span><br>GetTopChannels(context.Context, *GetTopChannelsRequest) (*GetTopChannelsResponse, error)<br><span class="hljs-comment">// Gets all servers that exist in the process.</span><br>GetServers(context.Context, *GetServersRequest) (*GetServersResponse, error)<br><span class="hljs-comment">// Returns a single Server, or else a NOT_FOUND code.</span><br>GetServer(context.Context, *GetServerRequest) (*GetServerResponse, error)<br><span class="hljs-comment">// Gets all server sockets that exist in the process.</span><br>GetServerSockets(context.Context, *GetServerSocketsRequest) (*GetServerSocketsResponse, error)<br><span class="hljs-comment">// Returns a single Channel, or else a NOT_FOUND code.</span><br>GetChannel(context.Context, *GetChannelRequest) (*GetChannelResponse, error)<br><span class="hljs-comment">// Returns a single Subchannel, or else a NOT_FOUND code.</span><br>GetSubchannel(context.Context, *GetSubchannelRequest) (*GetSubchannelResponse, error)<br><span class="hljs-comment">// Returns a single Socket or else a NOT_FOUND code.</span><br>GetSocket(context.Context, *GetSocketRequest) (*GetSocketResponse, error)<br>&#125;<br></code></pre></td></tr></table></figure><p>实际的实现在 internal 的 channelz 中。</p><p>有一个 <code>Identifier</code> 的封装，还比较有意思，可以用 数值、字符串、类型 做标识，提供了比较的方法，关键是有 <code>集成关系</code> ，可以用于标识类似于 进程关系 。</p><p>一般用于 监控 和 问题排查 和 调试环节，为了更加直观方便，官方提供了 <a href="https://github.com/grpc/grpc-experiments/tree/master/gdebug">ui 工具</a>。关于 channelz 的设计初衷，可以查看 <a href="https://github.com/grpc/proposal/blob/master/A14-channelz.md">proposal</a></p><h3 id="cmd"><a href="#cmd" class="headerlink" title="cmd"></a>cmd</h3><p>提供了一个简单的 生成 grpc 代码的工具 – protoc-gen-go-grpc  (核心代码在 google.golang.org/protobuf/compiler/protogen 中)</p><h3 id="codes"><a href="#codes" class="headerlink" title="codes"></a>codes</h3><p>类似于 http 的 200、400、401 等等状态码，提供了 grpc 中的状态码。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">var</span> strToCode = <span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>]Code&#123;<br><span class="hljs-string">`&quot;OK&quot;`</span>: OK,<br><span class="hljs-string">`&quot;CANCELLED&quot;`</span>:<span class="hljs-comment">/* [sic] */</span> Canceled,<br><span class="hljs-string">`&quot;UNKNOWN&quot;`</span>: Unknown,<br><span class="hljs-string">`&quot;INVALID_ARGUMENT&quot;`</span>: InvalidArgument,<br><span class="hljs-string">`&quot;DEADLINE_EXCEEDED&quot;`</span>: DeadlineExceeded,<br><span class="hljs-string">`&quot;NOT_FOUND&quot;`</span>: NotFound,<br><span class="hljs-string">`&quot;ALREADY_EXISTS&quot;`</span>: AlreadyExists,<br><span class="hljs-string">`&quot;PERMISSION_DENIED&quot;`</span>: PermissionDenied,<br><span class="hljs-string">`&quot;RESOURCE_EXHAUSTED&quot;`</span>: ResourceExhausted,<br><span class="hljs-string">`&quot;FAILED_PRECONDITION&quot;`</span>: FailedPrecondition,<br><span class="hljs-string">`&quot;ABORTED&quot;`</span>: Aborted,<br><span class="hljs-string">`&quot;OUT_OF_RANGE&quot;`</span>: OutOfRange,<br><span class="hljs-string">`&quot;UNIMPLEMENTED&quot;`</span>: Unimplemented,<br><span class="hljs-string">`&quot;INTERNAL&quot;`</span>: Internal,<br><span class="hljs-string">`&quot;UNAVAILABLE&quot;`</span>: Unavailable,<br><span class="hljs-string">`&quot;DATA_LOSS&quot;`</span>: DataLoss,<br><span class="hljs-string">`&quot;UNAUTHENTICATED&quot;`</span>: Unauthenticated,<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="connectivity"><a href="#connectivity" class="headerlink" title="connectivity"></a>connectivity</h3><p>连接状态的定义，详见 state 包。</p><h3 id="credentials"><a href="#credentials" class="headerlink" title="credentials"></a>credentials</h3><p>提供 grpc 的认证能力。<br>默认有:  tls、<a href="https://www.servicemesher.com/blog/envoy-xds-protocol/">xds</a>、<a href="https://datatracker.ietf.org/doc/html/rfc8693">sts</a>、oauth、<a href="https://cloud.google.com/docs/security/encryption-in-transit/application-layer-transport-security">alts</a>、local、insecure、google cloud 的方式。</p><h3 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h3><p>序列化方法 和 压缩方法。 提供了基于 proto 的序列化方法  和  基于 gzip 的压缩方法。</p><h3 id="gcp"><a href="#gcp" class="headerlink" title="gcp"></a>gcp</h3><p>希望提供 OpenCensus 的能力，目前还在测试阶段。</p><h3 id="grpclog"><a href="#grpclog" class="headerlink" title="grpclog"></a>grpclog</h3><p>logger 的使用为在一个包中，这个包初始化一个带 tag 的 logger 实例 (有缓存)。</p><p>其他方面设计中规中矩，使用的 github.com.golang/glog 作为底层 log 包</p><h3 id="health"><a href="#health" class="headerlink" title="health"></a>health</h3><p>提供客户端的健康检查接口，为了解决服务假死的情况。</p><h3 id="internal"><a href="#internal" class="headerlink" title="internal"></a>internal</h3><p>各种功能的具体实现 以及 一些工具库。</p><h3 id="interop"><a href="#interop" class="headerlink" title="interop"></a>interop</h3><p>一些用于测试的程序</p><h3 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h3><p>保持连接的配置。</p><h3 id="metadata"><a href="#metadata" class="headerlink" title="metadata"></a>metadata</h3><p>类似于 http 的 header，一个 <code>map[string][]string</code> ，用来传递元信息，例如 requestID 等。<br>提供注入 ctx 和 从 ctx 提取的方法。</p><h3 id="peer"><a href="#peer" class="headerlink" title="peer"></a>peer</h3><p>用来表示对端的连接信息。用来做认证的信息传输，具体信息可以查看 credentials 部分。</p><h3 id="profiling"><a href="#profiling" class="headerlink" title="profiling"></a>profiling</h3><p>性能工具，和上面的 channelz 类似，也是一个提供接口的 service，可以记录每个接口的时长等。<br>提供了 json 转义工具。<br>目前使用较少。</p><p>提供了一个 buffer.go 的文件，主要实现了一个 ring buffer，使用 atomic 实现的无锁 buffer ，值得参考 。[TODO]</p><h3 id="reflection"><a href="#reflection" class="headerlink" title="reflection"></a>reflection</h3><p>提供各 service 的反射，也是一个提供接口的 service，能够获取到每个 service 的入参与出参的格式。<br>一个最常规的用法是用于 <a href="https://github.com/fullstorydev/grpcurl">grpcurl</a></p><h3 id="resolver"><a href="#resolver" class="headerlink" title="resolver"></a>resolver</h3><p>用于处理 <code>service name 解析</code>  ，默认不做解析 (由更底层的 net 包做解析)，除非自己指定 resolver 方法。<br>关于 name 的定义详情，可以参考 <a href="https://github.com/grpc/grpc/blob/master/doc/naming.md">grpc 官方文档</a>，URI 规范用的 <a href="https://datatracker.ietf.org/doc/html/rfc3986">RFC 3986</a></p><p>从代码模式上看，使用了 建造者 模式，接口为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Builder <span class="hljs-keyword">interface</span> &#123;<br>Build(xxx, xxx, opts BuildOptions) (Resolver, error)<br>Scheme() <span class="hljs-keyword">string</span><br>&#125;<br></code></pre></td></tr></table></figure><p>resovler 从预期看，应该只需要一次调用，然后给 resolver 提供回调的能力 ( <code>ClientConn.UpdateState()</code> )。</p><p>建造者模式 相比于直接实例化，提供了 需要时再实例化 的能力。</p><h3 id="security"><a href="#security" class="headerlink" title="security"></a>security</h3><ol><li>提供了基于 rbac 的授权工具。</li><li>提供了 tls 工具，验证证书。</li></ol><p>具体可以参考 credentials</p><p>使用了 <a href="https://github.com/google/cel-go">cel-go</a> 这个规则引擎。值得进一步看下。可以参考<a href="https://cloud.tencent.com/developer/article/2025423">这篇文章</a> 。规则引擎的语言定义可以查看<a href="https://github.com/google/cel-spec/blob/master/doc/langdef.md">官方文档</a></p><h3 id="serviceconfig"><a href="#serviceconfig" class="headerlink" title="serviceconfig"></a>serviceconfig</h3><p>config 的类型接口定义。不知道用作什么目的。</p><h3 id="stats"><a href="#stats" class="headerlink" title="stats"></a>stats</h3><p>用于统计请求信息，类似于 tracing 和 metrics，在初始化 server 时，通过 options 注入。</p><h3 id="status"><a href="#status" class="headerlink" title="status"></a>status</h3><p>和 http 的状态码相似，不过支持自定义的 msg 信息，通过 error 传递。</p><h3 id="stress"><a href="#stress" class="headerlink" title="stress"></a>stress</h3><p>压测脚本</p><h3 id="tap"><a href="#tap" class="headerlink" title="tap"></a>tap</h3><p>xxx</p><h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><p>大量集中性单元测试</p><h3 id="xds"><a href="#xds" class="headerlink" title="xds"></a>xds</h3><p><a href="https://www.servicemesher.com/blog/envoy-xds-protocol/">xds的介绍</a> 、 <a href="https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol">envoy 官方文档</a> 、<a href="https://github.com/grpc/proposal/blob/master/A40-csds-support.md">grpc proposal</a><br>这是一系列资源发现服务的接口集合。<br>这个包是一套庞大的 xds 工具集，包括 client 和 server 。</p><p>因为还庞大的一套体系，没细读，之后找时间和 envoy 等一起阅读。【TODO】</p><h2 id="整体的一些感受"><a href="#整体的一些感受" class="headerlink" title="整体的一些感受"></a>整体的一些感受</h2><p>grpc  是一个很大的体系，对于 grpc 的使用也有很多的技巧，初始使用时，会觉得很简单，尤其是以后加接口做维护啥的。 但实际上，grpc 也有很多细节，甚至很多同学都不知道。<br>例如， grpc 有自己的一套 error code 方式、grpc 的 resolver 可以实现多种类型的 uri 、grpc 默认使用 pickfirst 的 lb 策略、grpc 有很多认证方式、grpc 可以用 admin 做调试、stats 做 metrics 监控 等等。</p><p>后续需要去看一下别人都是怎么使用 grpc 的，看看一些最佳实践。</p><h2 id="对于代码走读"><a href="#对于代码走读" class="headerlink" title="对于代码走读"></a>对于代码走读</h2><p>#readingcodes </p><p>代码的走读有 3 个层次：</p><ol><li>理解项目的整体模型</li><li>理解各个包解决了什么问题，大致怎么实现的</li><li>分析一些包的设计，找其亮点，想想如果自己写，会怎么写</li></ol><p>从产出的角度看，可以有：</p><ol><li>走读记录 (包的作用、设计好的地方)</li><li>代码结构图 ( 包结构、类关系、时序 )  </li></ol><p>如果能把 类关系图 和 时序图 画出来，那就很不错了。</p><hr><blockquote><p>My best friend is the one who brings out the best in me.<br>— <cite>Henry Ford</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>readingcodes</tag>
      
      <tag>grpc</tag>
      
      <tag>xds</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>grpc在k8s中的负载均衡问题</title>
    <link href="/longblog/posts/22_07_25_11_25_the_problem_of_grpc_lb_in_k8s_using_service.html"/>
    <url>/longblog/posts/22_07_25_11_25_the_problem_of_grpc_lb_in_k8s_using_service.html</url>
    
    <content type="html"><![CDATA[<p>因为 grpc 是基于 http2 的通信，而 http2 对单个 endpoint 默认仅建立一条 TCP 连接，这就导致在 k8s 中，一个 service 默认仅会有一条 grpc 连接，并且，对于该 grpc 的请求，也都会集中到其中一个 pod 上。</p><p>尽管 k8s 的 service 本身有着 round robin 的负载均衡方式，但那都是建立在 “多次建立连接” 的基础上，对于已经建立连接后，基于 四层网络通信 的 TCP，是无法做到负载均衡的。</p><p>这个问题在我们当前的服务中也存在，两个服务间通过 service name 进行调用时，则会出现负载不均问题。</p><p>之前一直没有太重视这个问题，主要原因在于 每个服务都会有多个 pod ，那么多个 pod 调用 多个 pod 时，一定程度上进行了负载均衡。但是这种负载均衡很不稳定，比较容易出现连接集中到其中几个 pod 上的情况，因此，需要用其他方式解决。</p><p>经过阅读 grpc 代码，发现 grpc 本身有提供一定的机制解决负载均衡的问题，只是默认的方式在 k8s 中没有那么友好。</p><p>这其中涉及到 两个主要概念： resolver、balancer(picker)</p><p>resolver的作用，是解析一个服务地址对应多少 ip 地址，默认的方式是 passthrough，意味着透传服务地址，交由更底层的 transport 去处理。</p><p>还有一些其他的 resolver： ① DNS resolver ② Manual resolver ③ unix resolver</p><p>其中，DNS resolver 可以解析 DNS 中所挂载的 backend ips，这对于传统的基于 DNS 做负载均衡的方案比较好用，k8s 中的 statefulset 也可以大致基于这种模式。</p><p>Manual resolver 则是手动设置 backend ips，如果有自己的服务注册与服务发现机制，则用这种方式就比较方便。</p><p>Balancer 的作用，是从 resolver 解析的对应的 ip 地址池 选择特定的连接，其中核心的职能由 picker 承担，grpc 提供了大量的负载均衡策略，并且支持自定义策略，默认是 pick_first，还有一些例如：轮询、加权轮询、grpc远程lb、优先、rls(自适应？)。 甚至，grpc 提供了一些集群负载均衡的策略，例如一致性hash、CDS LB？等。</p><p>从上面分析来看，我们至少有这么三类解决方案：</p><ol><li> 通过使用 grpc 本身提供的 resolver 机制 和 balancer 机制，实现基于 k8s 的服务发现机制(通过client-go 进行封装)，则能比较优雅地解决这个问题。</li><li> 通过在 client 端实现 conn-pool 的方式，类似于通过多次 dial 的方式创建多个连接，然后自行实现一些 负载均衡的策略，例如 round-robin 或者随机，或者 sticky 的机制等。这个方案实现起来，从当前的技术复杂度上来看是最低的。但有三个问题： ① service 本身一定要更加“随机”，如果是 sticky 类机制，则此方式失效(k8s service默认是轮询机制)。 ② 每个遇到 grpc 负载均衡问题的 client ，都要改动其 client 包，以支持获取 conn 的方式(或者进行多一层封装，github.com/shimingyah/pool 就是采用这种方式)。③ 连接是在初始化过程建立的，初始化之后通过扩容形成的新pod很难被加入到连接池中。</li><li>通过 service mesh ，指定 service 类型为 grpc。</li></ol><p>从目前来看，我认为第一种方式更优雅，对业务的侵入也更小，仅需要修改 grpc 的 dial options，以及导入一个包即可。 这个包的设计，最好将 服务发现 独立出来，专门用于 k8s 中的服务发现与动态监听。</p><p>有些同学会认为，负载均衡这种事，应该交给网关，所以上 service mesh ，业务不要关心。关于这个问题，我的看法是 :  降低业务同学的心智负担，从总体上看是对的，但还是得根据公司实际情况是否值得。相关观点可以查看 <a href="#">Post not found: 技术总结/服务化演进的一些问题探讨 服务化演进的一些问题探讨</a> 。</p><p>后面通过看一些框架的代码，发现 go-zero 有方案 1 的实现，可以参考:  <a href="https://github.com/zeromicro/go-zero/tree/master/zrpc/resolver">zrpc/resolver</a></p><p>可以参考：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/258326212">Kubernetes中gRPC Load Balancing分析和解决</a></li><li><a href="https://segmentfault.com/a/1190000004492447">负载均衡算法及手段</a></li></ul><hr><blockquote><p>Whenever you find yourself on the side of the majority, it is time to pause and reflect.<br>— <cite>Mark Twain</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>grpc</tag>
      
      <tag>微服务</tag>
      
      <tag>loadbalance</tag>
      
      <tag>负载均衡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>grpc的设计分析</title>
    <link href="/longblog/posts/22_07_25_11_21_learning_the_design_of_grpc.html"/>
    <url>/longblog/posts/22_07_25_11_21_learning_the_design_of_grpc.html</url>
    
    <content type="html"><![CDATA[<ol><li> Grpc 的场景是什么？为什么有价值？</li><li> stream 的应用场景是什么？和 unary 有啥区别？</li><li> grpc 使用多通道的价值有多大？</li><li>为什么有些语言下会有 异步/同步 之分？<ol><li> 网络的异步本质</li></ol></li><li> grpc 在使用 http2 传输时，究竟传输了些什么？</li><li> 如何使用其他序列化方式？例如 json？</li><li> 和客户端的交互中使用 grpc 的方式 以及 价值？</li><li> 在 grpc 中，什么粒度被称为一个 service ？</li><li> grpc 设计上的可借鉴点？</li><li> Pb 的价值有多大？</li><li> 一个 rpc 框架，要考虑些什么问题？    1.  服务治理的多层次关系</li></ol><p>gRPC 值得分析的点：</p><ol><li>基于 proto 文件，生成基础代码</li><li>提供多语言插件，使生态增长</li><li>序列化方式，支持 pb 和 json</li><li>grpc-gateway 和 grpc-web</li></ol><p>grpc 的源码走读，可以参考 <a href="#">Post not found: 技术总结/grpc的源码走读 grpc的源码走读</a></p><p>关于 grpc 的负载均衡，可以参考 <a href="#">Post not found: 技术总结/grpc的负载均衡 grpc的负载均衡</a></p><p>可以参考的文档:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/411315625">知乎 gRPC 简介</a></li><li> <a href="https://zhuanlan.zhihu.com/p/389328756">gRPC 基础概念详解</a></li><li> <a href="https://toutiao.io/posts/9bek5r/preview">了解 gRPC 一篇就够了 - 开发者头条</a></li><li> <a href="https://zhuanlan.zhihu.com/p/344914169">gRPC系列(四) 框架如何赋能分布式系统</a></li><li> <a href="https://zhuanlan.zhihu.com/p/332863487">基于 gRPC 的服务注册与发现和负载均衡的原理与实战</a></li></ul><hr><blockquote><p>Opportunity does not knock, it presents itself when you beat down the door.<br>— <cite>Kyle Chandler</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>网络协议</tag>
      
      <tag>grpc</tag>
      
      <tag>rpc</tag>
      
      <tag>http2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我为什么需要一套全面的软件环境</title>
    <link href="/longblog/posts/22_07_24_13_38_why_i_need_a_software_enviroment.html"/>
    <url>/longblog/posts/22_07_24_13_38_why_i_need_a_software_enviroment.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前有记录 <a href="#">Post not found: 技术总结/网络受限环境k3s安装记录 网络受限环境k3s安装记录</a> ，以及为什么要做这件事情 <a href="#">Post not found: 技术总结/我需要什么样的集群搭建工具 我需要什么样的集群搭建工具</a> 。</p><p>实际上，我希望有一套很方便的开发环境 甚至 生产环境，并且有一个需求： 这套环境不是平台绑定！ 我希望只要能给我一台机器，这套环境就能运行起来。</p><p>作为一套程序运行的环境，需要有两个层面的东西： </p><ul><li>基础设施，包含  集群管理、存储、日志、监控</li><li>基础应用，包含  关系数据库、缓存数据库、消息中间件、配置管理、注册中心</li></ul><p>在这之上，才是日常开发所需要的一些工具 以及开发出来的应用，例如  代码平台、容器镜像平台、CICD工具、数据库管理工具、测试工具等。</p><p>我希望这套工具能为我将来做大量的各类开发工作打下基础，让我可以专注在应用的设计与开发上，而不是关注基础设施。</p><h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>我现在的方案，是以</p><ul><li><input disabled="" type="checkbox"> 完成这篇文章，这是我的学习计划的一部分</li></ul><hr><blockquote><p>It’s not what happens to you, but how you react to it that matters.<br>— <cite>Epictetus</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>enviroment</tag>
      
      <tag>效率工程</tag>
      
      <tag>k3s</tag>
      
      <tag>云原生</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络受限环境k3s安装记录</title>
    <link href="/longblog/posts/22_07_21_12_45_install_k3s_in_air_gap_air.html"/>
    <url>/longblog/posts/22_07_21_12_45_install_k3s_in_air_gap_air.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在 <a href="#">Post not found: 技术总结/我需要什么样的集群搭建工具 我需要什么样的集群搭建工具</a> 中解释过，我有时候需要在 网络受限 的环境搭建 k8s 环境。由于 k3s 官方对 air gap 环境的支持比较好，因此记录一下如何做的安装。</p><h2 id="过程记录"><a href="#过程记录" class="headerlink" title="过程记录"></a>过程记录</h2><h3 id="下载资源"><a href="#下载资源" class="headerlink" title="下载资源"></a>下载资源</h3><p>资源地址: <a href="https://github.com/k3s-io/k3s/releases">https://github.com/k3s-io/k3s/releases</a></p><ul><li><p>建立资源文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mkdir k3s &amp;&amp; <span class="hljs-built_in">cd</span> k3s<br></code></pre></td></tr></table></figure></li><li><p>下载 k3s 二进制文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/k3s-io/k3s/releases/download/v1.21.12-rc3%2Bk3s1/k3s<br></code></pre></td></tr></table></figure></li><li><p>下载依赖镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/k3s-io/k3s/releases/download/v1.21.12-rc3%2Bk3s1/k3s-airgap-images-amd64.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>下载部署脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget -O install.sh https://get.k3s.io/<br></code></pre></td></tr></table></figure></li><li><p> 设置执行权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">chmod +x k3s install.sh<br></code></pre></td></tr></table></figure></li><li><p>将整个文件夹打包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -czf k3s.tar.gz ../k3s<br></code></pre></td></tr></table></figure></li></ul><h3 id="集群节点操作"><a href="#集群节点操作" class="headerlink" title="集群节点操作"></a>集群节点操作</h3><ul><li><p>将资源上传到机器上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp k3s.tar.gz xxxx:~/<br></code></pre></td></tr></table></figure></li><li><p>登录机器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh xxxx<br></code></pre></td></tr></table></figure></li><li><p>解压资源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf k3s.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>进入资源文件夹</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> k3s<br></code></pre></td></tr></table></figure></li><li><p>创建 k3s 默认镜像目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mkdir -p /var/lib/rancher/k3s/agent/images/<br></code></pre></td></tr></table></figure></li><li><p>将 k3s 放入 bin 目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">cp k3s /usr/<span class="hljs-built_in">local</span>/bin/<br></code></pre></td></tr></table></figure></li><li><p>解压默认镜像包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zmxf k3s-airgap-images-amd64.tar.gz  -C /var/lib/rancher/k3s/agent/images/<br></code></pre></td></tr></table></figure></li><li><p>安装 master 节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">INSTALL_K3S_SKIP_DOWNLOAD=<span class="hljs-literal">true</span> INSTALL_K3S_EXEC=<span class="hljs-string">&quot;server --disable traefik --token testdemo&quot;</span> ./install.sh<br></code></pre></td></tr></table></figure></li></ul><h3 id="安装常用工具"><a href="#安装常用工具" class="headerlink" title="安装常用工具"></a>安装常用工具</h3><h4 id="安装-helm"><a href="#安装-helm" class="headerlink" title="安装 helm"></a>安装 helm</h4><ul><li>下载 helm<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz<br></code></pre></td></tr></table></figure></li><li>解压<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -xzvf helm-v3.7.1-linux-amd64.tar.gz<br></code></pre></td></tr></table></figure></li><li>移动到 bin 下<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mv linux-amd64/helm /usr/<span class="hljs-built_in">local</span>/bin/helm<br></code></pre></td></tr></table></figure></li><li>清理残余<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rm -rf helm-v3.7.1-linux-amd64.tar.gz linux-amd64<br></code></pre></td></tr></table></figure></li></ul><h4 id="安装-dashboard"><a href="#安装-dashboard" class="headerlink" title="安装 dashboard"></a>安装 dashboard</h4><ul><li><p>获取基础 dashboard 清单</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget -O dashboard.yaml https://raw.githubusercontent.com/kubernetes/dashboard/v2.6.0/aio/deploy/recommended.yaml<br></code></pre></td></tr></table></figure></li><li><p>修改镜像拉取策略</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">imagePullPolicy: IfNotPresent<br></code></pre></td></tr></table></figure></li><li><p>修改 token 过期时间 (option)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在 deploy 启动参数中加入</span><br>--token-ttl=86400<br></code></pre></td></tr></table></figure></li><li><p>手动获取镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull kubernetesui/dashboard:v2.6.0<br><br>docker save -o dashboard.tar kubernetesui/dashboard:v2.6.0<br><br>docker pull kubernetesui/metrics-scraper:v1.0.8<br><br>docker save -o metrics-scraper.tar kubernetesui/metrics-scraper:v1.0.8<br></code></pre></td></tr></table></figure></li><li><p>压缩镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zcf dashboard.tar.gz dashboard.tar <br>tar -zcf metrics-scraper.tar.gz metrics-scraper.tar<br></code></pre></td></tr></table></figure></li><li><p>传递到服务器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp dashboard.tar.gz xxxx:~/k3s<br>scp metrics-scraper.tar.gz xxxx:~/k3s<br></code></pre></td></tr></table></figure></li><li><p>将镜像放入 k3s 默认路径中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf dashboard.tar.gz -C /var/lib/rancher/k3s/agent/images/<br>tar -zxf metrics-scraper.tar.gz -C /var/lib/rancher/k3s/agent/images/<br></code></pre></td></tr></table></figure></li><li><p>手动导入到 ctr 中 ( 不想重启 k3s )</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">ctr i import /var/lib/rancher/k3s/agent/images/dashboard.tar <br>ctr i import /var/lib/rancher/k3s/agent/images/metrics-scraper.tar<br></code></pre></td></tr></table></figure></li><li><p>设置访问账户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs bash">cat &lt;&lt;<span class="hljs-string">eof &gt; dashboard.role.yaml</span><br><span class="hljs-string">apiVersion: v1</span><br><span class="hljs-string">kind: ServiceAccount</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">    name: admin-user</span><br><span class="hljs-string">    namespace: kubernetes-dashboard</span><br><span class="hljs-string">---</span><br><span class="hljs-string"></span><br><span class="hljs-string">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="hljs-string">kind: ClusterRoleBinding</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">    name: admin-user</span><br><span class="hljs-string">roleRef:</span><br><span class="hljs-string">    apiGroup: rbac.authorization.k8s.io</span><br><span class="hljs-string">    kind: ClusterRole</span><br><span class="hljs-string">    name: cluster-admin</span><br><span class="hljs-string">subjects:</span><br><span class="hljs-string">    - kind: ServiceAccount</span><br><span class="hljs-string">      name: admin-user</span><br><span class="hljs-string">      namespace: kubernetes-dashboard</span><br><span class="hljs-string"></span><br><span class="hljs-string">eof</span><br></code></pre></td></tr></table></figure></li><li><p>部署 dashboard</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f dashboard.yaml -f dashboard.role.yaml<br></code></pre></td></tr></table></figure></li><li><p>设置 dashboard 端口访问</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard<br><br><span class="hljs-comment"># 将 port 改为 8082 (或自定义)</span><br><span class="hljs-comment"># 将 type 改为 LoadBalancer</span><br></code></pre></td></tr></table></figure></li><li><p>访问地址</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">https://xxxx:8082/<br></code></pre></td></tr></table></figure></li><li><p>跳过证书验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 在浏览器页面按下</span><br>thisisunsafe<br></code></pre></td></tr></table></figure></li><li><p>获取 token</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl -n kubernetes-dashboard describe secret admin-user-token | grep <span class="hljs-string">&#x27;^token&#x27;</span><br></code></pre></td></tr></table></figure></li><li><p>修改 metrics scriber 的保存时长</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit deploy -n kubernetes-dashboard dashboard-metrics-scraper<br><br><span class="hljs-comment"># 添加 args</span><br>args:<br>  - --metric-duration<br>  - 360h<br></code></pre></td></tr></table></figure></li><li><p>持久化 metrics， 创建 pvc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">cat &lt;&lt;<span class="hljs-string">eof &gt; metrics.pvc.yaml</span><br><span class="hljs-string">apiVersion: v1</span><br><span class="hljs-string">kind: PersistentVolumeClaim</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">    name: metrics-pvc</span><br><span class="hljs-string">    namespace: kubernetes-dashboard</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">    accessModes:</span><br><span class="hljs-string">      - ReadWriteOnce</span><br><span class="hljs-string">    # storageClassName: local-path</span><br><span class="hljs-string">    resources:</span><br><span class="hljs-string">      requests: </span><br><span class="hljs-string">        storage: 2Gi</span><br><span class="hljs-string">eof</span><br></code></pre></td></tr></table></figure></li><li><p>创建 pvc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f metrics.pvc.yaml<br></code></pre></td></tr></table></figure></li><li><p>修改 metrics deploy</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit deploy -n kubernetes-dashboard dashboard-metrics-scraper<br></code></pre></td></tr></table></figure></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 修改 volume 申明</span><br><span class="hljs-attr">volumes:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">metrics-volume</span><br>    <span class="hljs-attr">persistentVolumeClaim:</span><br>  <span class="hljs-attr">claimName:</span> <span class="hljs-string">metrics-pvc</span><br><br><span class="hljs-comment"># 修改 挂载申明</span><br><span class="hljs-attr">volumeMounts:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">metrics-volume</span><br>    <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/tmp</span><br></code></pre></td></tr></table></figure><h4 id="安装-nginx-ingress"><a href="#安装-nginx-ingress" class="headerlink" title="安装 nginx-ingress"></a>安装 nginx-ingress</h4><p>ingress 作为集群的统一入口，几乎是必不可少的。nginx 是最被大家熟悉的了，因此平常就使用 nginx 作为 ingress。</p><ul><li><p>获取 nginx-ingress-controller 清单</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget -O ingress-nginx.yaml https://raw.githubusercontent.com/kubernetes/ingress-nginx/release-v1.3/deploy/static/provider/kind/1.22/deploy.yaml<br></code></pre></td></tr></table></figure></li><li><p>获取 镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull registry.k8s.io/ingress-nginx/controller:v1.3.0<br>docker pull docker.io/jettech/kube-webhook-certgen:v1.2.1<br><br>docker save -o kube-webhook-certgen.tar docker.io/jettech/kube-webhook-certgen:v1.2.1<br><br>docker save -o ingress-nginx.tar registry.k8s.io/ingress-nginx/controller:v1.3.0<br><br>tar -zcf ingress-nginx.tar.gz ingress-nginx.tar<br>tar -zcf kube-webhook-certgen.tar.gz kube-webhook-certgen.tar<br></code></pre></td></tr></table></figure></li><li><p>上传镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">scp ingress-nginx.tar.gz xxxx:~/k3s<br>scp kube-webhook-certgen.tar.gz xxxx:~/k3s<br></code></pre></td></tr></table></figure></li><li><p>导入镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf ingress-nginx.tar.gz -C /var/lib/rancher/k3s/agent/images/<br>tar -zxf kube-webhook-certgen.tar.gz -C /var/lib/rancher/k3s/agent/images/<br><br>ctr i import /var/lib/rancher/k3s/agent/images/ingress-nginx.tar<br>ctr i import /var/lib/rancher/k3s/agent/images/kube-webhook-certgen.tar<br></code></pre></td></tr></table></figure></li><li><p>修改yaml镜像</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># nginx deployment</span><br><span class="hljs-attr">image:</span> <span class="hljs-string">registry.k8s.io/ingress-nginx/controller:v1.3.0</span><br><br><span class="hljs-comment"># job</span><br><span class="hljs-attr">image:</span> <span class="hljs-string">docker.io/jettech/kube-webhook-certgen:v1.2.1</span><br></code></pre></td></tr></table></figure></li><li><p>去掉 node-selector </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#删除 ingress-ready: &quot;true&quot;</span><br>kubectl edit deploy ingress-nginx-controller -n ingress-nginx<br></code></pre></td></tr></table></figure></li><li><p>部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f ingress-nginx.yaml<br></code></pre></td></tr></table></figure></li><li><p>修改 svc 类型为 LoadBalancer (似乎不用)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit svc ingress-nginx-controller -n ingress-nginx<br></code></pre></td></tr></table></figure></li><li><p>测试一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl xxxx<br></code></pre></td></tr></table></figure></li></ul><h4 id="对-dashboard-增加-ingress"><a href="#对-dashboard-增加-ingress" class="headerlink" title="对 dashboard 增加 ingress"></a>对 dashboard 增加 ingress</h4><p>证书的来源，可以是自签，也可以是申请真正的证书，具体可以参考 <a href="#">Post not found: 技术总结/如何解决证书问题 如何解决证书问题</a></p><ul><li>创建 secret <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">k create secret tls mg-tls --key _wildcard.mg.com-key.pem --cert _wildcard.mg.com.pem<br></code></pre></td></tr></table></figure></li></ul><ul><li><p>修改 dashboard 为 http 访问<br>仅需要把 <code>--auto-generate-certificates</code> 给注释掉，然后开放 <code>9090</code> 端口即可，另外，把 readness 探活端口也改成 9090</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit deploy kubernetes-dashboard -n kubernetes-dashboard<br></code></pre></td></tr></table></figure></li><li><p>把 service 指向 9090</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard<br></code></pre></td></tr></table></figure></li><li><p>创建 ingress yaml</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs bash">cat &lt;&lt;<span class="hljs-string">eof &gt; dashboard.ing.yaml</span><br><span class="hljs-string">apiVersion: networking.k8s.io/v1</span><br><span class="hljs-string">kind: Ingress</span><br><span class="hljs-string">metadata:</span><br><span class="hljs-string">  labels:</span><br><span class="hljs-string">    app: kubernetes-dashboard</span><br><span class="hljs-string">  name: kubernetes-dashboard</span><br><span class="hljs-string">  namespace: kubernetes-dashboard</span><br><span class="hljs-string">spec:</span><br><span class="hljs-string">  rules:</span><br><span class="hljs-string">  - host: dashboard.mg.com</span><br><span class="hljs-string">    http:</span><br><span class="hljs-string">      paths:</span><br><span class="hljs-string">      - backend:</span><br><span class="hljs-string">          service:</span><br><span class="hljs-string">            name: kubernetes-dashboard</span><br><span class="hljs-string">            port: </span><br><span class="hljs-string">              number: 80</span><br><span class="hljs-string">        path: /</span><br><span class="hljs-string">        pathType: ImplementationSpecific</span><br><span class="hljs-string">  tls:</span><br><span class="hljs-string">  - hosts:</span><br><span class="hljs-string">      - dashboard.mg.com</span><br><span class="hljs-string">    secretName: mg-tls</span><br><span class="hljs-string">eof</span><br></code></pre></td></tr></table></figure></li><li><p>创建 ingress</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">kubectl apply -f dashboard.ing.yaml<br></code></pre></td></tr></table></figure></li></ul><ul><li>(可选) 实际也可以用 nginx 直接代理 https<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># 直接在注解中添加</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="hljs-string">HTTPS</span><br>    <span class="hljs-attr">nginx.ingress.kubernetes.io/force-ssl-redirect:</span> <span class="hljs-string">&quot;true&quot;</span><br></code></pre></td></tr></table></figure></li></ul><h4 id="安装-bash-completion"><a href="#安装-bash-completion" class="headerlink" title="安装 bash-completion"></a>安装 bash-completion</h4><ul><li><p>安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install -y bash-completion<br></code></pre></td></tr></table></figure></li><li><p>配置 helm 到 bash-completion 配置文件中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">helm completion bash &gt; /etc/bash_completion.d/helm<br></code></pre></td></tr></table></figure></li><li><p>生效</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">source</span> /usr/share/bash-completion/bash_completion<br></code></pre></td></tr></table></figure></li></ul><h3 id="踩了一个大坑"><a href="#踩了一个大坑" class="headerlink" title="踩了一个大坑"></a>踩了一个大坑</h3><ul><li>阿里云会墙掉未备案的域名，如果想走公网ip，就不能随便自签一个证书<br>对通信过程的抓包<br><img src="https://static.longalong.cn/img/20220723023426.png"><br>对 tls 握手的抓包<br><img src="https://static.longalong.cn/img/20220723023648.png"></li></ul><ul><li>查看 tls 握手过程 #network #ssl<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openssl s_client -connect baidu.com:443 -msg<br></code></pre></td></tr></table></figure></li></ul><p>国内非 air gap 也可以使用如下加速安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -<br></code></pre></td></tr></table></figure><h3 id="后续要继续做的"><a href="#后续要继续做的" class="headerlink" title="后续要继续做的"></a>后续要继续做的</h3><ul><li><input disabled="" type="checkbox"> 调研存储的实现方案 (nfs、longhorn)</li><li><input disabled="" type="checkbox"> 调研 cert manager 的作用</li><li><input disabled="" type="checkbox"> 完成对基础环境的封包</li><li><input disabled="" type="checkbox"> 解决调试的问题( init container )</li><li><input disabled="" type="checkbox"> 考虑是否解决证书轮转问题</li><li><input disabled="" type="checkbox"> 考虑解决 registry 问题</li><li><input disabled="" type="checkbox"> 解决日志采集问题 (采或不采是个问题，方案就用 fluentd)</li><li><input disabled="" type="checkbox"> 解决集群监控问题 及 告警问题</li><li><input disabled="" type="checkbox"> 解决非常基础的一些组件问题 (redis、mysql、kafka)</li><li><input disabled="" type="checkbox"> 解决多集群管理问题 (rancher)</li><li><input disabled="" type="checkbox"> 解决多集群发布问题 </li></ul><hr><blockquote><p>As you walk in God’s divine wisdom, you will surely begin to see a greater measure of victory and good success in your life.<br>— <cite>Joseph Prince</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>k3s</tag>
      
      <tag>云原生</tag>
      
      <tag>运维</tag>
      
      <tag>air gap</tag>
      
      <tag>k8s集群安装</tag>
      
      <tag>ingress</tag>
      
      <tag>dashboard</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我需要什么样的集群搭建工具</title>
    <link href="/longblog/posts/22_07_21_what_kind_of_k8s_installer_that_I_need.html"/>
    <url>/longblog/posts/22_07_21_what_kind_of_k8s_installer_that_I_need.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>k3s 是一个精简的 k8s 发行版，之前在 <a href="#">Post not found: 技术总结/记一次k3s环境搭建记录 记一次k3s环境搭建记录</a> 中有过描述。</p><p>相比于 k3s_install.sh 而言， k3sup 最大的价值在于 可以通过 ssh 远程安装，而不是登录到某台机器上再执行安装。另外，通了很简洁的命令行参数。</p><p>无疑，k3sup 作为一个轻量级的集群安装工具，还是很不错的。</p><p>但逐渐我也发现了一些问题：</p><ol><li>k3sup 写死了获取 k3s_install.sh 的脚本地址，这对于国内网络环境来说，不是很友好</li><li>k3sup 只能采用有网环境部署，对于 k3s 的 air gap 状况没有支持</li><li>k3s_install.sh 中的众多环境变量，无法排上用场</li></ol><p>调研过社区中很多的集群部署工具，各工具都有自己的一些特色。</p><ul><li>有些十分轻量简单，例如 k3sup 以及一些简单封装的 ansible ； </li><li>有些有图形界面，例如 autok3s ；</li><li>有些非常庞大，把集群部署、集群管理、应用管理等融于一体的，例如 kubeoperator 之类；</li><li>还有一些发行版自带支持的工具，例如 microk8s、minikube ，包含基础的集群部署 以及 常用的一些插件(ingress、dashboard等) ；</li><li>也有一些工具和云厂商适配得比较好，例如 kops 。</li></ul><p>可以看出来，现在社区中大多数工具，都是基于 <code>网络良好</code> 的条件的。但受制于一些特殊的条件，有些时候，我们希望在一个地方把所有依赖都解决好，然后去到局域网环境下进行部署。</p><p>我比较多使用 k3sup 进行远程搭建集群，但是大多数情况下，网络环境都不是很好，因此用 k3sup 不是很友好。</p><p>我希望的 k3s 集群安装工具，最好有这些特性：</p><ol><li>支持远程安装</li><li>比较好地支持 airgap 场景</li><li>可以做版本管理 (不可变基础设施)</li><li>可以有一些自定义的基础服务</li><li>工具依赖少</li></ol><p>我决定启动一个项目，解决网络受限环境下的集群搭建问题。<br>这个项目是以解决问题为主，不求追求大而全，也不求追求何等的优雅和极致，毕竟我还有很多的事等着做。当真的觉得某些点不好用，或者某些能力无法支持时，再去考虑解决方案，整体采用渐进式的开发方式，毕竟，我也不是专门搞这个的，无法很充分地考虑到各种问题，这很正常。</p><h2 id="项目的考虑"><a href="#项目的考虑" class="headerlink" title="项目的考虑"></a>项目的考虑</h2><h3 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h3><p>有两种使用方式：</p><ol><li>命令行</li><li>配置式</li></ol><p>我倾向配置式的，这样方便重复使用，而命令行则容易无法记录。但命令行也有一个好处，可以很方便地进行修改。</p><h3 id="能力支持"><a href="#能力支持" class="headerlink" title="能力支持"></a>能力支持</h3><ol><li>k8s master 、k8s worker 安装启动</li><li>支持 单master 节点以及 多master 节点</li><li>支持基础的 storage 方案 (longhorn、nfs)</li><li>支持基础的网络插件 (flannel)</li><li>支持 nginx-ingress、lb</li><li>支持 air gap 的场景</li><li>可选择性包含 dashboard </li><li>将来可选择性包含其他插件 (包括业务系统插件)</li></ol><h3 id="生态选择"><a href="#生态选择" class="headerlink" title="生态选择"></a>生态选择</h3><p>就目前来看，k3s 是一个很好的能解决问题的方案，官方做了很多将 k3s 放到资源受限环境的事。<br><a href="https://microk8s.io/docs">microk8s</a> 也很不错，两者有些差异，但对我的场景来看，差异不大。从 air gap 的场景来看，microk8s 的支持没有 k3s 好。</p><p>以 k3s 作为底层实现，对当下而言，是一个不错的选择。</p><p>具体资料可以参考:</p><ul><li><a href="https://docs.rancher.cn/docs/k3s/_index">k3s 中文文档</a> </li><li><a href="https://rancher.com/docs/k3s/latest/en/">k3s 英文文档</a></li></ul><h3 id="最直接的方式"><a href="#最直接的方式" class="headerlink" title="最直接的方式"></a>最直接的方式</h3><a href="#">Post not found: 技术总结/网络受限环境k3s安装记录 网络受限环境k3s安装记录</a><p>2020-07-21:  先完善上面的记录，把相关工具打包，看看够不够用，不够再往下一步 (todo: 采用配置文件安装)</p><p>重新看了下 <a href="https://github.com/sealerio/sealer">sealer</a> 这个项目，从理念上来看，还是很不错的，借由 docker 把 操作系统的依赖打包到一个镜像中 的理念，sealer 把所有基础设施层和业务层全部打包到一个镜像中，恢复的是一个基于 k8s 的所有应用集群。<br>把这个作为一个主要交付物，还是很简洁的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>k3s</tag>
      
      <tag>云原生</tag>
      
      <tag>开发环境</tag>
      
      <tag>运维</tag>
      
      <tag>集群搭建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>服务化演进的一些问题探讨</title>
    <link href="/longblog/posts/22_07_19_21_44_some_discuss_about_microservice.html"/>
    <url>/longblog/posts/22_07_19_21_44_some_discuss_about_microservice.html</url>
    
    <content type="html"><![CDATA[<p>前两天在 go-krotas 的微信群里，看到一哥们儿提问: </p><blockquote><p>在 k8s 中，不理解为啥还需要 registry ? 直接用 service 不就行了吗？</p></blockquote><p>我回答道:</p><blockquote><p>我觉得直接用 service 主要的问题是 扩展性问题。业务上会有各种对服务分组的需求，比如版本、地域等等。 但是四层的负载均衡比较难做到。所以基于注册中心 + subset 的方式就有了生存空间。<br>不过，如果是比较简单的场景，直接用 service 也是够了的。</p></blockquote><p>之后，一哥们儿回到：</p><blockquote><p>把这些需求沉到 istio 运维层，如果你用 registry，那就是开发者自己管了</p></blockquote><p>这个问题其实很多人都会问到，之前和文浩也讨论过这个话题，当时我的想法大概是，把很多东西下沉到 运维层 当然没问题，但实际上这是一个需要看 成本 和 公司阶段 的问题。</p><p>对于一个初期的项目来说，使用最原始的 <code>单体结构</code> 实际上是成本最低的，毕竟一个项目能发展到什么阶段，对于绝大多数项目而言，都是玄学，难以参透，所以 <code>保持软件架构的简洁</code> 是非常重要的。进，可以按模块拆分；退，可以推倒重来；大不了项目一黄，扔掉完事儿。</p><p>当产品流量不错，服务逻辑也开始逐渐膨胀，就该有所规划地进行 模块的解耦设计，表现在代码侧，就是把不同 类型的<code>接口 区分前缀</code>、把实现逻辑<code>独立成包</code>、把 model <code>内联查询拆开</code>等等。</p><p>回到上面的问题，我们又该如何抉择 使用 registry 还是 使用 istio 呢？<br>我认为还是应当比较成本。 isito 等一系列服务治理的体系，在运维上的成本是不低的，如果要用其去替换 registry ，至少需要考虑以下几点：</p><ol><li>我们是否有人才能够做好 istio 的维护 甚至开发？</li><li>假设我们能维护好，那么这套体系是否真的能够降低 业务开发同学的心智负担？<ul><li>使用 registry 的时候，他们需要花多少精力去关注 服务治理 的东西？</li><li>他们是否真的能够做到不用再关心  服务分组(负载均衡)、认证、限流 等等？</li><li>这些价值，是否能 cover 住有专人去维护另一套复杂的体系带来的成本？</li></ul></li></ol><p>不得不说，当我们重新审视完上面几点，就会发现实际上两者很难说谁优谁劣，对小点的公司而言，几乎毫不犹豫选择使用 <code>registry</code> ( 当然，如果业务简单，会毫不犹豫地使用 service  )； 对于很大的公司而言，可能会考虑使用 <code>side car</code> 的流量治理模式；对于中等大小的公司，可能就处于摇摆状态了……</p><p>一个很实际的例子，如果一家原来是用的 dubbo 或者 <code>spring cloud</code> 这一套的公司，他们已经有非常完善的生态了，不论是 服务注册发现 还是 降级限流熔断，或者是 负载均衡策略 等等，本就是业务开发同学应当知道的，成本也没有很高。 和上面说的这一套 ( side car ) 相比，他们又有什么动力转到这个方向上去呢？</p><p>毛剑老师 之前在一场直播中也简要回答过这个问题:  B站几乎是统一语言的(golang)，用的统一的框架( go-kratos )，任何服务治理上的问题，都只需要在框架层改动即可，几乎都是一次性工作，一劳永逸的事。</p><p>总结一下，技术的发展日新月异，<code>云原生</code>、<code>service mesh</code>、<code>side car</code>、<code>istio</code>、<code>服务运行时</code> 等等概念如日中天，甚至于有些年轻人生来就在 微服务 + 云原生 的环境中，认为 <code>单体架构</code> 甚至 <code>SOA</code> 已经是上个时代的产物了。</p><p>诚然，技术的发展给 社会生产力 带来了更高的效率，因此我们应当崇敬技术，应当拥抱新技术，甚至推动新技术的发展。但在工程上时，也需要考虑新技术的场景适用性，对比成本和收益，姑且压制住  技术人对于新技术的好奇和冲动，用更理性的思维去做抉择。</p><p>我实际上也是一个比较有技术人普标性格的人，<code>好奇</code>、<code>爱折腾</code>、<code>喜欢尝试新技术</code>、<code>较真</code>……，之所以会有上面的想法，可能也和一些经历有关。</p><p>公司有一个前端的项目，做的是官网，用的是 nuxt 框架，为的是用 <code>服务端渲染(SSR)</code> 。之后我们有一波比较大型的推广活动，就需要组织各端同学做压测，以保证容量和服务稳定性。这个服务没有太引起我的关注，因为按以往对官网的理解，就是一个静态页，只要资源往 CDN 一扔，啥事儿都不会有。</p><p>但出乎意料的是，组织压测的各小组汇报情况，官网的 qps 到 5k 左右时怎么都上不去了，各 pod 资源利用率也不高，就是不知道啥情况。搞了很久，踩了很多坑，最后还是没解决。</p><p>主要的坑有： </p><ul><li>① 前端同学对压测的工具和流程不熟悉，花费较多时间学习相关操作  </li><li>② 前端同学对在 linux 容器中如何排查问题不熟悉  </li><li>③ 前端同学对服务间调用的网络链路等不熟悉</li><li>④ 基于 vue3 的 nuxt 会有 .mjs 文件格式，这在一些网关或者浏览器中会有坑( 需要设置特定的 mime type )</li><li>⑤ 没有同学能够 hold 住 ssr 的常见问题。</li></ul><p>倒不是在踩前端同学有多菜，我也是从前端转过来的，我明白从日常工作的技能上来看，熟练掌握 linux 操作能进行问题排查 以及 提前预测方案问题 的同学毕竟是更少的。</p><p>后来勉强过了这次活动，总结复盘时，有同学也提出了，官网的场景 似乎 用 全站静态化 + 懒加载 的方式更加合适。 后面听说要改成静态化的方式，不过我也没继续跟了。</p><p>再举一个后端这边的例子。</p><p>我们有一个业务场景，是把 cavas 画布内的各项操作，进行合并，并转发给协同者。这条链路上，我们原来是  一个 <code>消息服务</code>  + 一个 <code>合并服务</code> ，前者处理 <code>客户端连接</code>、<code>鉴权</code>、<code>消息分发</code> 等功能，后者承担 <code>画布数据合并</code> 的功能。</p><p>画布的合并实际上有两个步骤，一个是 索引，用来校验操作的合法性以及落盘，另一个是 合并，用来做真实的数据合并操作。 某一次规划索引的功能时，这个服务被拆成了两个服务，把 索引 和 数据合并 分开了。</p><p>由于我不是直接负责这块儿的，也没有怎么太关注具体的内容。</p><p>后来做压测，我负责这条链路的性能测试 以及 调优工作，才细致地去看了里面的设计与实现，之后也通过压测去验证一些想法，大致的情况是这样的：</p><p>服务被拆分成两个，他们之间通过 <code>kafka</code> 进行异步通信，由于 kafka 消息大小的限制，他们之间使用了 <code>mongodb</code> 做大消息存储；由于 <code>版本的强约束</code>，两个服务之间又用了 mysql 做统一版本管理；由于 <code>索引服务</code> 在一些情况下，需要使用 <code>全量数据</code>，他们之间又提供了 <code>rpc 调用</code>，以获取数据。</p><p>当我去询问这样的价值时，得到的回答是 <code>解耦</code> 、<code>错误隔离</code>、<code>异步提升性能</code> 、<code>定向优化</code> 等等理由…… </p><p>当我表明我的想法，认为他们合在一个进程中更合理时，得到的回答是： 你要更 open 一些、大家都在做微服务，合在一起是<code>反模式的</code>、他们现在运行得很好…… </p><p>可能由于应对这种场景的经验比较欠缺，我一时也不知道该怎么说这事儿。 但我心里非常清楚，合在一起对 <code>性能</code>、<code>稳定性</code>、<code>成本</code>、<code>开发负担</code> 等各方面都有非常大的价值。然后也不管一些反对的声音，花了几个周末的时间，在独立的环境中，对两个服务做合并，做优化，然后做压测…… ，最后的结果是 我所预期的 和 压测的结果 几乎一样，性能提升超过 10 倍，代码删减了接近一半，数据库调用从 4 次 降到 1 次，同样 qps 下，资源占用降低到原来的 40% ……</p><p>后来一次会议上我提出，<code>微服务</code> 是需要遵循一些原则的，我们对微服务的理解不能仅停留在 “微服务” 这个 名词 上，不是所有能拆的服务都该被拆分，至少要基于 <code>DDD</code> 的一些基本原则。</p><p>后来，看到一个架构的设计原则，认为： </p><blockquote><p>我们做系统架构设计，宗旨就是 <code>降低服务复杂性</code> ，复杂性是万恶之源！</p></blockquote><p>这和 istio 从原来的微服务模型 回归到 单体服务时，<a href="https://docs.google.com/document/d/1v8BxI07u-mby5f5rCruwF7odSXgb9G8-C9W5hQtSIAg/edit#heading=h.ra1vuew9eiv1">官方设计文档</a>的第一句话不谋而和</p><blockquote><p><strong>Complexity is the root of all evil or: How I Learned to Stop Worrying and Love the Monolith</strong><br>复杂性是万恶之源，不然我怎么会爱上单体，并且从此不再焦虑呢？</p></blockquote><blockquote><p>更多信息可以参考 <a href="https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/">istio-as-an-example-of-when-not-to-do-microservices</a><br>中文翻译可以参考 <a href="https://www.infoq.cn/article/VtfJLLvqDIOzglwBpqPk">istio 为什么不再使用微服务</a></p></blockquote><p>用一句很让人警醒的话来结束这篇文章，希望我们能以此共勉: </p><blockquote><p>真正的大佬，都是能把复杂问题简单化的人</p></blockquote><hr><blockquote><p>Wisdom begins at the end.<br>— <cite>Daniel Webster</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>微服务</tag>
      
      <tag>istio</tag>
      
      <tag>云原生</tag>
      
      <tag>服务治理</tag>
      
      <tag>devops</tag>
      
      <tag>反微服务</tag>
      
      <tag>microservice</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于价值输入的一些想法</title>
    <link href="/longblog/posts/22_07_19_10_30_some_reflection_of_values_input.html"/>
    <url>/longblog/posts/22_07_19_10_30_some_reflection_of_values_input.html</url>
    
    <content type="html"><![CDATA[<p>今天跟一个同学聊 “初衷” 的问题，他拿出了 want can must 的理论，并且说: must 就是你的用户的声音，是公司的价值。 我心中一震，觉得此事不对，便问这套东西是谁跟你讲的？他答xxx。是我们的团队 leader 。</p><p>对于一个团队 leader 而言，一项重要的职责，就是 保持团队稳定、提升团队效能。其中，要提升 团队稳定 性，核心就是保证 团队成员有继续留下去的理由，这可以有很多方面，例如 做感兴趣的事、有更高维度的成长、有竞争力的薪资、团队氛围、被认可，以及一个很重要的点：自己在做自己认可的事。</p><p>因此，除了外在的那些方法，从 价值输入 为基础的方法就是一个非常非常高效的方法。<br>常见的方式有：特殊小组，经常开会，讨论一些团队、企业价值、公司战略、个人目标 等等。在团体中去表达出自己的”当下的”想法。</p><p>有几个值得参考的点：</p><ol><li>一些公司喜欢招年轻人</li><li>很多公司的中层以上喜欢经常开会</li><li>我党有写作文的传统、有开会的传统、有表态的传统</li><li>重新看 《浪潮》</li><li>《亮剑》中赵刚在战俘营的工作</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>values</tag>
      
      <tag>团队管理</tag>
      
      <tag>团队</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tcpdump</title>
    <link href="/longblog/posts/22_07_18_17_46_some_records_of_tcpdump_for_grab_net_packages.html"/>
    <url>/longblog/posts/22_07_18_17_46_some_records_of_tcpdump_for_grab_net_packages.html</url>
    
    <content type="html"><![CDATA[<h2 id="tcpdump-的基本使用"><a href="#tcpdump-的基本使用" class="headerlink" title="tcpdump 的基本使用"></a>tcpdump 的基本使用</h2><p>tcpdump 可以让我们直接观察网卡的网络流量，方便我们进行 四层 的问题排查 或 学习。</p><ul><li><p>简单使用： <code>tcpdump</code></p></li><li><p>指定网卡： <code>tcpdump -i eth0</code></p></li><li><p>指定显示详略： <code>tcpdump -v</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">11:12:36.647512 IP (tos 0x0, ttl 64, id 46064, offset 0, flags [DF], proto TCP (6), length 52)<br>    172.17.2.203.48402 &gt; iZ2ze57vwreom23zkxvl6qZ.8001: Flags [F.], cksum 0xc46f (correct), seq 2257707167, ack 2959427480, win 502, options [nop,nop,TS val 1345882009 ecr 581770398], length 0<br></code></pre></td></tr></table></figure></li><li><p>更多一点信息: <code>tcpdump -vv</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">11:16:16.311248 IP (tos 0x0, ttl 64, id 16969, offset 0, flags [DF], proto TCP (6), length 60)<br>    172.17.2.203.56348 &gt; iZ2ze57vwreom23zkxvl6qZ.8001: Flags [S], cksum 0x4023 (correct), seq 3161834876, win 64240, options [mss 1460,sackOK,TS val 1346101673 ecr 0,nop,wscale 7], length 0<br></code></pre></td></tr></table></figure></li><li><p>显示二进制:  <code>tcpdump -x</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">11:17:34.686426 IP (tos 0x0, ttl 64, id 64831, offset 0, flags [DF], proto TCP (6), length 60)<br>    172.17.2.203.57696 &gt; iZ2ze57vwreom23zkxvl6qZ.8001: Flags [S], cksum 0x5709 (correct), seq 2287840066, win 64240, options [mss 1460,sackOK,TS val 1346180048 ecr 0,nop,wscale 7], length 0<br>0x0000:  4500 003c fd3f 4000 4006 dfc5 ac11 02cb<br>0x0010:  ac11 02c9 e160 1f41 885d ab42 0000 0000<br>0x0020:  a002 faf0 5709 0000 0204 05b4 0402 080a<br>0x0030:  503d 13d0 0000 0000 0103 0307<br></code></pre></td></tr></table></figure></li><li><p>指定 udp : <code>tcpdump -u</code> 或者  <code>udp</code></p></li><li><p>过滤host 和 ip : <code>tcpdump &quot;host xx.xx.xx.xx &amp;&amp; port 8001&quot;</code></p></li><li><p>写入文件: <code>tcpdump -w xx.pcap -Z root</code> (-Z 指定写文件的 user，默认是 tcpdump，可能会导致 no permission)</p></li><li><p>从文件中查看： <code>tcpdump -r xx.pcap</code></p></li><li><p>不要将 port 转成名字: <code>tcpdump -n</code></p></li><li><p>指定抓包数量:  <code>tcpdump -c 3</code></p></li></ul><h2 id="过滤-expression"><a href="#过滤-expression" class="headerlink" title="过滤 (expression)"></a>过滤 (expression)</h2><p>expression 得到的是一个 bool 。</p><ul><li>协议过滤：<code>ether, fddi, tr, wlan, ip, ip6, arp, rarp, decnet, tcp, udp, icmp</code></li><li>且： <code>and | &amp;&amp;</code></li><li>源地址:  <code>src xxx.xxx.xxx.xx</code></li><li>目标地址:  <code>dst xxx.xxx.xxx.xx</code></li><li>网段过滤: <code>net 172.10.10.0/24</code></li><li>port 段过滤: <code>portrange 3000-3100</code></li></ul><p>例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 地址 和 port </span><br>tcpdump host 192.168.1.10 and tcp port 22 -c 4 <br></code></pre></td></tr></table></figure><h2 id="http-过滤"><a href="#http-过滤" class="headerlink" title="http 过滤"></a>http 过滤</h2><ul><li>捕获所有进出 12345 端口的 IPv4 HTTP 报文，即只打印包含数据的报文，不打印 SYN、FIN、ACK-only 等报文<br>  命令示例： <code>tcpdump -i eth0 -vv -n &#39;tcp port 12345 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)&#39;</code></li><li>只抓获 GET 请求包<br>  命令示例：<code>tcpdump -i eth0 -vv -n &#39;tcp port 12345 and tcp[((tcp[12:1] &amp; 0xf0)&gt;&gt;2):4]=0x47455420&#39;</code></li><li>只抓获 POST 请求包<br>  命令示例：<code>tcpdump -i eth0 -vv -n &#39;tcp port 12345 and tcp[((tcp[12:1] &amp; 0xf0)&gt;&gt;2):4]=0x504f5354&#39;</code></li></ul><h2 id="tcpdump-和-wireshark-结合"><a href="#tcpdump-和-wireshark-结合" class="headerlink" title="tcpdump 和 wireshark 结合"></a>tcpdump 和 wireshark 结合</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> -l 为不用缓冲，直接发送，可快速看到结果</span><br>ssh root@xx.xx.xx.xx &#x27;tcpdump -s 0 -l -i eth0 &quot;tcp port 52000&quot; -w -&#x27; | wireshark -k -i -<br></code></pre></td></tr></table></figure><h2 id="一些表达式内容"><a href="#一些表达式内容" class="headerlink" title="一些表达式内容"></a>一些表达式内容</h2><p><img src="https://static.longalong.cn/img/20220718122411.png"></p><p>可参考文档：</p><ol><li><a href="https://www.cnblogs.com/jiujuan/p/9017495.html">https://www.cnblogs.com/jiujuan/p/9017495.html</a></li><li><a href="https://blog.csdn.net/penriver/article/details/123951062">https://blog.csdn.net/penriver/article/details/123951062</a> 这篇文章虽然较短，但内容很精炼，参考下。</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>tcpdump</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
      <tag>网络协议</tag>
      
      <tag>通信协议</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>效率工程</title>
    <link href="/longblog/posts/22_07_18_10_40_efficiency_engineering.html"/>
    <url>/longblog/posts/22_07_18_10_40_efficiency_engineering.html</url>
    
    <content type="html"><![CDATA[<p>得益于 ob ，我逐渐接触到了 <code>待办</code> 、 <code>daily notes</code> 、<code>memo</code> 等概念，开始关注 <code>目标管理</code>、<code>结果管理</code> 、<code>知识管理</code> 等。 我开始渐渐感觉到 轻松 和 充实，感受到一些标准的工作流 带给我的实际价值。我们可以把上面所关注的这些所有项，统称为 <code>效率工程</code>。</p><p>不论是工作 还是 自己做事情，想要得到更高的收益，始终要看两点： 工作时长 * 工作效率 。很多人喜欢通过 加班 的方式来提升收益，但在我看来，这是得不偿失的。我的公式是这样的：<br>生活总价值 = 工作时长 * 工作效率 + 生活时长 * 生活效率 。 并且 生活时长 = 16 - 工作时长 。</p><p>往往通过增加工作时长的，总会以一个不高的效率。这样，实际我们的生活总价值，反倒是降低了。所以我很不喜欢通过增加工作时长来产生价值。</p><p>另一个因子，是 <code>工作效率</code> ，这实际上是值得我们挖掘的巨大宝藏！ 上天在时间分配上，对任何人都是公平的。而之所以我们和很多牛逼的人有很大差别，往往就在于我们的工作效率有着巨大的差别！</p><p>明确了 需要极大提升 工作效率 这个目标，我们一起看看可以如何提升？</p><p>一些主题：</p><ol><li>我们能如何提升工作效率？<ol><li>目标管理 (找到真正有价值的事！)</li><li>待办管理 (罗列需要落地事)</li><li>时间管理 (安排时间精力的分布)<ol><li>通过番茄工作法，让一段时间专注于一件事</li></ol></li><li>知识库管理 (降低大脑负荷，把容量留给更有创造力的事)</li></ol></li><li>我们能如何帮助他人提升工作效率？<ol><li>明确流程、职责和交付物<ol><li>流程需要 review 和 check</li><li>每件事需要有唯一的责任人</li><li>交付物最好有标准模板</li></ol></li><li>建立公共知识库</li><li>建立团队共同目标<ol><li>周期性复盘会</li><li>团队成员共建待办项</li><li>通过有价值的事聚集向心力</li></ol></li></ol></li></ol><p>工作效率对我而言，可以包含两个方面的内容：</p><ol><li>开发工作效率</li><li>项目管理效率</li></ol><p>对于开发而言，我希望能够建立一整套快速开发流程，能够支持我快速做各类开发尝试！！！ <a href="/notpublish/index.html" name="快速开发" >快速开发</a><br>另外，我希望能够用项目管理的方法，在团队管理中 和 自己的项目中 使用起来。我将来一定会带团队，我需要怎么做好团队管理，让大家都力往一处使？ 我一定会独立做很多事，我该如何 get things done？</p><p>纵观之前很多次和老婆一起定的计划，几乎所有周期性的 或者 长期性的 计划，最后都不了了之，有些甚至没有开始。究其原因，一项重要原因就是 我们没有采用比较好的 项目管理方式，核心有以下几点：</p><ol><li>没有清晰明确的目标</li><li>没有很强的责任感 或 just do it 的执行力</li><li>没有清晰的任务拆解 和 时间规划图</li><li>没有形成文档 (知识管理)<br>另外，从客观原因看，平常要上班，因此要兼顾时间的分配问题，有时候很长时间都没法投入到自己的计划中，打破计划的挫败感十分严重。</li></ol><ul><li><input disabled="" type="checkbox"> 如何解决个人项目规划中的现实问题？</li></ul><p>从心态上，从流程上。流程可能更加有用。</p><ul><li><input disabled="" type="checkbox"> 收集一整套工作流需要的文档模板</li></ul><p>一些问题：</p><ol><li>如何快速发现自己在浪费时间？<blockquote><p>通过 daily notes<br>通过 时间计划表 (日历的时间流逝)</p></blockquote></li></ol><ol><li>有些什么样的时间管理方式？<blockquote><p>参考 day planner 的模式<br>番茄工作法</p></blockquote></li></ol><ol><li>3D原则<pre><code class=" mermaid">flowchart LRstuff --&gt; B&#123;是否 5 min 能完成?&#125;B --&gt; |YES| DO[do it right now : Do]B --&gt; |NO| B2&#123;是否一定需要自己做?&#125;B2 --&gt; |NO| Delegate[委托他人 : Delegate]B2 --&gt; |YES| Defer[加入待办 稍后完成 : Defer]</code></pre></li></ol><p>项目管理的 check 点：</p><ol><li>做的事是不是最被需要的事？</li></ol><p>值得参考的书：</p><ul><li>《GTD》</li></ul><h2 id="待相关完成的文档"><a href="#待相关完成的文档" class="headerlink" title="待相关完成的文档 :"></a>待相关完成的文档 :</h2><p>!<a href="/posts/2207301036.html" title="任务管理的方法">任务管理的方法</a></p><hr><p>归属: </p><ul><li><a href="/notpublish/index.html" name="GTD" >GTD</a></li></ul><hr><blockquote><p>I decided that it was not wisdom that enabled poets to write their poetry, but a kind of instinct or inspiration, such as you find in seers and prophets who deliver all their sublime messages without knowing in the least what they mean.<br>— <cite>Isocrates</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>效率工程</tag>
      
      <tag>任务管理</tag>
      
      <tag>开发效率</tag>
      
      <tag>工程管理</tag>
      
      <tag>待办管理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何成为一个有产品思维的研发人员</title>
    <link href="/longblog/posts/22_07_16_20_12_how_to_be_a_developer_with_product_sense.html"/>
    <url>/longblog/posts/22_07_16_20_12_how_to_be_a_developer_with_product_sense.html</url>
    
    <content type="html"><![CDATA[<p>#问题 #产品 #思维</p><p>如何成为一个有产品思维的研发</p><ol><li> 产品的思维是什么样的？</li><li> 什么叫做用户思维？</li><li> 如何拥有同理心和洞察力？</li><li> 产品的职业技能有哪些？</li><li> 怎么把领域模型的思路用在产品思维上？</li><li> 怎么把 uml 的技能用在产品技能上？</li><li> 怎么借鉴产品经理的推动力(项目经理的推动力)？</li><li> 怎么借鉴产品经理的沟通能力？</li></ol><hr><blockquote><p>Friendship without self-interest is one of the rare and beautiful things of life.<br>— <cite>James F. Byrnes</cite></p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>质量保证梳理</title>
    <link href="/longblog/posts/22_07_16_20_02_some_thing_about_qa.html"/>
    <url>/longblog/posts/22_07_16_20_02_some_thing_about_qa.html</url>
    
    <content type="html"><![CDATA[<p>#qa #quality #项目工程 #质量 #质量保证 </p><p>对于一些需求的实现，使用checklist的方式，回答清楚每一个跟质量相关的问题，帮助开发人员梳理清楚对于质量保证而言最重要的事是什么，做到质量保证“能落地”。</p><h3 id="问题列表："><a href="#问题列表：" class="headerlink" title="问题列表："></a>问题列表：</h3><h4 id="如何保证质量？"><a href="#如何保证质量？" class="headerlink" title="如何保证质量？"></a>如何保证质量？</h4><p>首先得定义质量，要能对质量进行衡量</p><p>对于一个软件项目而言，质量意味着什么</p><h5 id="可扩展性"><a href="#可扩展性" class="headerlink" title="可扩展性"></a>可扩展性</h5><ul><li>以当前的资源部署下，在业务上，能支撑多少业务量(tps/qps)？</li><li>最早遇到性能瓶颈的模块是什么 ？</li><li>最简单能解决该性能瓶颈的方法是什么，解决成本怎么样？</li><li>从设计上，需要达到20-100倍的设计标准，当前的方案能否达到目标？</li><li>扩容/缩容的成本如何？</li></ul><h5 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h5><ul><li>当前设计是否存在单点故障？</li><li>极端情况下，是否能够正常提供共服务(流量突增、恶意刷接口)？</li><li>节点故障是否会影响到正常使用(部分节点宕机)？</li><li>功能是否具备feature toggle？</li><li>功能是否具备回滚能力？</li><li>若发生错误，是否能第一时间得到通知？</li><li>若发生错误，是否任何人都能快速定位到问题？</li></ul><h5 id="可维护性"><a href="#可维护性" class="headerlink" title="可维护性"></a>可维护性</h5><ul><li>预计可能的功能拓展有些什么？可能的功能需要增加哪些内容？</li><li>是否是插件化设计，组件的替换成本如何？</li><li>对于较大的功能模块，是否有比较明显的设计模式说明？</li><li>功能是否具有两个以上的人熟悉，做到维护人员冗余？</li></ul><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><ul><li>是否有详细的说明文档、设计文档、沟通文档、项目过程文档？</li><li>是否有针对于项目结构/模块设计/代码风格与他人进行沟通讨论？</li><li>是否有完善的单元测试及集成测试？</li><li>是否进行过技术探讨与反思？例如当前项目的主要问题是什么？解决的优先级是怎样的？当前的解决方案是否具有通用性？能否有所沉淀以成为通用组件？等</li></ul><h4 id="如何用测试来保障质量？"><a href="#如何用测试来保障质量？" class="headerlink" title="如何用测试来保障质量？"></a>如何用测试来保障质量？</h4><p>测试 是更接近实际的一种质量保证手段。</p><h5 id="2-1-如何保证功能的正确性？"><a href="#2-1-如何保证功能的正确性？" class="headerlink" title="2.1 如何保证功能的正确性？"></a>2.1 如何保证功能的正确性？</h5><h6 id="单元测试-集成测试"><a href="#单元测试-集成测试" class="headerlink" title="单元测试/集成测试"></a>单元测试/集成测试</h6><ul><li>如何保证(自动化)单元测试的覆盖率</li><li>学习QA如何写测试用例</li><li>做测试的代码覆盖率检查<h6 id="如何能快速管理集成测试"><a href="#如何能快速管理集成测试" class="headerlink" title="如何能快速管理集成测试"></a>如何能快速管理集成测试</h6></li><li>super_test 项目<h6 id="如何保证集成测试的场景覆盖率"><a href="#如何保证集成测试的场景覆盖率" class="headerlink" title="如何保证集成测试的场景覆盖率"></a>如何保证集成测试的场景覆盖率</h6></li><li>学习QA如何写测试用例</li><li>先以一系列场景为例，实际写一堆用例再来回答这个问题</li></ul><h5 id="2-2-如何保证性能和可扩展性？"><a href="#2-2-如何保证性能和可扩展性？" class="headerlink" title="2.2 如何保证性能和可扩展性？"></a>2.2 如何保证性能和可扩展性？</h5><h6 id="性能测试、故障演练-性能瓶颈"><a href="#性能测试、故障演练-性能瓶颈" class="headerlink" title="性能测试、故障演练(性能瓶颈)"></a>性能测试、故障演练(性能瓶颈)</h6><p>性能测试主要为 <code>单模块性能测试</code> 和 <code>链路集成测试</code></p><p>对于模块的测试，可以先站在基础架构的角度，考虑模块的可扩展性，再站在实际使用的角度，从业务角度测试性能。</p><p>例如，对于messenger的压测，可以先考虑当前使用的 redis、mongo、kafka 的本身的拓展能力，得到在不同流量级别下这些模块的性能。</p><p>然后，考虑 messenger 目前提供的服务内容，针对每个业务内容，进行单独的测试，类似于单接口测试。然后对多接口进行测试，考虑不同接口之间的相互影响因素。</p><p>对于链路压测，需要考虑 1. 链路范围界定 2. mock服务。(ps: 可以考虑mock为正常服务的一个切面)</p><h5 id="2-3-自动化性能测试平台的构想"><a href="#2-3-自动化性能测试平台的构想" class="headerlink" title="2.3 自动化性能测试平台的构想"></a>2.3 自动化性能测试平台的构想</h5><p>对于业务的性能测试，压测的情况越接近于真实业务情况的压测约具有说服力。因此，性能测试是要尽量模拟真实的业务场景。</p><p>但对于一个变化较快的业务，或者一个新的业务，是很难准确估计真实的业务流量模型的。</p><p>这种时候最好的方式是对多个可能的变量进行笛卡尔积，然后对每种情况进行压测。</p><p>举个例子，messenger可能面临的业务流量模型有很多，其中 总连接数、单个房间人数、房间个数、首页关注人数、changeset发送频率、changeset大小、广播消息类型/频率 等都是可能的变量</p><p>例如，平均一个房间10个人，单实例上 100 个房间，总连接5000时，用户以 6帧/s 的速度发送 800byte 大小的changeset，那么，对于资源的耗用情况如何？</p><p>如果要对每一种情况进行手工压测，那么其成本是巨大的，</p><p>从 do not repeat yourself 的角度出发，这应该是一个可以自动化的流程。</p><p>对于压测人员，需要做的是： 1. 找出约束的变量，配置关注的变量值。 2. 对结果进行分析并做近一步的确认。</p><p>自动化性能测试平台最好是一个可以适应多种场景的通用化平台，支持自定义的压测脚本、自定义的压测报告、自定义的压测策略，</p><p>应该支持多种消息格式，例如 http、https、ws、wss、grpc、mqtt 等。</p><p>对于这个平台的搭建，一定要仔细去分析 jmeter、metersphere 这两个平台的逻辑以及设计。</p><h5 id="2-4-如何保证可靠性？"><a href="#2-4-如何保证可靠性？" class="headerlink" title="2.4 如何保证可靠性？"></a>2.4 如何保证可靠性？</h5><ul><li>  边界测试、极端测试、混沌测试、故障演练(错误故障)</li></ul><h6 id="可以考虑以下内容："><a href="#可以考虑以下内容：" class="headerlink" title="可以考虑以下内容："></a>可以考虑以下内容：</h6><ul><li>  api的边界测试交给中间件来进行。</li><li>  梳理可能的错误点，并考虑故障注入的方式。</li><li>  跳出代码逻辑去考虑错误故障，目标是得到尽可能全的故障类型，并针对每个可能的故障进行故障排查及恢复演练。</li></ul><h6 id="当前最紧要的事："><a href="#当前最紧要的事：" class="headerlink" title="当前最紧要的事："></a>当前最紧要的事：</h6><ul><li>  故障演练的规范化。</li></ul><h5 id="2-5-如何保证用户角度的正确性？"><a href="#2-5-如何保证用户角度的正确性？" class="headerlink" title="2.5 如何保证用户角度的正确性？"></a>2.5 如何保证用户角度的正确性？</h5><ul><li>  视觉感知测试/e2e测试</li></ul><p>e2e测试的成本相对较高，需要测试人员写相应的代码，且每当业务逻辑产生变化，则需要维护这些用例代码。</p><p>视觉感知测试是另一种和e2e测试类似的测试，一般来说不需要写代码，但由于测试是基于“图片对比”的，因此灵活性不如 e2e,</p><p>视觉感知测试的优点是“直观”，在考虑操作录制的情况下，测试人员仅需要对“用例场景”进行定义即可，要求相对较低。</p><h4 id="视觉感知测试怎么做？"><a href="#视觉感知测试怎么做？" class="headerlink" title="视觉感知测试怎么做？"></a>视觉感知测试怎么做？</h4><p>最基础的方式，是进行图片对比，有一系列的操作逻辑，每一步操作后，都有一个截图，用于展示当前操作状态。</p><p>只要一个功能的逻辑没有改动，则特定操作会产生特定的结果。</p><p>只要重复这样的操作逻辑，并对每次的图片进行比对，就能得出特定的结论。</p><p>划分应当以 功能 区分开。</p><p>在某一个功能下，有一些具体的场景。</p><p>每个场景都有特定的操作与逻辑。</p><p>很多场景是相关联的，这些场景应当可以进行参数化配置。</p><p>场景中的很多流程是相似的，这些流程应当可以复用。</p><p>由于运行与截图需要对测试人员透明，因此需要提供录制场景的方法。</p><p>考虑到功能可能频繁变更，因此要增加快速处理比对失败的场景的能力。</p><p>考虑到测试的后台运行属性，因此需要具备报警与通知的功能。</p><p>考虑到素材的可变更性，需要标注可变素材块。</p><p>考虑到h5的布局对内容的影响，可以考虑对于布局的视觉感知测试。</p><h6 id="当前最紧要的事：-1"><a href="#当前最紧要的事：-1" class="headerlink" title="当前最紧要的事："></a>当前最紧要的事：</h6><p>以一个功能需求为实际场景，进行MVP实验</p><h4 id="考虑当前-master-项目的整体质量保证措施"><a href="#考虑当前-master-项目的整体质量保证措施" class="headerlink" title="考虑当前 master 项目的整体质量保证措施"></a>考虑当前 master 项目的整体质量保证措施</h4><ul><li>  以瑞阳牵头的发布流程的保证</li><li>  各小组进行的code review</li><li>  写轮眼项目</li><li>  前端项目的e2e模块</li><li>  后端的api接口自动化测试</li><li>  监控报警</li><li>  基于用户反馈的 oncall 机制</li></ul><p>文档直通车：</p><a href="#">Post not found: 技术总结/关于质量保证的探讨 关于质量保证的探讨</a><hr><blockquote><p>The greatest achievement of humanity is not its works of art, science, or technology, but the recognition of its own dysfunction.<br>— <cite>Eckhart Tolle</cite></p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>关于质量保证的探讨</title>
    <link href="/longblog/posts/22_07_16_20_00_something_about_qa.html"/>
    <url>/longblog/posts/22_07_16_20_00_something_about_qa.html</url>
    
    <content type="html"><![CDATA[<p>#qa #quality #项目工程 #质量 #质量保证</p><h2 id="什么是质量？"><a href="#什么是质量？" class="headerlink" title="什么是质量？"></a>什么是质量？</h2><p>系统质量，首先保证系统的正常运行，包括功能正确、系统稳定性。其次，要保证系统的健壮性，包括系统的容错能力、报警能力、自恢复能力。还要保证系统的可维护性和可扩展性，包括系统功能增加/修改的难易程度、系统横向扩展的能力。</p><h2 id="我们主要关注哪些点？"><a href="#我们主要关注哪些点？" class="headerlink" title="我们主要关注哪些点？"></a>我们主要关注哪些点？</h2><ol><li> 保证正确的业务逻辑</li></ol><p>任意一个功能都是符合业务预期的，覆盖业务所需要的所有场景。</p><ol start="2"><li> 保证可维护性</li></ol><p>考虑功能规划，确保在之后的新业务需求开发时，能流程地接入系统，而不是做trick兼容。</p><p>新老功能的替换时，确保在数据转换上的可实施。</p><p>在新老功能替换时，确保平滑迁移。</p><ol start="3"><li> 保证容错性(健壮性)</li></ol><p>确保程序有充分的错误处理机制，不会出现程序崩溃宕机的情况。</p><p>确保有明确的监控指标和告警措施，能在程序出现问题时第一时间感知。</p><p>确保有明确的应急方案，例如流量切换，降级、熔断，feature toggle等方案</p><ol start="4"><li> 保证可扩展性</li></ol><p>程序的设计尽量是无状态的，可以水平扩展的。</p><p>如果无法做到无状态，就要做到分治，最终达到可以无限扩展的能力。</p><ol start="5"><li> 保证性能</li></ol><p>选择合适的处理流程，能够异步处理的尽量异步，尽量保证主流程上没有较大的阻塞操作。</p><p>尽量保证程序逻辑层面的不冗余，再保证代码结构设计层面的性能优化。</p><p>由于数据库往往是最终瓶颈，因此要始终保持sql的高效，主要是 分页、批量、索引、独立 几个方式。</p><ol start="6"><li> 安全性？</li></ol><h2 id="如何保证："><a href="#如何保证：" class="headerlink" title="如何保证："></a>如何保证：</h2><ol><li> 代码规范(命令规范、职责单一、分层清晰等)</li><li> 写代码时的高标准(设计模式、面向对象、依赖注入、结构清晰)</li><li> 复杂问题的方案设计与review</li><li> 代码质量保证工具(如sonar、go vet)</li><li> 测试(单元测试、接口测试、集成测试、e2e测试、性能测试)</li><li> 不断重构(小步持续性重构)</li></ol><h2 id="如何执行："><a href="#如何执行：" class="headerlink" title="如何执行："></a>如何执行：</h2><ol><li> [代码规范] =&gt; 有规范、有review</li><li> [高要求] =&gt; 梳理流程、整理文档、先设计再执行、拉人探讨</li><li> [方案设计与review] =&gt; 有文档、有review流程</li><li> [代码质量工具] =&gt; CI/CD 步骤</li><li> [不断重构] =&gt; 每个月自查代码问题</li><li> [测试] =&gt; 见下方</li></ol><h4 id="单元测试的要求"><a href="#单元测试的要求" class="headerlink" title="单元测试的要求"></a>单元测试的要求</h4><ol><li> 所有库方法，必须有正确性单元测试用例。</li><li> 复杂的库方法，需要有多种边界情况测试用例。</li><li> 单元测试用例管理直接在当前模块下的 xxx_test.go 文件中。</li></ol><h4 id="接口测试要求"><a href="#接口测试要求" class="headerlink" title="接口测试要求"></a>接口测试要求</h4><p>目的：保证单个接口的输入输出的正确性</p><p>主要内容： 1. 输入值的边界参数传入。 2. 确保输出值的schema。</p><h4 id="集成测试要求"><a href="#集成测试要求" class="headerlink" title="集成测试要求"></a>集成测试要求</h4><p>目的：从用户行为的角度，保证功能的正确性。</p><p>主要内容：</p><ol><li> 从场景出发，进行数据准备。</li><li> 实际测试，对返回值进行断言。</li></ol><h4 id="e2e测试要求"><a href="#e2e测试要求" class="headerlink" title="e2e测试要求"></a>e2e测试要求</h4><ol><li> 重要流程的场景测试，例如，登录、注册、创建team、创建project、打开文档等。</li><li> 可以考虑基于图片对比的测试。(视觉感知测试)</li></ol><h4 id="性能测试要求"><a href="#性能测试要求" class="headerlink" title="性能测试要求"></a>性能测试要求</h4><ol><li> 单服务性能测试</li></ol><ul><li>  将所有服务拆分，对其进行性能测试。</li><li>  将服务的依赖项进行拆分，mock。</li></ul><ol start="2"><li> 集成服务性能测试</li></ol><ul><li>  全链路数据压测，数据准备与压测。</li><li>  数据来源可采用流量录制。</li></ul><ol start="3"><li> 数据库性能测试</li></ol><ul><li>  对业务场景进行数据库操作过程排查</li><li>  对单个sql语句进行查询分析</li></ul><h2 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h2><p>服务质量的保证主要应当从</p><ol><li> 团队开发人员意识培养</li><li> 团队质量保证规范与流程</li><li> 测试</li></ol><p>这三个方面入手。</p><p>我当前从 测试 入手，主要有以下几个方面的内容：</p><h4 id="完成-api-接口测试框架搭建与开发"><a href="#完成-api-接口测试框架搭建与开发" class="headerlink" title="完成 api 接口测试框架搭建与开发"></a>完成 api 接口测试框架搭建与开发</h4><p>super-test 项目，目标是让团队成员写 <code>接口测试</code> 的难度降低，现在已经做到：</p><ol><li> 使用 json 配置文件进行测试</li><li> 具有简单的测试触发页面</li></ol><h4 id="考虑-websocket-的功能测试"><a href="#考虑-websocket-的功能测试" class="headerlink" title="考虑 websocket 的功能测试"></a>考虑 websocket 的功能测试</h4><p>[TODO]</p><h4 id="考虑-性能测试-框架"><a href="#考虑-性能测试-框架" class="headerlink" title="考虑 性能测试 框架"></a>考虑 性能测试 框架</h4><ol><li> 项目性能</li><li> 中间件性能</li><li> 数据库性能</li></ol><p>文档直通车：</p><a href="#">Post not found: 技术总结/质量保证梳理 质量保证梳理</a><hr><blockquote><p>A man’s growth is seen in the successive choirs of his friends<br>— <cite>Ralph Waldo Emerson</cite></p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>groupcache 源码阅读记录</title>
    <link href="/longblog/posts/2207161947.html"/>
    <url>/longblog/posts/2207161947.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>“缓存” 是一个 非常、非常、非常 通用的模块，是提升 程序性能/系统性能 的极佳方式之一，缓存的模块有非常多的开源方案。</p><p>本地缓存可以使用 gcache、goframe中也有一个gcache，自己要实现一个简单的 LRU 的缓存也不难。</p><p>分布式缓存中，最常用的是 redis，几乎通吃，以前也有一些团队使用 memcache，现在几乎被 redis 替代。</p><p>内存中的缓存还可以看下 godis 这个项目，golang 的 redis 实现。</p><p>而 groupcache ，作为内存中的 分布式缓存，实现非常简洁，很有参考价值。值得一提的是，groupcache 的作者就是 memcache 的作者。</p><h2 id="可参考的方面"><a href="#可参考的方面" class="headerlink" title="可参考的方面"></a>可参考的方面</h2><h3 id="Pb-和-httpv2-提升性能"><a href="#Pb-和-httpv2-提升性能" class="headerlink" title="Pb 和 httpv2 提升性能"></a>Pb 和 httpv2 提升性能</h3><p>常规我们接触 pb，都是直接使用 grpc 生成代码，使用 grpc 的框架提供 rpc 服务，但是在 groupcache 中，作者直接把 pb 拿出来使用，并且结合 httpv2 的连接复用，也同样能够提供高性能，一定程度上达到了合 grpc 一样的能力。</p><h3 id="Singleflight-去除重复请求"><a href="#Singleflight-去除重复请求" class="headerlink" title="Singleflight 去除重复请求"></a>Singleflight 去除重复请求</h3><p>通用的解决重复请求的方案，常用于解决缓存穿透问题。</p><h3 id="87行代码的-lru-策略"><a href="#87行代码的-lru-策略" class="headerlink" title="87行代码的 lru 策略"></a>87行代码的 lru 策略</h3><p>一个双向链表 + 一个 hashmap，前者用来做 lru，后者用来做缓存。</p><p>这个双向链表是由 golang 提供的，初次之外，golang官方库还提供了 ring 和 heap 两种数据结构。</p><h3 id="48行代码的一致性hash"><a href="#48行代码的一致性hash" class="headerlink" title="48行代码的一致性hash"></a>48行代码的一致性hash</h3><p>有多个 hash slot，无删除 slot 操作。</p><p>使用的 []int 的方式做的 slot，这种方式在查询时的时间复杂度是 Ologn，这种方式和 redis client 的 slot 实现方式不一样，redis 用了更多的空间，但得到的是 O1 的查询复杂度。</p><h2 id="一些特点"><a href="#一些特点" class="headerlink" title="一些特点"></a>一些特点</h2><ol><li> 会做本地缓存(hot cache)，且无更新机制</li><li> 有 load 机制，本地缓存没有 且 未能从 peer 获取时，进行 load</li><li> 有 evicted 机制，可以设置回调</li></ol><p>整体来看，和 gcache 这类本地缓存差别不大，加的 peers 可以帮助减少 load 机制的使用，对于 load 操作很重的缓存比较有利。但本地的 cache 无法主动更新的特点可能导致缓存不一致问题。</p><p>生产使用的场景不太确定，可能适用于数据一致性不太重要、load过程很繁重的情况。</p><p>从开发角度来看，这个项目有一些可参考性，例如 48行代码实现一致性hash、87行代码实现 lru、singleflight解决缓存穿透、直接使用 pb 做为序列化方式提升性能、服务间的http使用 http2 提升性能。</p><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul><li><input disabled="" type="checkbox"> 可以再看一下 go-redis 中的 hash slot 保持方法，以及 mongos 如何保证 路由到正确节点。</li></ul><hr><blockquote><p>They must often change, who would be constant in happiness or wisdom.<br>— <cite>Confucius</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>readingcodes</tag>
      
      <tag>缓存</tag>
      
      <tag>cache</tag>
      
      <tag>groupcache</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记一次服务性能的调优排查</title>
    <link href="/longblog/posts/22_07_16_a_record_of_service_performance_improve.html"/>
    <url>/longblog/posts/22_07_16_a_record_of_service_performance_improve.html</url>
    
    <content type="html"><![CDATA[<h3 id="事情起因："><a href="#事情起因：" class="headerlink" title="事情起因："></a>事情起因：</h3><ol><li><p> 某一天，听到浩兄说我们有个告警，是因为 event-tracking 的 cpu 使用超标<br><img src="https://static.longalong.cn/img/warning.png"></p></li><li><p> 我感觉比较奇怪，顺口问了下情况，后来又和 浩兄、窦兄 一起看了下各种监控</p></li></ol><h3 id="查看-cpu、内存、网络-情况"><a href="#查看-cpu、内存、网络-情况" class="headerlink" title="查看 cpu、内存、网络 情况"></a>查看 cpu、内存、网络 情况</h3><p><img src="https://static.longalong.cn/img/asynccode-12.png"></p><p><img src="https://static.longalong.cn/img/asynccode-11.png"></p><p>发现很奇怪，内存和 cpu 是猛增上去的，但网络流量却非常小。</p><p>又听到 浩兄 说当时机器的 socket 连接数被打满了，于是怀疑是 goroutine 的问题，进一步查看 goroutine 监控</p><h3 id="查看-goroutine-监控"><a href="#查看-goroutine-监控" class="headerlink" title="查看 goroutine 监控"></a>查看 goroutine 监控</h3><p><img src="https://static.longalong.cn/img/asynccode-8.png"></p><p>发现确实 goroutine 飙得非常高。 也没多想，怀疑是不是有 for 循环里面起了 协程，导致 goroutine 没控制住？</p><p>于是和 窦兄 一块儿，一通代码查看，……额……，没发现啥问题。</p><p>此事一直耿耿于怀，听相关负责人说，在计划重构 event-tracking ，有点害怕，毕竟私有部署的项目中，我还有些依赖 event-tracking 的 sdk [😱]……</p><p>但由于 ① 没有现场，没法抓各种 profile ② 没有 tracing，不知道究竟卡在哪里了</p><p>毕竟，日志、监控、tracing、pprof 相当于我们的眼睛，没有这些，现在做一切都相当于盲猜……</p><p>为了减轻私有化适配的工作，在浩兄的怂恿下，开始了一番自救操作……</p><h3 id="进一步排查的准备工作"><a href="#进一步排查的准备工作" class="headerlink" title="进一步排查的准备工作"></a>进一步排查的准备工作</h3><ol><li><p> 由于不知道各接口的响应情况，于是初步建了个 metrics 的板子，简单看了下，觉得挖不同接口的响应时长可能没啥意义，这应该是个系统性问题，于是放弃继续做板子，转向其他方向。</p></li><li><p> 由于已经在框架中集成了 tracing 的东西，于是花了半个小时把 event-tracking 的 所有 tracing 接上。(包括 redis、db、kafka、http request)</p></li><li><p> 为了能复现高压力下的场景，在压测机上装了 ab </p></li></ol><h3 id="试下未做调整时的压测情况"><a href="#试下未做调整时的压测情况" class="headerlink" title="试下未做调整时的压测情况"></a>试下未做调整时的压测情况</h3><h4 id="压测结果"><a href="#压测结果" class="headerlink" title="压测结果"></a>压测结果</h4><p>并发 200， qps 54</p><p><img src="https://static.longalong.cn/img/asynccode-2.png"></p><p><img src="https://static.longalong.cn/img/asynccode-10.png"></p><p>tracing </p><p><img src="https://static.longalong.cn/img/20220716105356.png"></p><p>有四个表现奇怪的地方：</p><ol><li><p> 负载非常不均衡，必定有鬼</p></li><li><p> nginx 到 pod 的时间居然达到数秒</p></li><li><p> Pod 内 produce kafka 的时间 居然和 整个请求的时长一样</p></li><li><p> 在 kafka 队列中，居然卡了这么长时间</p></li></ol><h4 id="先怀疑下-kafka-实例的问题"><a href="#先怀疑下-kafka-实例的问题" class="headerlink" title="先怀疑下 kafka 实例的问题"></a>先怀疑下 kafka 实例的问题</h4><p>kafka 监控 </p><p><img src="https://static.longalong.cn/img/asynccode-6.png"></p><p>就这点量，远远达不到 kafka 的瓶颈，跳过。</p><h4 id="怀疑下-是不是代码中用了-同步发送"><a href="#怀疑下-是不是代码中用了-同步发送" class="headerlink" title="怀疑下 是不是代码中用了 同步发送"></a>怀疑下 是不是代码中用了 同步发送</h4><p><img src="https://static.longalong.cn/img/asynccode.png"></p><p>看来并不是，排除。</p><h4 id="怀疑一下-ikafka-包的问题"><a href="#怀疑一下-ikafka-包的问题" class="headerlink" title="怀疑一下 ikafka 包的问题"></a>怀疑一下 ikafka 包的问题</h4><p>此时发现 ikafka 没有接 metrics ，于是看了下之前写的文档，想把 ikafka 的 metrics 接上。</p><p>然后发现 我想接的是 sarama ，但 ikafka 没有暴露 metrics 出来，也没有把 sarama 的 metrics 接口暴露出来，无果……</p><p>这个问题留到之后再怀疑吧</p><h4 id="怀疑一下-kafka-的配置问题"><a href="#怀疑一下-kafka-的配置问题" class="headerlink" title="怀疑一下 kafka 的配置问题"></a>怀疑一下 kafka 的配置问题</h4><p><img src="https://static.longalong.cn/img/asynccode-1.png"></p><p>果然，看到了一个问题，consumer 的 队列数 居然仅设置了 1 ，这岂不是意味着，消息只能一条条从 kafka 取回来？那不得老慢了……</p><p>另外，看到没有开 autocommit，于是也顺手加上。<br><img src="https://static.longalong.cn/img/20220716105438.png"></p><p>ok，这下顺眼多了。其他也不知道咋样，先压一波试下吧。</p><h3 id="调整-channel-size-后的压测"><a href="#调整-channel-size-后的压测" class="headerlink" title="调整 channel size 后的压测"></a>调整 channel size 后的压测</h3><p>刚准备压的，看了一眼 grafana ，懵了…… </p><p><img src="https://static.longalong.cn/img/asynccode-4.png"></p><p>啥情况？？？ Cpu 直接被拉满了？？？</p><p>吓得我反手就抓了一波 pprofile</p><p><img src="https://static.longalong.cn/img/asynccode-9.png"></p><p>发现居然有大量的 park 方法的调用，这显然就是 goroutine 疯狂切换导致的问题啊。</p><p>按以往的经验，很有可能是 for 循环中的 select 不是全阻塞的。此时跑去搜了一圈 <code>for</code> 的代码。没发现问题，每个 for 循环都还比较规范……</p><p>于是回来接着看 pprofile，注意到 左边 kafka 的调用，按理，这是属于底层包的调用啊，应该不会有啥问题啊。</p><p>跟了一圈代码，由于是直接的 cgo 调用，也很难继续追下去了。</p><p><img src="https://static.longalong.cn/img/origin_img_v2_e59df2f5-be93-4e16-8749-3f500e19ab9g.jpg"></p><p>想到之前 confluent 给我留下的奇奇怪怪的印象 (主要是因为黑盒问题)，再加上对 sarama 做过比较仔细的源码阅读，想着既然 confluent 不好调试，换成 sarama 先试试吧……</p><h3 id="切换-sarama-后的压测"><a href="#切换-sarama-后的压测" class="headerlink" title="切换 sarama 后的压测"></a>切换 sarama 后的压测</h3><p>并发 200， qps 940</p><p><img src="https://static.longalong.cn/img/asynccode-3.png"></p><p>grafana 监控</p><p><img src="https://static.longalong.cn/img/asynccode-7.png"></p><p>时间分布合理</p><p><img src="https://static.longalong.cn/img/asynccode-5.png"></p><p>打完   收工 ！</p><h3 id="结局："><a href="#结局：" class="headerlink" title="结局："></a>结局：</h3><ol><li><p> Event-tracking 的性能问题至少算是解了</p></li><li><p> 如果需要的话，可以再去整理下 confluent 的正确打开方式 ( 还是算了…… ，直接用 sarama 或者 kafka-go 不香吗 )</p></li><li><p> 公共包最好还是提供一些统一的 metrics 接口、提供统一的 tracing 设置</p></li><li><p> 对于我们现在大多数的业务场景，1c 的 cpu 支撑个 1000qps 问题是不大的，大家可能需要更新下对性能的感性认识</p></li></ol><hr><blockquote><p>There are two kinds of failures: those who thought and never did, and those who did and never thought.<br>— <cite>Laurence J. Peter</cite></p></blockquote>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>自动解决文章的图片问题</title>
    <link href="/longblog/posts/22_07_how_to_reslove_random_pic.html"/>
    <url>/longblog/posts/22_07_how_to_reslove_random_pic.html</url>
    
    <content type="html"><![CDATA[<p>我有给文章添加图片的需求，主要是为了解决一些需要发布的文章 没有 头图的问题。</p><p>有几个解决方案：</p><ol><li>在创建 post 的时候，创建好图片</li><li>通过命令的方式，增加图片</li></ol><p>另外，我希望我的图片能够更加稳定地存在自己的图床上，因此有把图片放到自己图床的需求，这部分可以参考 <a href="#">Post not found: 生产力建设/解决ob的图床问题 解决ob的图床问题</a></p><p>先用最简单的方式，使用 templater 插件，插件的使用可以参考 <a href="#">Post not found: 生产力建设/ob插件选择和使用 ob插件选择和使用</a>。<a href="https://silentvoid13.github.io/Templater/internal-functions/internal-modules/system-module.html" title="Previous chapter">templater官方博客</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">&lt;% tp.web.random_picture(&quot;600x200&quot;, &quot;landscape,water&quot;) %&gt;<br></code></pre></td></tr></table></figure><p>这样得到的，是一个在 文档中使用 超链接 呈现出来的图片。</p><p>我希望能在 meta 中添加一张图片，则自己写了个脚本，注入到 templater 中，如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">newimage</span>(<span class="hljs-params">size, query</span>) </span>&#123;<br><br><span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> getRequest(<br><span class="hljs-string">`https://source.unsplash.com/random/<span class="hljs-subst">$&#123;size ?? <span class="hljs-string">&quot;&quot;</span>&#125;</span>?<span class="hljs-subst">$&#123;query ?? <span class="hljs-string">&quot;&quot;</span>&#125;</span>`</span>);<br><br><span class="hljs-keyword">const</span> url = response.url;<br><br><span class="hljs-comment">// 这里可以做一些其他处理，比如上传到自己的图床</span><br><br><span class="hljs-keyword">return</span> url<br><br>&#125;<br><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getRequest</span>(<span class="hljs-params">url</span>) </span>&#123;<br><br><span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> fetch(url);<br><br><span class="hljs-keyword">if</span> (!response.ok) &#123;<br><br><span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">&quot;Error performing GET request&quot;</span>);<br><br>&#125;<br><br><span class="hljs-keyword">return</span> response;<br><br>&#125;<br><br><br><span class="hljs-built_in">module</span>.exports = newimage;<br></code></pre></td></tr></table></figure><p>命令暂时就不加了，使用 template 的快捷键一样 ok 。</p><p>当然，按理使用 quickadd 也能实现此功能，回头再看。</p><h3 id="增加转成自己的图床"><a href="#增加转成自己的图床" class="headerlink" title="增加转成自己的图床"></a>增加转成自己的图床</h3><p>我在 上面的代码中，加上上传到 picgo ，改成了:</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">newimage</span>(<span class="hljs-params">size, query</span>) </span>&#123;<br><span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> getRequest(<br><span class="hljs-string">`https://source.unsplash.com/random/<span class="hljs-subst">$&#123;size ?? <span class="hljs-string">&quot;&quot;</span>&#125;</span>?<span class="hljs-subst">$&#123;query ?? <span class="hljs-string">&quot;&quot;</span>&#125;</span>`</span>);<br><br><span class="hljs-keyword">const</span> url = response.url;<br><br><span class="hljs-keyword">const</span> res = <span class="hljs-keyword">await</span> fetch(uploadUrl, &#123;<br><span class="hljs-attr">method</span>: <span class="hljs-string">&quot;POST&quot;</span>,<br><span class="hljs-attr">headers</span>: &#123; <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span> &#125;,<br><span class="hljs-attr">body</span>: <span class="hljs-built_in">JSON</span>.stringify(&#123; <span class="hljs-attr">list</span>: [url] &#125;),<br>&#125;);<br><br><span class="hljs-keyword">const</span> data = <span class="hljs-keyword">await</span> res.json();<br><span class="hljs-keyword">return</span> data.result[<span class="hljs-number">0</span>]<br>&#125;<br><br><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getRequest</span>(<span class="hljs-params">url</span>) </span>&#123;<br><span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> fetch(url);<br><br><span class="hljs-keyword">if</span> (!response.ok) &#123;<br><span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-built_in">Error</span>(<span class="hljs-string">&quot;Error performing GET request&quot;</span>);<br>&#125;<br><span class="hljs-keyword">return</span> response;<br>&#125;<br><br><br><span class="hljs-built_in">module</span>.exports = newimage;<br></code></pre></td></tr></table></figure><p>意想不到的是，居然发生了 <code>CORS</code> 的问题，而这种问题，只能由 picgo 来解决了，于是download 了 picgo 的代码，一番操作，添加了 跨域允许 的 header ：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">// 在 handleRequest 中添加了 OPTIONS</span><br><span class="hljs-keyword">if</span> (request.method === <span class="hljs-string">&#x27;OPTIONS&#x27;</span>) &#123;<br>handleResponse(&#123;<br>response,<br><span class="hljs-attr">header</span>: &#123;<br><span class="hljs-string">&#x27;access-control-allow-headers&#x27;</span>: <span class="hljs-string">&#x27;*&#x27;</span>,<br><span class="hljs-string">&#x27;access-control-allow-methods&#x27;</span>: <span class="hljs-string">&#x27;POST, GET, OPTIONS&#x27;</span>,<br><span class="hljs-string">&#x27;access-control-allow-origin&#x27;</span>: <span class="hljs-string">&#x27;*&#x27;</span><br>&#125;<br>&#125;)<br><br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// 在 处理 upload 的请求中，添加同样的 OPTIONS</span><br></code></pre></td></tr></table></figure><p>然后，perfect ！</p><p>最后，增加一个纯模板，配一个命令，per<del>per</del>perfect !</p><hr><p>归属: </p><ul><li><a href="#">Post not found: 生产力建设/ob的使用问题 ob的使用问题</a></li><li><a href="#">Post not found: 生产力建设/解决ob的发布问题 解决ob的发布问题</a></li></ul><hr><blockquote><p>A prudent question is one half of wisdom.<br>— <cite>Francis Bacon</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>ob</tag>
      
      <tag>ob插件</tag>
      
      <tag>obsidian</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>serverless_究竟是何方神圣？</title>
    <link href="/longblog/posts/22_07_11_what_is_serverless.html"/>
    <url>/longblog/posts/22_07_11_what_is_serverless.html</url>
    
    <content type="html"><![CDATA[<h2 id="什么是-serverless"><a href="#什么是-serverless" class="headerlink" title="什么是 serverless"></a>什么是 serverless</h2><p>顾名思义，<code>serverless</code> 就是 <code>server-less</code>，也就是 <code>别话时间去搞服务器</code> =&gt; <code>把精力全都放到业务开发上</code> !</p><p>在传统的开发流程中，一个团队的标准配置是： 前端工程师 * x + 后端工程师 * y + 运维工程师 * z 。 前端写交互，后端写数据逻辑与存储，运维就搞服务部署、灰度、日志、监控等等。每个岗位各司其职，看起来十分完美。</p><p>但有时候也没有那么完美，人越多、职责分的越细，岗位间的鸿沟就越大，沟通的成本在组织内就会急剧增加。 通常的表现就是 会越来越多、参会的人也越拉越多，有时候可能一个简单的 <code>上新服务进行调试</code> 的工作，都需要大动干戈搞十来个人拉会各种同步和对齐。</p><p>这种时候我们可能就会想： 能不能不要这么多麻烦的服务器的问题？由一个统一的平台去解决 网关配置、服务发现、服务调用、日志、告警、数据库、中间件、CICD、负载均衡、动态扩缩容 等等……</p><p>实际上，不论是传统的各种 cmdb，还是各种微服务框架，还是各种服务引擎，都是在为了解决上面列出的这个问题，只是他们选择的方案不同而已。 其中 serverless，是最晚出现的一种方案，是在 微服务架构之后出现的另一种架构风格。</p><p>有一种论调是 serverless = faas + baas。其中 faas 是主计算的，而 baas 是主存储的。实际上我们对服务器的需求本质上就这两类： 计算 + 存储。</p><p>而泛 IT 领域内，大家常说起 serverless 的时候，总喜欢把 AWS 的 lambda 计算作为例子，或者把 阿里云 的 函数计算 作为例子。容易让人误以为 serverless 就是 <code>函数计算</code> 。</p><p>而我认为 serverless ，除了包括 机器视角下 的 faas 以及 baas 外，还包括 开发流 视角下的 serverless 开发工具链 + 管理平台 + 编排系统 + 监控系统。 这是站在 serverless 的终极目标上得出的结论。</p><p>云服务上更关心 机器视角，例如 baas 要包含哪些产品？kv？文档存储？对象存储？table存储？ 例如 faas 有哪些形式的延伸？微服务场景？任务触发场景？</p><p>开发者更关心 开发流视角，例如 如何部署一段程序？如何管理一段程序？如何监控程序运行？</p><h2 id="serverless-解决了什么问题？"><a href="#serverless-解决了什么问题？" class="headerlink" title="serverless 解决了什么问题？"></a>serverless 解决了什么问题？</h2><ol><li>开发和部署工具链</li><li>弹性扩缩容 (按量付费)</li></ol><h2 id="使用-serverless-的场景是什么？"><a href="#使用-serverless-的场景是什么？" class="headerlink" title="使用 serverless 的场景是什么？"></a>使用 serverless 的场景是什么？</h2><ol><li>异步 (事件触发)</li><li>无状态 (少依赖)</li><li>突发性</li></ol><h2 id="serverless-的技术点有哪些？"><a href="#serverless-的技术点有哪些？" class="headerlink" title="serverless 的技术点有哪些？"></a>serverless 的技术点有哪些？</h2><ol><li>如何触发 serverless？(events)</li><li>如何解决弹性扩缩容？<ol><li>基于 kubernetes</li></ol></li><li>如何解决路由绑定？(负载均衡)</li><li>如何解决快速启动？</li><li>如何解决程序运行？(build 过程)</li><li>如何解决服务编排？</li></ol><h2 id="serverless-比较难搞定什么？"><a href="#serverless-比较难搞定什么？" class="headerlink" title="serverless 比较难搞定什么？"></a>serverless 比较难搞定什么？</h2><ol><li><p>状态保持 (本地缓存、长连接)</p></li><li><p>事务</p></li><li><p>编排</p></li><li><p>冷启动</p></li><li><p>黑盒排查问题</p></li><li><p>服务商绑定</p></li></ol><h2 id="阿里云的几款-serverless-产品的异同"><a href="#阿里云的几款-serverless-产品的异同" class="headerlink" title="阿里云的几款 serverless 产品的异同"></a>阿里云的几款 serverless 产品的异同</h2><ol><li>FC</li><li>SAE</li><li>MSE</li><li>ASK</li></ol><p>当我们纵眼观察 阿里云 提供了几类和 serverless 有关的产品时，往往容易犯迷糊。<br>FC 是函数计算，主要目的是提供计算能力，运行的资源粒度可以非常小 (128MB * 0.08 C)，可以运行任意你想要的程序。在使用场景上，类似于 <code>任务</code> 的概念。(当然你也可以把他用于 http server)</p><p>SAE 是 serverless 应用引擎，提供的能力和 FC 类似，都是计算能力。在场景上，类似于 <code>service</code> 的概念，例如启动一个 auth 服务。 相比于传统的自己部署一个服务，SAE 提供了 网关、弹性伸缩、监控 等能力。(其实，MSE 有逐渐替代 SAE 的倾向，毕竟他们的重合度太高了)</p><p>MSE 是 微服务引擎，提供的是 服务治理 的能力。是 注册/配置中心、网关、分布式事务、流量治理、开发测试 的集合体。实际就是把原来 阿里云 提供的各类单个的产品，在 微服务 的应用场景下进行了组合。</p><p>ASK 是 弹性 k8s 集群，也就是 k8s 集群的按量付费版本，提供的是 k8s 基础设施。</p><h2 id="我们对-serverless-抱有什么样的期待？"><a href="#我们对-serverless-抱有什么样的期待？" class="headerlink" title="我们对 serverless 抱有什么样的期待？"></a>我们对 serverless 抱有什么样的期待？</h2><ol><li>完全无运维 <ul><li>一套完善的开发和部署平台</li></ul></li><li>友好一致的开发体验<ul><li>开发者无需关注除 业务需求 之外的一切 (比如 k8s、注册中心、服务发现、CICD 等等)</li></ul></li><li>省钱<ul><li>按需付费，不用为每个不怎么使用的应用都花着钱</li></ul></li></ol><h2 id="一些常见的-serverless-应用"><a href="#一些常见的-serverless-应用" class="headerlink" title="一些常见的 serverless 应用"></a>一些常见的 serverless 应用</h2><ul><li><input disabled="" type="checkbox"> 举一些具体的例子</li></ul><ol><li>音视频行业的转码需求</li><li>设计、图形等领域相关的渲染需求</li><li>推荐系统相关的机器学习需求</li></ol><p>分为 2 类：</p><ol><li>微服务场景</li><li>弹性任务场景</li></ol><h2 id="serverless-平台有哪些？"><a href="#serverless-平台有哪些？" class="headerlink" title="serverless 平台有哪些？"></a>serverless 平台有哪些？</h2><ul><li><input disabled="" type="checkbox"> 对比各家的产品，看看他们都在解决什么问题？</li></ul><ol><li>openfaas</li><li>knative</li><li>kubeless</li><li>阿里云相关产品</li><li>腾讯云相关产品</li><li>AWS 相关产品</li></ol><h2 id="我会怎么选？"><a href="#我会怎么选？" class="headerlink" title="我会怎么选？"></a>我会怎么选？</h2><ul><li><input disabled="" type="checkbox"> 列举一些场景，分别在这些场景下我会如何决策？</li></ul><p>如果我是团队 TL，我会如何选择？</p><h2 id="可以参考的文档"><a href="#可以参考的文档" class="headerlink" title="可以参考的文档"></a>可以参考的文档</h2><ol><li><a href="https://www.aliyun.com/product/aliware/fnf">阿里云 serverless 工作流</a></li><li><a href="https://help.aliyun.com/document_detail/97792.html">阿里云 serverless 应用引擎</a></li><li><a href="https://www.aliyun.com/product/fc">阿里云 FC 函数计算</a></li><li><a href="https://www.aliyun.com/product/cs/ask">阿里云 ASK 容器服务</a></li><li><a href="https://cloud.tencent.com/document/product/583/9199">腾讯云函数</a></li><li><a href="https://cloud.tencent.com/document/product/1154">腾讯云 serverless 应用中心</a></li><li><a href="https://cloud.tencent.com/document/product/1371">腾讯云 弹性微服务</a></li><li><a href="https://firebase.google.com/">firebase</a></li></ol><hr><blockquote><p>Through meditation and by giving full attention to one thing at a time, we can learn to direct attention where we choose.<br>— <cite>Eknath Easwaran</cite></p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>serverless</tag>
      
      <tag>faas</tag>
      
      <tag>baas</tag>
      
      <tag>cloud native</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>syncthing的方案及安装记录</title>
    <link href="/longblog/posts/22_07_30_10_17_syncthing_install_log_to_resolve_file_sync.html"/>
    <url>/longblog/posts/22_07_30_10_17_syncthing_install_log_to_resolve_file_sync.html</url>
    
    <content type="html"><![CDATA[<p>项目地址： <a href="https://github.com/syncthing/syncthing">syncthing</a></p><h3 id="安装-syncthing"><a href="#安装-syncthing" class="headerlink" title="安装 syncthing"></a>安装 syncthing</h3><ul><li><p>下载地址: <a href="https://github.com/syncthing/syncthing/releases">https://github.com/syncthing/syncthing/releases</a></p></li><li><p>选择和自己电脑匹配的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/syncthing/syncthing/releases/download/v1.20.3/syncthing-linux-amd64-v1.20.3.tar.gz <br></code></pre></td></tr></table></figure></li><li><p>解压目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf syncthing-linux-amd64-v1.20.3.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>移动文件到 /usr/bin 下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mv syncthing-linux-amd64-v1.20.3/syncthing /usr/bin/syncthing<br></code></pre></td></tr></table></figure></li><li><p>创建启动用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">adduser syncthing<br></code></pre></td></tr></table></figure></li><li><p>创建 systemd 开机自启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">cp syncthing-linux-amd64-v1.20.3/etc/linux-systemd/system/syncthing@.service /etc/systemd/system/syncthing@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>允许开机自启</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl <span class="hljs-built_in">enable</span> syncthing@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>开启服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl start syncthing@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>配置代理</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">proxy_pass</span> <span class="hljs-number">127.0.0.1:8384</span>;<br></code></pre></td></tr></table></figure></li><li><p>开放防火墙<br><code>22000/tcp</code> + <code>22000/tcp</code></p></li></ul><h3 id="安装-discover"><a href="#安装-discover" class="headerlink" title="安装 discover"></a>安装 discover</h3><p>由于公共的 discover 服务在国内访问实在问题大大的，因此最好自己搭一个发现服务器 (类似于信令服务)。</p><ul><li><p>下载地址： <a href="https://github.com/syncthing/discosrv/releases">https://github.com/syncthing/discosrv/releases</a></p></li><li><p>下载和服务器匹配的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/syncthing/discosrv/releases/download/v1.18.6/stdiscosrv-linux-amd64-v1.18.6.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>解压文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf stdiscosrv-linux-amd64-v1.18.6.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>将文件移动到 opt 下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">mv stdiscosrv-linux-amd64-v1.18.6 /opt/stdiscosrv<br></code></pre></td></tr></table></figure></li><li><p>创建 daemon</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs bash">cat &lt;&lt;<span class="hljs-string">eof &gt;  /etc/systemd/system/syncdiscover@syncthing.service</span><br><span class="hljs-string">[Unit]</span><br><span class="hljs-string">Description=Syncthing discover for %I</span><br><span class="hljs-string">After=network.target</span><br><span class="hljs-string">StartLimitIntervalSec=60</span><br><span class="hljs-string">StartLimitBurst=4</span><br><span class="hljs-string"></span><br><span class="hljs-string">[Service]</span><br><span class="hljs-string">WorkingDirectory=/opt/stdiscosrv</span><br><span class="hljs-string">User=%i</span><br><span class="hljs-string">ExecStart=/opt/stdiscosrv/stdiscosrv -debug -listen 0.0.0.0:8101</span><br><span class="hljs-string">Restart=on-failure</span><br><span class="hljs-string">RestartSec=1</span><br><span class="hljs-string">SuccessExitStatus=3 4</span><br><span class="hljs-string">RestartForceExitStatus=3 4</span><br><span class="hljs-string"></span><br><span class="hljs-string"># Hardening</span><br><span class="hljs-string">ProtectSystem=full</span><br><span class="hljs-string">PrivateTmp=true</span><br><span class="hljs-string">SystemCallArchitectures=native</span><br><span class="hljs-string">MemoryDenyWriteExecute=true</span><br><span class="hljs-string">NoNewPrivileges=true</span><br><span class="hljs-string"></span><br><span class="hljs-string">[Install]</span><br><span class="hljs-string">WantedBy=multi-user.target</span><br><span class="hljs-string"></span><br><span class="hljs-string">eof</span><br><br></code></pre></td></tr></table></figure></li><li><p>运行服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl <span class="hljs-built_in">enable</span> syncdiscover@syncthing.service &amp;&amp;\<br>systemctl start syncdiscover@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>查看服务运行状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl status syncdiscover@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>查看服务 id</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">journalctl -u syncdiscover@syncthing.service<br></code></pre></td></tr></table></figure></li><li><p>结果如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">7月 10 20:11:26 longser2 stdiscosrv[19917]: stdiscosrv v1.18.6 &quot;Fermium Flea&quot; (go1.17.6 linux-amd64) teamcity@build.syncthing.net 2021-12-30 12:07:01 UTC [purego]<br>7月 10 20:11:26 longser2 stdiscosrv[19917]: Server device ID is xxxx-xxxx-xxxx-xxxx-xxxx-xxx<br></code></pre></td></tr></table></figure></li><li><p>在各客户端中修改 全局发现服务器地址</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">https://xxx.xxx.xxx:8101/?id=xxxx-xxxx-xxxx<br></code></pre></td></tr></table></figure></li></ul><ul><li>官方文档地址: <a href="https://docs.syncthing.net/users/stdiscosrv.html">https://docs.syncthing.net/users/stdiscosrv.html</a></li></ul><h3 id="安装-relay-server"><a href="#安装-relay-server" class="headerlink" title="安装 relay server"></a>安装 relay server</h3><p>relay 服务的使用场景是，当 p2p 失败时，可以借由 relay server 进行数据转发。</p><ul><li><p>下载地址： <a href="https://github.com/syncthing/relaysrv/releases">https://github.com/syncthing/relaysrv/releases</a></p></li><li><p>下载和服务器匹配的版本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://github.com/syncthing/relaysrv/releases/download/v1.18.6/strelaysrv-linux-amd64-v1.18.6.tar.gz<br></code></pre></td></tr></table></figure></li><li><p>解压文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">tar -zxf strelaysrv-linux-amd64-v1.18.6.tar.gz<br></code></pre></td></tr></table></figure></li></ul><p>我目前没有 relay 的需求，待有需求时，再来完善此处。</p><ul><li>官方文档地址: <a href="https://docs.syncthing.net/users/strelaysrv.html">https://docs.syncthing.net/users/strelaysrv.html</a></li></ul><hr><p>归属:</p><ul><li><a href="/posts/undefined.html" title="syncthing">syncthing</a>  安装记录</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>syncthing</tag>
      
      <tag>文件同步</tag>
      
      <tag>操作记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决ob的图床问题</title>
    <link href="/longblog/posts/22_07_30_09_47_image_bed_in_ob.html"/>
    <url>/longblog/posts/22_07_30_09_47_image_bed_in_ob.html</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>如 <a href="#">Post not found: 生产力建设/解决ob的发布问题 解决ob的发布问题</a> 中所描述的，我有很强的发布需求，在发布过程中，经常遇到这样的问题：</p><ol><li>图片数量多了后，压缩、打包、发布的速度就降下去了 [强诉求]</li><li>不同的电脑间，文件同步变成了一个比较麻烦的事 [弱诉求]</li><li>分享一篇文档时，本地图片地址无法查看 [中等诉求]</li></ol><p>于是就开始思考这个问题 :  <code>如何解决 blog 的 图片/视频 等静态资源问题?</code></p><p>方案实际是很成熟的 : 使用图床。</p><p>实际上，图床是一个非常广泛的需求，不论大家用什么写作工具，只要想发布到互联网上，都需要用到图床。</p><p>在网上，大家能搜到很多第三方的图床平台(github、gitee、bilibili 以及一些奇奇怪怪的平台)，但很多都不稳定，容易挂掉(或关闭)，对图床而言，稳定性是极其重要的，否则重新整理历史文档中的图片地址，然后再重新发布到各平台……这也太难了……<br>(想想微信图片加了防盗链、简书加了防盗链……)</p><p>自建图床 可能对有强写作习惯的人来说是一个比较好的方案。<br>图床 的搭建需要两个部分： 存储空间 + 管理工具。</p><p>在云端上，存储空间 可以直接选择 对象存储 ，也可以使用服务器挂载硬盘，各有一定优劣，但对大多数人来说，<code>对象存储</code> 是一个更合适的选择。</p><p>管理工具，可以建立在云端服务器上，也可以建立在本机。如果选择了对象存储方案，则可以把管理工具建在本机。好处是省去了服务器的维护工作。</p><p>我会选择 七牛云 作为存储空间 (因为每个月有 10Gb 免费空间和流量啊！七牛赛高！)，选择用 <a href="https://github.com/Molunerfinn/PicGo">picGo</a> 作为图床管理工具。</p><p>我在 ob 中，使用 <a href="https://github.com/renmu123/obsidian-image-auto-upload-plugin/blob/master/readme-zh.md">自动上传图片</a> ，直接将 copy 的图片上传到了图床上。</p><p>使用了一段时间后，发现直接用图床有些问题，比如断网环境下就没法使用了…… 而且平常在本地使用时，会有明显的图片显示延迟。</p><p>其实，我需要的是这样的功能：</p><ol><li>图片平常就保存在本地，但希望存放在某个特定目录 [似乎需求不强]</li><li>图片是采用 md 格式的引用，而不是 wiki 的引用 [图片直接上传问题问题也不大]</li><li>当有发布需要时，把对应的本地图片链接转换成图床地址 [同上]</li><li>发布打包时，对照是否已经存在上传过的图片，已上传则不再上传 [同上]</li></ol><p>可以查阅 ob 的开发者文档，看看怎么拦截 cmd + v 。同时可以参考  <a href="https://github.com/renmu123/obsidian-image-auto-upload-plugin/blob/master/readme-zh.md">自动上传图片</a> ，看看他是怎么做到的。 </p><blockquote><p>ps: 2022-07-30 按，目前使用的 picGo，使用 cmd + shift + v 和 cmd + v 两种方式选择图片存本地和上传。因为强缓存的问题，实际也没有多少请求 cdn 。目前够用，暂时不考虑其他方案。<br>之前 picGo 没设置跨域，在 ob 中写 js 脚本上传会有问题，看了下 picGo 的代码，提了 pr ，已经通过了，也解决了自己写 js 脚本上传问题。</p></blockquote><p>详细信息可以查看 <a href="#">Post not found: 生产力建设/自动解决文章的图片问题 自动解决文章的图片问题</a></p><h3 id="解决预览大小问题"><a href="#解决预览大小问题" class="headerlink" title="解决预览大小问题"></a>解决预览大小问题</h3><p>目前没有比较通用的解决方案，或许使用 image 标签是不错的方案。</p><blockquote><p>ps： 2022-07-30 按，在 ob 中，使用 image in editor 的插件，就能很好解决。在 web 端，默认是 100% 的大小，正常需求下没问题。图片组  可以参考  hexo fluid 的方案，有需求时再看。</p></blockquote><p>可以参考的工具：<br><a href="https://github.com/tiann/markdown-img-upload">md-image-upload</a><br><a href="https://github.com/aleksey-rezvov/obsidian-local-images">将图片下载到本地</a><br><a href="https://github.com/Molunerfinn/PicGo">上传图片的服务</a><br><a href="https://github.com/renmu123/obsidian-image-auto-upload-plugin/blob/master/readme-zh.md">自动上传图片</a></p><hr><p>归属:</p><ul><li><a href="#">Post not found: 生产力建设/ob的使用问题 ob的使用问题</a></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>ob的使用问题</title>
    <link href="/longblog/posts/22_07_09_10_26_problems_in_using_ob.html"/>
    <url>/longblog/posts/22_07_09_10_26_problems_in_using_ob.html</url>
    
    <content type="html"><![CDATA[<p>这是解决 ob 的使用过程中，我遇到的问题 以及 解决的方式</p><ol><li><a href="#">Post not found: 生产力建设/解决ob的发布问题 解决ob的发布问题</a></li><li><a href="#">Post not found: 生产力建设/ob文件同步方案 ob文件同步方案</a></li><li><a href="#">Post not found: 生产力建设/解决ob的图床问题 解决ob的图床问题</a></li><li><a href="#">Post not found: 生产力建设/解决ob的任务管理问题 解决ob的任务管理问题</a></li><li><a href="#">Post not found: 生产力建设/解决ob的自动标签问题 解决ob的自动标签问题</a></li><li><a href="#">Post not found: 生产力建设/自动解决文章的图片问题 自动解决文章的图片问题</a></li><li><a href="#">Post not found: 生产力建设/ob文件同步方案 ob文件同步方案</a></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>ob</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ob文件同步方案</title>
    <link href="/longblog/posts/22_07_30_10_22_the_way_how_i_sync_files_for_ob.html"/>
    <url>/longblog/posts/22_07_30_10_22_the_way_how_i_sync_files_for_ob.html</url>
    
    <content type="html"><![CDATA[<p>ob 是基于本地存储的 md 编辑器 及 知识管理软件。 由于其文件存储在本地，当我们有 2 台以上的终端设备时，就希望某一台终端上的修改能够及时同步到其他终端。此时，就有文件同步的需求了。</p><p>我有两台 mac ，一台在公司，一台在家里，我希望两台的内容能够同步，这样，在公司(jia)里没写完的内容，回到家 ( gongsi ) 还能接着写。</p><p>方案有如下几个：</p><ul><li>官方提供的 sync 服务</li><li>远程硬盘挂载</li><li>远程同步</li></ul><p>下面分别看看。</p><h3 id="买官方的-sync-服务"><a href="#买官方的-sync-服务" class="headerlink" title="买官方的 sync 服务"></a>买官方的 sync 服务</h3><p>根据<a href="https://obsidian.md/sync">官网的信息</a>， 每个月 <code>$8</code> ( 我穷！我不配！)<br>能白嫖的，就一定不能付费！！！<br>(🙏🙏🙏 抱歉了，ob 的同学们，感恩提供的软件，下次一定)</p><h3 id="远程硬盘挂载"><a href="#远程硬盘挂载" class="headerlink" title="远程硬盘挂载"></a>远程硬盘挂载</h3><p>硬盘的物理位置不一定在本地，可以在云端的某个位置，因此当我们的几台电脑都挂载同一个远程的硬盘，就能实现文件的同步了，这有一个更为大家熟知的名字:   <code>网盘</code></p><p>目前实现网盘的方案有很多，例如：<code>ftp</code> 、<code>nfs</code>、<code>smb</code> 、<code>webdav</code> 。相对应的，只要我们提供对应的 service 就可以了。</p><p>提供服务的方式有两类:</p><ul><li>由自己在一台服务器上启动对应的 server<ul><li>nfs server 、smb server、 ftp server、webdav server 等</li><li>nextcloud、 owncloud、seafile、cloudreve 等</li></ul></li><li>直接使用一些云厂商提供的服务。<ul><li>aliyun nas 、七牛云、 坚果云 等</li></ul></li></ul><p>优势：</p><ul><li>直接的远程同步，支持 ( 近 )实时修改同步</li></ul><p>劣势:</p><ul><li>需要完全的网络通路，弱网体验较差，断网情况不可使用</li><li>自行搭建有门槛，云厂商提供的价格也不低</li></ul><h3 id="远程同步"><a href="#远程同步" class="headerlink" title="远程同步"></a>远程同步</h3><p>远程同步类似于保持多个存储库均保有一份数据，在一个地方的修改定期同步到各方。</p><p>可以有两个方案：</p><ul><li>基于 git 的版本管理和同步</li><li>基于 文件夹同步的方案</li></ul><p>如果采用 git 的方案，那么就要解决 pull 和 push 触发的问题，例如使用 crontab。或者使用手动操作的方式 <a href="obsidian://show-plugin?id=obsidian-git">ob git 插件</a></p><p>如果采用 文件夹同步的方案，例如 <code>syncthing</code> ，那么就需要看是否有 版本管理的需求。 (ps: 历史版本并不是仅能使用 git 方案，ob 本身是提供了 历史版本的机制的 )</p><p>git 可以白嫖 <code>gitee</code> 或 <code>github</code> 或 <code>coding</code> 或 <code>codeup</code> (阿里云效) ，都还 ok 。 自己搭的话，用 <code>gitea</code> 就 ok。</p><p>文件夹同步的话，自己搭的话可以用 <code>rsync</code> 或者 <code>syncthing</code> 均可。如果希望使用直接的服务，那么 坚果云、onedrive、icloud 等均可 (华为、小米 均有云空间产品，如果设备的生态比较统一的话，也比较 ok)。</p><p>这里就比较纠结了 😖</p><h3 id="我的需求"><a href="#我的需求" class="headerlink" title="我的需求"></a>我的需求</h3><p>一切的方案都应当以实际需求出发！</p><p>总结了一下，我对于 ob 存储的需求其实只有 1 个 能自动同步文件即可。</p><p>另外，<br>我有文件存储和备份的需求。<br>我有图片 gallery 的需求。<br>我有跨端的需求 (需要支持 android、mac、windows、linux)。<br>我有全下云的长远诉求。</p><p>综合来看，可以先选择在云端自建 syncthing ，各客户端也安装 <a href="/posts/undefined.html" title="syncthing">syncthing</a>。</p><h3 id="ob的其他方面"><a href="#ob的其他方面" class="headerlink" title="ob的其他方面"></a>ob的其他方面</h3><ol><li>我有很强的 <code>publish</code> 需求 <a href="#">Post not found: 生产力建设/解决ob的发布问题 解决ob的发布问题</a></li><li>我有很强的 <code>图床</code> 需求 <a href="#">Post not found: 生产力建设/解决ob的图床问题 解决ob的图床问题</a></li><li>我希望能够智能进行关键词提炼 <a href="#">Post not found: 生产力建设/解决ob的自动标签问题 解决ob的自动标签问题</a></li><li>可以参考这个项目 <a href="https://github.com/vrtmrz/obsidian-livesync">livesync</a></li></ol><hr><p>归属:</p><ul><li><a href="#">Post not found: 生产力建设/ob的使用问题 ob的使用问题</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>ob</tag>
      
      <tag>syncthing</tag>
      
      <tag>文件同步</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>解决ob的发布问题</title>
    <link href="/longblog/posts/22_07_30_09_45_how_to_handle_publish_issues_in_ob.html"/>
    <url>/longblog/posts/22_07_30_09_45_how_to_handle_publish_issues_in_ob.html</url>
    
    <content type="html"><![CDATA[<p>我的一个强需求是: 将 ob 上管理的这些文档，发布到 web 中。</p><ul><li>在发布的页面中，要解决 双向链接 的识别问题 [强需求]</li><li>在发布的页面中，要解决 悬浮阅读 的问题 [中强需求]</li><li>在发布的页面中，要解决 段落引用 的问题 [中等需求]</li><li>在发布的页面中，我需要有 知识关联图谱 存在 [弱需求]</li></ul><ul><li><input disabled="" type="checkbox"> 解决文档发布的多平台分发问题 <a href="/posts/undefined.html" title="TODOs">TODOs</a> #tasks <ul><li><input checked="" disabled="" type="checkbox"> 解决 github 的发布问题 ✅ 2022-07-16</li><li><input checked="" disabled="" type="checkbox"> 解决 blog 站 的发布问题 ✅ 2022-07-16</li><li><input disabled="" type="checkbox"> 解决 infoq 写作平台的发布问题</li><li><input disabled="" type="checkbox"> 解决 掘金 的发布问题</li><li><input disabled="" type="checkbox"> 解决 简书 的发布问题</li><li><input disabled="" type="checkbox"> 解决 CSDN 的发布问题</li><li><input disabled="" type="checkbox"> 解决 gitee 的发布问题</li></ul></li><li><input checked="" disabled="" type="checkbox"> 修改 hexo-backlink 的代码，以适应我的需求 <a href="/longblog/posts/22_07_30_09_45_how_to_handle_publish_issues_in_ob.html#hexo 解决双链问题" name="解决ob的发布问题" >解决ob的发布问题</a> ✅ 2022-07-16</li><li><input checked="" disabled="" type="checkbox"> 发布的文章中，有图片比没图片的阅读心理压力小，增加图片 ✅ 2022-07-16 <a href="#">Post not found: 生产力建设/自动解决文章的图片问题 自动解决文章的图片问题</a></li><li><input checked="" disabled="" type="checkbox"> 解决 悬浮阅读 的发布问题 ✅ 2022-07-30</li><li><input disabled="" type="checkbox"> 通过 CICD 完成现有平台的发布</li></ul><p>由于我的 博客 渲染，采用的是 hexo 体系，因此发布问题的解决，需要结合 hexo 的生态。</p><h3 id="hexo-解决双链问题"><a href="#hexo-解决双链问题" class="headerlink" title="hexo 解决双链问题"></a>hexo 解决双链问题</h3><p>最简单的方案是: <code>npm install hexo-backlink</code>， <a href="https://github.com/Cyrusky/hexo-backlink">项目地址</a></p><p>由于 社区的 hexo-backlink 不支持子路径，因此借鉴一下自己改改。</p><p>hexo 采取的插件机制，估计是用的类似于 <a href="https://github.com/bellard/quickjs">quickjs</a> 或者 v8 的沙盒，可由开发者自行开发插件，而 hexo 只需要把所有的插件代码组织起来，运行一遍，就能实现插件对内容的处理。沙盒技术可以参考 <a href="https://www.pudn.com/news/628f83bdbf399b7f351eb05d.html">虚拟机随谈</a> #插件机制 #quickjs #js引擎</p><p>考虑到将来可能会有比较多的 hexo 的适配问题，因此希望能更全面了解 hexo 的插件能<br>力，可以阅读 <a href="https://hexo.io/zh-cn/api/filter">hexo extend</a></p><p>不得不说，hexo 的文档写得是真的烂……<br>根本不知道每个阶段有什么参数，会影响什么……<br>最后，通过 两次 <code>before_post_render</code> 解决了全局变量获取的问题，虽然不怎么优雅，但算是能解决问题。</p><p>代码如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-comment">// data 为 </span><br><span class="hljs-comment">// [ </span><br><span class="hljs-comment">// [&#123;&#125;,&#123;&#125;], posts</span><br><span class="hljs-comment">// [] about,index</span><br><span class="hljs-comment">// ]</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">doreplace</span>(<span class="hljs-params">data</span>) </span>&#123;<br>  <span class="hljs-keyword">let</span> &#123; content, title &#125; = data;<br>  <span class="hljs-keyword">let</span> result = content.match(<span class="hljs-regexp">/\[\[.*?\]\]/g</span>);<br>  <span class="hljs-keyword">if</span> (result &amp;&amp; result.length &gt; <span class="hljs-number">0</span>) &#123;<br>    result.forEach(<span class="hljs-function">(<span class="hljs-params">linkName</span>) =&gt;</span> &#123;<br>      <span class="hljs-keyword">let</span> [realName, showName] = (linkName + <span class="hljs-string">&quot;&quot;</span>)<br>        .replace(<span class="hljs-string">&quot;[[&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br>        .replace(<span class="hljs-string">&quot;]]&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)<br>        .split(<span class="hljs-string">&quot;|&quot;</span>);<br>      <span class="hljs-keyword">let</span> anchor = <span class="hljs-literal">null</span>;<br>      [realName, anchor] = realName.split(<span class="hljs-string">&quot;#&quot;</span>);<br><br>      <span class="hljs-keyword">let</span> doc = hexo.locals.get(realName)<br>      <span class="hljs-comment">// console.log(&quot;path : &quot;, doc.path);</span><br>      <span class="hljs-built_in">console</span>.log(doc)<br><br>      <span class="hljs-keyword">if</span> (doc) &#123;<br>        <span class="hljs-keyword">let</span> path = getsubpath(doc.permalink)<br>        content = content.replace(<br>          linkName,<br>          <span class="hljs-string">`&lt;a href=&quot;<span class="hljs-subst">$&#123;path&#125;</span><span class="hljs-subst">$&#123;anchor ? <span class="hljs-string">&quot;#&quot;</span> + anchor : <span class="hljs-string">&quot;&quot;</span>&#125;</span>&quot; name=&quot;<span class="hljs-subst">$&#123;realName&#125;</span>&quot; &gt;<span class="hljs-subst">$&#123;showName || realName&#125;</span>&lt;/a&gt;`</span><br>        );<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        content = content.replace(<br>          linkName,<br>          <span class="hljs-string">`&lt;a href=&quot;/notpublish/index.html&quot; name=&quot;<span class="hljs-subst">$&#123;realName&#125;</span>&quot; &gt;<span class="hljs-subst">$&#123;showName || realName&#125;</span>&lt;/a&gt;`</span><br>        );<br>      &#125;<br>    &#125;);<br>  &#125;<br><br>  data.content = content;<br>  <span class="hljs-keyword">return</span> data;<br>&#125;<br><br><span class="hljs-comment">// 先统计</span><br>hexo.extend.filter.register(<span class="hljs-string">&quot;before_post_render&quot;</span>,<br>  <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params">data</span>) </span>&#123;<br>    <span class="hljs-keyword">if</span> (ignore(data)) &#123;<span class="hljs-keyword">return</span>&#125;<br><br>    hexo.locals.set(data.title, <span class="hljs-function">() =&gt;</span> data)<br>  &#125;, <span class="hljs-number">0</span>)<br><br><span class="hljs-comment">// 后替换</span><br>hexo.extend.filter.register(<span class="hljs-string">&quot;before_post_render&quot;</span>,<br>  <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params">data</span>) </span>&#123;<br>    <span class="hljs-keyword">if</span> (ignore(data)) &#123;<span class="hljs-keyword">return</span>&#125;<br><br>    doreplace(data)<br>  &#125;, <span class="hljs-number">0</span>)<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">ignore</span>(<span class="hljs-params">data</span>) </span>&#123;<br>  <span class="hljs-keyword">var</span> sourceFileName = data.source;<br>  <span class="hljs-keyword">var</span> ext = sourceFileName.substring(sourceFileName.lastIndexOf(<span class="hljs-string">&quot;.&quot;</span>)).toLowerCase();<br>  <span class="hljs-keyword">return</span> !data.publish || ext != <span class="hljs-string">&#x27;.md&#x27;</span>;<br>&#125;<br><br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getsubpath</span>(<span class="hljs-params">p</span>) </span>&#123;<br>  <span class="hljs-keyword">if</span> (p.match(<span class="hljs-regexp">/^(http|https):\/\//</span>)) &#123;<br>    <span class="hljs-keyword">let</span> u = <span class="hljs-keyword">new</span> URL(p)<br>    <span class="hljs-keyword">return</span> u.pathname<br>  &#125;<br>  <span class="hljs-keyword">return</span> p<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="解决-blog-站的发布问题"><a href="#解决-blog-站的发布问题" class="headerlink" title="解决 blog 站的发布问题"></a>解决 blog 站的发布问题</h3><p>方案： 采用 七牛云 的 qshell，发布到某个 bucket 下即可:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">qshell qupload quploadconfig.json<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs text">➜  blog git:(master) ✗ cat quploadconfig.json <br>&#123;<br>    &quot;src_dir&quot;            :   &quot;publish/&quot;,<br>    &quot;bucket&quot;             :   &quot;bloglong&quot;,<br>    &quot;key_prefix&quot;         :   &quot;&quot;,<br>    &quot;ignore_dir&quot;         :   false,<br>    &quot;overwrite&quot;          :   true,<br>    &quot;check_exists&quot;       :   false,<br>    &quot;check_hash&quot;         :   true,<br>    &quot;check_size&quot;         :   false,<br>    &quot;rescan_local&quot;       :   true,<br>    &quot;skip_file_prefixes&quot; :   &quot;test,demo,&quot;,<br>    &quot;skip_path_prefixes&quot; :   &quot;temp/&quot;,<br>    &quot;skip_fixed_strings&quot; :   &quot;.svn,.git,.vscode&quot;,<br>    &quot;skip_suffixes&quot;      :   &quot;.DS_Store&quot;,<br>    &quot;log_rotate&quot;         :   1,<br>    &quot;log_stdout&quot;         :   false,<br>    &quot;file_type&quot;          :   0,<br>    &quot;resumable_api_v2&quot;   :   false,<br>    &quot;resumable_api_v2_part_size&quot; : 4194304<br> &#125;<br><br></code></pre></td></tr></table></figure><h3 id="解决-github-发布问题"><a href="#解决-github-发布问题" class="headerlink" title="解决 github 发布问题"></a>解决 github 发布问题</h3><p>方案： 采用 docs 目录，作为 github pages 的入口。</p><p>目前可以先这样用着，之后觉得 <code>基于分支</code> 的发布方式更好的话，到时再调整一下就行。</p><h3 id="解决悬浮阅读的问题"><a href="#解决悬浮阅读的问题" class="headerlink" title="解决悬浮阅读的问题"></a>解决悬浮阅读的问题</h3><p>实际上，这是一个和发布本身没太多相关性的问题，甚至可以认为，这个功能通过加一个浏览器插件就能解决。</p><p>确实如此，因此通过在生成的 html 中，添加自定义的 js 引用来达到目的。代码比较粗糙，将来有更多更清晰的需求时，再进行统一改造。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs js"><span class="hljs-keyword">let</span> allowSubs = [<span class="hljs-string">&quot;/archives/&quot;</span>, <span class="hljs-string">&quot;/posts/&quot;</span>, <span class="hljs-string">&quot;/categories/&quot;</span>, <span class="hljs-string">&quot;/tags/&quot;</span>]<br><span class="hljs-keyword">let</span> matchpath = <span class="hljs-built_in">window</span>.location.pathname.match(<span class="hljs-regexp">/\/.*\//</span>) || []<br><span class="hljs-keyword">let</span> firstPath = matchpath[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">let</span> shouldOpen = <span class="hljs-literal">false</span><br><br><span class="hljs-comment">// 在允许的路径中</span><br><span class="hljs-keyword">if</span> (allowSubs.includes(firstPath) &amp;&amp; self == top) &#123;<br><span class="hljs-keyword">let</span> longiframeStyle = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&quot;style&quot;</span>)<br>longiframeStyle.innerText = <span class="hljs-string">`.long-frame&#123;width:500px;height:600px;border:none;position:absolute;z-index:9999;display:block;&#125;.frame-on&#123;display:block&#125;`</span><br><br><span class="hljs-keyword">let</span> longiframe = <span class="hljs-built_in">document</span>.createElement(<span class="hljs-string">&quot;iframe&quot;</span>)<br><br>longiframe.id = <span class="hljs-string">&quot;longframe&quot;</span><br>longiframe.classList.add(<span class="hljs-string">&quot;long-frame&quot;</span>)<br><br><span class="hljs-keyword">let</span> body = <span class="hljs-built_in">document</span>.getElementsByTagName(<span class="hljs-string">&quot;body&quot;</span>)[<span class="hljs-number">0</span>]<br><br>body.append(longiframeStyle)<br>body.append(longiframe)<br><br>runscript()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">runscript</span>(<span class="hljs-params"></span>) </span>&#123;<br><br><span class="hljs-keyword">let</span> longframe = <span class="hljs-built_in">document</span>.getElementById(<span class="hljs-string">&quot;longframe&quot;</span>); <span class="hljs-comment">// 目前只有一个 iframe</span><br><span class="hljs-built_in">this</span>.document.querySelectorAll(<span class="hljs-string">&quot;main a&quot;</span>).forEach(<span class="hljs-function"><span class="hljs-params">a</span> =&gt;</span> &#123;<br>a.addEventListener(<span class="hljs-string">&quot;mouseover&quot;</span>, <span class="hljs-function"><span class="hljs-params">e</span> =&gt;</span> showInIframe(longframe, e))<br>&#125;);<br><br><span class="hljs-built_in">this</span>.document.onclick = <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params">e</span>) </span>&#123;<br>shouldOpen = <span class="hljs-literal">false</span><br><span class="hljs-keyword">if</span> (longframe.src != <span class="hljs-string">&quot;&quot;</span>) &#123;<br>longframe.style.height = <span class="hljs-number">0</span><br>longframe.style.width = <span class="hljs-number">0</span><br>longframe.style.display = <span class="hljs-string">&quot;none&quot;</span><br>&#125;<br>&#125;;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">showInIframe</span>(<span class="hljs-params">iframe, e</span>) </span>&#123;<br><span class="hljs-keyword">if</span> (shouldOpen) &#123; <span class="hljs-comment">// 防止闪动</span><br><span class="hljs-keyword">return</span><br>&#125;<br>shouldOpen = <span class="hljs-literal">true</span><br><br><span class="hljs-keyword">let</span> src = e.target.href || <span class="hljs-string">&quot;&quot;</span><br><span class="hljs-keyword">if</span> (!src) &#123; <span class="hljs-keyword">return</span> &#125;<br><br><span class="hljs-comment">// 得去掉锚点，否则 fluid 主题的 scroll 会有问题</span><br>src = src.split(<span class="hljs-string">&quot;#&quot;</span>)[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">// 外链</span><br><span class="hljs-keyword">if</span> (src.trimStart().startsWith(<span class="hljs-string">&quot;http&quot;</span>)) &#123;<br><span class="hljs-comment">// 同源</span><br><span class="hljs-keyword">if</span> (<span class="hljs-built_in">window</span>.location.host == src.replace(<span class="hljs-regexp">/^(http|https):\/\//</span>, <span class="hljs-string">&quot;&quot;</span>).split(<span class="hljs-string">&quot;/&quot;</span>)[<span class="hljs-number">0</span>]) &#123;<br>iframe.onload = <span class="hljs-function"><span class="hljs-keyword">function</span> (<span class="hljs-params"></span>) </span>&#123;<br><span class="hljs-keyword">if</span> (!shouldOpen) &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">let</span> posx = e.pageX; <span class="hljs-keyword">let</span> posy = e.pageY;<br><br>iframe.style.top = posy + <span class="hljs-number">30</span> + <span class="hljs-string">&quot;px&quot;</span>;<br>iframe.style.left = posx + <span class="hljs-number">50</span> + <span class="hljs-string">&quot;px&quot;</span>;<br>iframe.style.width = <span class="hljs-string">&quot;500px&quot;</span><br>iframe.style.height = <span class="hljs-string">&quot;600px&quot;</span><br>iframe.style.display = <span class="hljs-string">&quot;block&quot;</span><br>&#125;<br>iframe.src = src<br>&#125;<br>&#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>现在悬浮阅读有一些不方便的地方：</p><ol><li>仅有一个预览框 (无法多个预览)</li><li>预览框的位置和大小太死板</li><li>仅适用于一级结构 (层级内是关闭的)</li><li>内嵌页面的格式不够友好 (header 部分太长)</li><li>无法自定义是否开启或关闭</li></ol><p>之后看情况解决下这些问题。【TODO】</p><h3 id="hexo-与-ob-的目录结构组织问题"><a href="#hexo-与-ob-的目录结构组织问题" class="headerlink" title="hexo 与 ob 的目录结构组织问题"></a>hexo 与 ob 的目录结构组织问题</h3><p>我目前的绝大多数文章，都是 技术相关 的文章，所以在写的时候，都是直接扔到一个统一的 <code>_posts</code> 目录下，因为这也是 hexo 直接的文章管理方式。 </p><p>随着文章范围的扩展，有一些其他类型的文章独立成体系，就不太方便统一扔到一个目录下，比如 <code>生产力建设</code> 下有一系列 ob 的文章。</p><p>从期望来看，一个目录，就对应着一个 <code>分类</code> 。<br>从 ob 和 hexo 的职责来看，ob 负责 <code>知识库管理</code> ，hexo 负责 <code>blog 渲染和发布</code>。</p><p>hexo 需要用到 ob 中的各种文档。 目前我的解决方式是，把原有的 hexo 下的 <code>source</code> 目录，软链到 ob 的根目录下。 这样的问题在于，想发布的文档，只能被拖到另一个目录下。 这是不友好的。</p><p>可以探索另一种方式，所有的文档全部放到 ob 中，把要发布的文章，统一加上一个特定的 meta 信息，要发布之前，用脚本跑一次，把相关文档 软链/复制 到对应的 hexo 目录下，然后再进行渲染和发布操作。</p><p>值得参考的文档：<br><a href="https://my-logseq-publish.vercel.app/#/page/logseq">基于 logseq 的文档</a><br><a href="https://github.com/oleeskild/obsidian-digital-garden">ob中的社区发布方案</a></p><hr><p>归属:</p><ul><li><a href="#">Post not found: 生产力建设/ob的使用问题 ob的使用问题</a></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>service mesh 是如何产生的？</title>
    <link href="/longblog/posts/22_06_16_how_service_mesh_born.html"/>
    <url>/longblog/posts/22_06_16_how_service_mesh_born.html</url>
    
    <content type="html"><![CDATA[<h3 id="演进过程"><a href="#演进过程" class="headerlink" title="演进过程"></a>演进过程</h3><p>最原始的应用，是由小团队直接负责的单体应用，直观的感受是，团队里的每个人，都对整个项目的技术选型具有影响力(姑且认为 每个人都是 “技术管理委员会” 的成员)。由于仅有一个大项目，也就基本不存在 “平台能力” 的概念。</p><p>单体项目逐渐膨胀，分层逐渐模糊、模块逐渐耦合、调用逐渐混乱、发布越发频繁、单个错误的影响面越发增大…… ，这就进入到所谓的 “单体地狱” 阶段。 解决办法之一，就是进行 服务化演进。</p><h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p>当单体服务拆分成多个服务后，从代码功能上，出现了一系列 与业务功能无关的 相似需求，例如 <code>服务发现</code>、<code>配置管理</code>、<code>负载均衡</code>、<code>健康检查</code>、<code>限流熔断</code>、<code>安全加密</code>、<code>协议转换</code>、<code>认证授权</code>、<code>链路追踪</code>、<code>通用监控</code> 等，我们将之统称为 “平台能力”。</p><p>在组织结构上，不同的服务 会被 不同的团队(人员) 所管理，服务的技术走向 会逐渐脱离原有的 “技术管理委员会” 的管理，逐渐出现 不同代码实现、不同库选型、不同框架选型、不同语言选型 等等情况。</p><p>当出现了一些上述的问题后，有识之士 就会想： <strong>“如何统一提供平台能力，解放业务专家们，让业务同学专注业务开发？”</strong></p><h3 id="解决问题的方向"><a href="#解决问题的方向" class="headerlink" title="解决问题的方向"></a>解决问题的方向</h3><h4 id="进程内方案"><a href="#进程内方案" class="headerlink" title="进程内方案"></a>进程内方案</h4><p>最直接的想法会是：根据不同语言，提供平台能力的 sdk。表现形式可能是： 工具库、应用框架。例如，统一的 web server 框架，在框架中提供 服务发现、负载均衡、监控、限流 等平台能力。</p><p>举个栗子，java 中的 <code>spring cloud</code> 提供了几大组件解决平台能力，如： <code>Eureka</code> 解决服务注册与发现、 <code>Ribbon</code> 解决负载均衡、 <code>Hystrix</code> 解决系统保护、 <code>Gateway</code> 提供 api 网关、 <code>Spring cloud config</code> 解决配置管理……</p><p>实际上，在单个语言体系下的各类 微服务框架 都是在解决这个问题。例如 golang 下的 <code>kratos</code>、<code>go-zero</code>、<code>go-micro</code>、<code>rpcx</code>、<code>kitex</code>、<code>go-kit</code> 等。(每个语言下都有一大堆)</p><p>但这种方式也存在 2 个主要问题： </p><ol><li>如果使用了多个语言体系，那么代码的维护成本就需要 *N 。例如，一个 负载均衡 的能力，如果有 python、java、golang、nodejs 4种语言，就需要对应的开发团队维护 4 套代码。难度之大，难以想象。  这个假设，其实是建立在一些 <code>大型团队</code>、<code>历史包袱重</code> 的前提下的。 对于大多数中小团队，服务端其实也只有一个语言体系，因此不失为一个不错的方案。</li><li>当平台能力不够稳定时(其实几乎很难稳定)，平台能力的升级需要业务代码同步更新，而推动业务同学进行库的升级，在稍大点的团队中是十分费心费力的。这也就是 代码耦合 带来的弊端。</li></ol><h4 id="进程外方案"><a href="#进程外方案" class="headerlink" title="进程外方案"></a>进程外方案</h4><p>在遇到上面的问题后，自然而然的想法，就是将一些平台能力进行抽离，在单独的进程中运行。独立部署后，使用一系列进程间通信的方式提供平台能力，就解决了 “语言绑定” 和 “代码绑定” 的问题。就这样，sidecar 模式诞生了！</p><p>Sidecar 在解决一些问题的同时，自然也引入了一些问题，主要有两个：</p><ol><li>通信方式的问题。</li><li>性能的问题。</li></ol><p>性能问题，从全局来看，由于多了一层进程外处理流程，不可避免地肯定会有性能损耗。解决办法自然就是尽量降低 sidecar 本身处理的资源耗用，包括 语言选型使用更高性能的语言(如 go、c++ 等)、代码层的架构设计和实现优化、扩展点使用更高性能的实现 (例如 grpc、wasm、golang、lua 等)。</p><p>通信方式 有两个走向：</p><ol><li>业务完全透明 的流量劫持 模式。</li><li>提供 http/grpc 的通信模式。</li></ol><h3 id="side-car-一览"><a href="#side-car-一览" class="headerlink" title="side car 一览"></a>side car 一览</h3><p>目前社区中比较出彩的 sidecar 解决平台能力的方案有： <a href="https://konghq.com/kong-mesh">kong(kuma)</a>、<a href="https://github.com/istio/istio">istio(envoy)</a>、<a href="https://github.com/traefik/mesh">traefik-mesh</a>、<a href="https://docs.nginx.com/nginx-service-mesh">nginx mesh (不开源)</a>、<a href="https://github.com/linkerd/linkerd2">linkerd</a>、 <a href="https://github.com/dapr/dapr">dapr</a> 、<a href="https://github.com/mosn/mosn">mosn</a>、<a href="https://github.com/megaease/easegress">easegress</a> 、<a href="https://github.com/hashicorp/consul">consul</a> 、<a href="https://github.com/openservicemesh/osm">osm(envoy)</a></p><p>从上面的项目可以看出，sidecar 大多都是从 <code>网关</code> 延伸而来的，这和 <code>平台能力</code> 的主体 <code>流量治理</code> 是分不开关系的。 基础能力是要做到 <code>服务发现</code>、<code>负载均衡</code>、<code>路由</code>、<code>安全</code>，延伸能力有  <code>限流熔断</code>、<code>可观测性(metrics、tracing)</code> 、<code>流量灰度</code>、<code>故障注入</code>、<code>认证授权</code>、<code>协议转换</code>、<code>管理平台</code> 。 </p><p>所有上面这些项目，有一个比较特殊： <code>dapr</code>，其他的基本都是 <code>网关</code>，而 dapr 被认为是一个 <code>应用运行时</code>，之所以 dapr 也被我列到这里，是因为他们有很多相似的地方，例如：<code>路由</code> 、<code>服务发现</code>、<code>负载均衡</code>、<code>可观测性</code> 等。 </p><p>现在看起来不一样的地方，例如 dapr 提供 <code>kvstore(state)</code>、<code>pubsub</code> 等，目标是提供与平台无关(不太相关) 的特定能力，例如 kvstore 就提供了 <code>DynamoDB</code> 、<code>redis</code>、<code>postgresql</code> 等实现。  从一部分 service mesh 的项目发展方向来看 (envoy、mson等)，流量代理的类型从原有的 <code>tcp</code>、<code>http</code>、<code>ws</code>、<code>http2</code>、<code>grpc</code> 等协议，扩展至 <code>redis</code>、<code>mongodb</code>、<code>dynamodb</code>、<code>kakfa</code>、<code>dubbo</code> 甚至是 自定义 协议(自有 rpc 协议) 的代理。 </p><p>有了这类中间件的代理，自然而然就会想着做些什么，比如 抽象一些通用业务能力，在代理中进行一些特定处理……， 这样，也就和 dapr 殊途同归了……</p><h3 id="趋势"><a href="#趋势" class="headerlink" title="趋势"></a>趋势</h3><p>可以看到一个趋势，随着技术需求的逐渐固化，开发模式逐渐靠近 <code>更加通用</code>、<code>更加透明</code>、<code>更加傻瓜式</code> 的设计理念，不论是各类开发框架提供的 <code>开箱即用 的开发套件</code>，还是类似于 grpc 提供的 <code>rpc client server 代码生成能力</code>， 亦或是各类脚手架工具提供的 <code>http 基础代码、orm 代码 一键生成</code> 能力，还是 基础设施层提供的 <code>流量代理side car</code> 流量治理能力，以及还未怎么普及的 <code>应用运行时</code>(eg: dapr)。</p><p>可以认为，基础设施所追求的一个目标是： <strong>极大地 降低业务人员的心智负担， 让业务人员 回归 业务开发！</strong> 。 </p><h3 id="我们可以做些什么？"><a href="#我们可以做些什么？" class="headerlink" title="我们可以做些什么？"></a>我们可以做些什么？</h3><p>为了实现这个目标，我们可以无所不用其极。例如：</p><ul><li>在一定程度上，选择一套完善的开发框架，能够完成业务开发的需要 (http server、log、api、orm)；</li><li>选择一套部署方案，能够快速准备环境，部署应用 (gitlab、k8s 等)；</li><li>选择一套通用基础设施，以及对应的管理平台 (mysql、redis、kafka 等)；</li><li>选择一系列通用工具，例如 功能测试、接口测试、压测、低代码平台、yapi、k8s 调试工具(devspace 等)、oauth平台、账户中心、rbac 等等；</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>实际上，<code>dapr</code> 的设计思想，和 <code>baas</code> 有着密不可分的联系。当我们盘点一下 baas 所提供的能力，例如 文档存储、事件通知 ，就会发现，和 dapr 提供的 state 管理、pub/sub(binding) 相对应。</p><h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><p><a href="https://philcalcado.com/2017/08/03/pattern_service_mesh.html">Pattern: Service Mesh</a><br><a href="https://developer.aliyun.com/article/785943">Dapr 在阿里云原生的实践-阿里云开发者社区</a><br><a href="https://mosn.io/blog/posts/multi-protocol-deep-dive/">MOSN 多协议机制解析</a><br><a href="https://www.servicemesher.com/envoy/intro/what_is_envoy.html">Envoy 是什么? · Envoy proxy中文文档</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>service</tag>
      
      <tag>service mesh</tag>
      
      <tag>istio</tag>
      
      <tag>linkerd</tag>
      
      <tag>sidecar</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>几种后端通信方式的杂谈</title>
    <link href="/longblog/posts/22_3_25_some_kinds_of_communication_in_backends.html"/>
    <url>/longblog/posts/22_3_25_some_kinds_of_communication_in_backends.html</url>
    
    <content type="html"><![CDATA[<h2 id="计算机的几种通信方式"><a href="#计算机的几种通信方式" class="headerlink" title="计算机的几种通信方式"></a>计算机的几种通信方式</h2><p>对于计算机而言，通信 是一件永远不可能被忽视的事情。通信 基本可以分为 进程内通信 和 进程间通信。 进程内通信的方式大致有： <code>① 共享内存</code>  <code>② 变量传递</code>。进程间通信又需要分为 在同一操作系统上 和 在不同操作系统上，同一操作系统上的进程间通信主要有 <code>① 共享内存</code>  <code>② 共享存储</code> <code>③ 管道(命名)</code> <code>④ 信号量</code> <code>⑤ 消息队列</code> <code>⑥ socket</code> 通信。不同操作系统上，则只能使用 <code>socket</code> 通信。</p><p>实际上，从上面可以看出，除了 <code>信号量</code> 的通信方式比较独特外，其他的通信方式都是基于 <code>共享</code> 或 <code>传递</code> 的进行。只是 共享的方式 和 传递的方式 有所差别。</p><h3 id="进程内通信"><a href="#进程内通信" class="headerlink" title="进程内通信"></a>进程内通信</h3><p>在 进程内通信时，共享内存 是可以被特定编程语言直接使用的内存格式，因此效率非常高；在进程间的共享内存上，内存是最底层的共享方式，因此内存格式需要自己约定，也就意味着所有传递的值 需要经过一定的格式转换，也就是 序列化的过程。</p><p>在 进程内通信时，变量传递可以分为 值传递 和 引用传递 ，所有的操作都是编程语言做的，我们只管使用即可。但在 进程间的消息传递时，我们则需要自己处理 消息格式 的问题，也即是 序列化和反序列化 的过程。</p><p>上述的这些通信方式，实际上是很通用的模型，不仅在操作系统层被使用，在应用层，我们基于这些模型造了很多工具或软件系统。例如，共享内存 我们有 <code>redis</code> 、<code>memcache</code> 等，共享存储 我们有 <code>mysql</code>、<code>etcd</code>、<code>mongodb</code> 等等，管道 我们有 <code>redis</code> ，消息队列 我们有 <code>kafka</code>、<code>zeroMQ</code> 、<code>rabbitMQ</code> 等等，甚至有一些 消息队列的通用协议，例如 <code>MQTT</code>、<code>AMQP</code> 等等。</p><h3 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h3><p>最繁荣的进程间通信方式，实际上还是 <code>socket</code> 通信，socket 本身只是一个接口定义，不过这个接口定义太通用了，任何消息传递几乎都可以套用这个接口，无论是 <code>文件</code>、<code>网络</code> 还是 <code>内存</code> 。</p><h2 id="服务端的常见通信方式"><a href="#服务端的常见通信方式" class="headerlink" title="服务端的常见通信方式"></a>服务端的常见通信方式</h2><p>对于服务端开发而言，最常用的还是基于 网络 的 socket 编程，最底层自然都依赖 TCP/UDP，在应用层上，我们有非常多的协议，例如 <code>http</code> 、<code>http2</code> 、 <code>http3</code> 、<code>websocket</code>、 <code>MQTT</code> 以及各种小领域的协议，其实，所有的协议，都是对特定领域的通信内容的通用抽象，例如，http 是一个很常用的互联网请求协议，包含 请求行 、请求头 、请求体 ，一般认为 http 是一个 文本协议，实际上这指的是其 序列化方式，文本内容直接通过 ascll [待验证] 进行传输，背景是 http 协议出生在 文本内容共享浏览 的互联网初始定位 的时代。</p><p>后来发现 http 的传输效率不高，于是 http2 做了 压缩消息头 、二进制分帧传输、连接复用 的优化。在后来，认为基于 tcp 的传输效率还是有点低，而现代基础设施整体是比较好的，因此基于 udp 在应用层做了一些消息质量保证的操作，用于提升传输效率。</p><p>其实 http 系列协议，都可以看做是在 http1.1 的协议约定基础上，在传输层做优化。 那么，是否有其他通过优化协议本身内容的方式呢？其实其他协议都是在做这件事。例如，<code>websocket</code>，建立在 tcp 之上，使用非常简洁的控制帧，通信消息全在消息体当中。还有一些追求极致性能的协议，甚至直接建立在 TCP 上做应用层消息传输，例如 kafka 的通信协议。</p><p>从 自定义消息结构 这个看待协议的角度出发，我们甚至可以认为 rpc 才是真正的一切协议的源头，可以想象曾经有各类自定义的 rpc 格式，例如 <code>samba</code>、<code>nfs</code>、<code>ssh</code> 等等，当他们具有一定的名气后，大家就把他们从 自定义 rpc 协议 的认识中拎出来，直接用他们的名字代替。也就是说，我们现在所自定义的各种 rpc 协议，当他们具有一定名气后，就可以拥有自己的 名字 。</p><p>阐述完各类协议的基本情况后，我们来聚焦一下 <code>http</code>、<code>http2</code>、<code>grpc</code>、 <code>ws</code> ，看一下他们的关系。</p><h3 id="几种协议的区别认识"><a href="#几种协议的区别认识" class="headerlink" title="几种协议的区别认识"></a>几种协议的区别认识</h3><p>Http 的全名叫 超文本传输协议，是互联网最常用的协议，分为 请求行 (method + path)、请求头 (header) 、请求体 (body)，请求体可以是二进制数据(经过编码传输)。</p><p>http2 是 http 的升级版，所有请求格式延续了 http 的格式，对上层应用来说整体没啥差别(如果仅当做http来用)，但是也提供了 服务端推送、stream 等功能。一定程度上，我们可以认为，http2 是 http 的 传输层封装 (充当 transport 层)。</p><p>grpc 是把 http2 当做传输层 (transport 层)。其他特性是自行实现的，例如 <code>interceptor</code>、<code>resolver</code>、<code>balancer</code>、<code>auth</code>、<code>log</code>、<code>status</code>(状态码)、<code>stats</code>(监控)。实际上，我们不能把 grpc 当做一种协议，而是一种 rpc 框架 (类似于 http 框架)，协议 有特定格式 或 接口约定，而 grpc 是用于生成特定 server 和 client 的一整套工具。</p><p>ws 是直接在 tcp 之上的一层通信协议，特点是 轻量、连接保持，ws的想象空间很大，实际上，如果你愿意，甚至可以使用 ws 作为 http 的 transport 层，也可以把 ws 作为 mqtt 的 transport 层，也可以把 ws 作为 grpc 的传输层。</p><p>一些情况下，我们可以认为，一个协议 或者 一个框架，为什么选择了某项技术 而并不是 其他技术，是由于 生态 决定的，例如为什么 grpc 选用了 http2 而不是直接的 tcp 连接？为什么后端服务调用大家使用 grpc 而不是 手写 http？为什么后端不用 ws 通信？</p><h3 id="ws的特点"><a href="#ws的特点" class="headerlink" title="ws的特点"></a>ws的特点</h3><p>ws 现在的主要场景在前后端的即时消息上，这得益于 ws 的 状态保持 的特性，那么，我们是否可以基于这个特性，做更多的事情？</p><p>比如，① 基于 ws 的 http 协议转换、② 基于 ws 的 grpc 协议转换、③ 基于 ws 的自定义 rpc 框架、④ 基于 ws 的自定义框架。</p><p>对于 ①，应用场景较少，如果是为了传输性能，那么使用 http2 就能解决，而且 http2 的生态更好。<br>对于 ②，可以，但目前已经有了基于 http 的 grpc 协议转换，使用 http2 的情况下，性能也没啥问题。<br>对于 ③，可以，但要考虑生态问题，这基本意味着重新实现整套 grpc 的各模块。<br>对于 ④，可以，但目前已经有一些 ws 框架，例如 socket.io，要考虑清楚为什么需要一套新的框架。</p><h3 id="我对于当前-http-、http2、grpc、ws-方式的基本判断"><a href="#我对于当前-http-、http2、grpc、ws-方式的基本判断" class="headerlink" title="我对于当前 http 、http2、grpc、ws 方式的基本判断"></a>我对于当前 http 、http2、grpc、ws 方式的基本判断</h3><ol><li>http 有完善的接口定义方式 (<code>openapi</code>)，http2 甚至 http3 在性能上和将来的生态上也非常不错。目前没有看到好的基于 http 接口定义 方式自动生产 server 和 client 的工具。</li><li>grpc 有完善的接口定义方式，性能上和生态上很不错，有自动生成代码的工具链。前端调用不支持直接通信，需要经过 http 协议再转一次(浏览器端 或 proxy 端)。</li><li>ws 有一定的生态支持，ws 的状态保持在一些场景下是非常不错的特性。ws 没有自动生成代码的工具。</li></ol><h3 id="ws有什么特殊的价值？"><a href="#ws有什么特殊的价值？" class="headerlink" title="ws有什么特殊的价值？"></a>ws有什么特殊的价值？</h3><p>ws 有两个特性： ① 连接保持  ② 协议轻量 。另外，ws 的生态不错 (主要指浏览器的特殊支持)。<br>ws 在一些需要长链接的场景下，非常有价值，比如： ① 协商缓存内容，② 服务端缓存内容(eg: 权限)</p><p>如果解决 ws 的 ① 重连状态保持  ② http 降级  ③ 代码自动生成  ④ 开发模式  ⑤ 测试工具包 问题，那么 ws 不失为一个很好的通信工具。</p><h2 id="代码生成的思考"><a href="#代码生成的思考" class="headerlink" title="代码生成的思考"></a>代码生成的思考</h2><p>代码生成是一个非常好的思路，可以保证代码的统一性，减少不规范的地方，可维护性更高。现在可以看到，在 client 和 server 代码生成上，grpc 做的是最好的，生态也比较开放，在这个基础上可以开发一些自己需要的功能。</p><p>Go-zero 框架是自己实现的一套语法解析并形成特定代码，提供了模板化的方法生成代码，也和 grpc 一样提供了自定义插件的方式，看上去野心不小。</p><p>Go-kratos 则是接入 grpc 的生态，通过扩展生成代码的方式，接入了自己的 http 和 rpc。</p><p>Go-frame 在接口自动化代码生产上没有动作，只是在 脚手架工具 中简化了 对 grpc 代码生成的命令。</p><p>除了上面说到的 基于接口文档 自动化生成 server 及 client 代码外，还有一些其他常用的可生成的代码：</p><ol><li>基于 数据库表 生成 结构体、orm、基本 crud 代码。</li><li>基于 接口定义，生成前端 client 代码。</li><li>生成部署侧的脚本或包 (docker、k8s、devspace等)</li></ol><p>第 1 点中的 model 生成，go-frame 和 go-zero 都有做。 第 2 点目前只有 go-zero 做了一些，grpc 也有一些。 第 3 点都有动作。</p><p>另外 ，补充一嘴，数据库的结构体生成 是可以 正反使用的，例如，通过 orm，生成数据库表，同样也可以通过 数据库表，生成 orm，这点可以参考 <a href="https://blog.longalong.cn/posts/22_03_21_%E5%85%B3%E4%BA%8E%E5%9F%BA%E4%BA%8E%E6%8E%A5%E5%8F%A3%E5%AE%9A%E4%B9%89%E7%9A%84%E5%BC%80%E5%8F%91%E6%B5%81.html">关于基于接口定义的开发流</a> 最后的链接。</p><h3 id="一个疑惑"><a href="#一个疑惑" class="headerlink" title="一个疑惑"></a>一个疑惑</h3><p>按理，http 才是互联网下的王者，那么，为什么很少见到基于 http 的 接口定义文档 自动生成代码的工具呢？</p><p>实际上，相比于 protobuff 的 proto3 这种新的 DSL ，我们使用已有语言的成本可能更低，例如 基于 yaml 或者 基于 json 的，比如使用 openapi 的接口定义。甚至，使用一门我们熟悉的语言做接口描述，例如 js，然后代码生成则直接使用 js 进行拼接 ( 或模板渲染 )。</p><p>这个可以找找是否有相关的工具，如果没有，可以自己实现一个。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>杂七杂八写了一些自己的想法，很多表述不一定很精准，但思路确实还是有可参考性的，可以经常回味一下。</p>]]></content>
    
    
    
    <tags>
      
      <tag>communication</tag>
      
      <tag>backend</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记一次有状态服务的负载均衡方案探索</title>
    <link href="/longblog/posts/22_3_23_a_record_of_balancing_stateful_service_explore.html"/>
    <url>/longblog/posts/22_3_23_a_record_of_balancing_stateful_service_explore.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>我们的服务是有状态服务，服务在提供对外访问时，需要负载到特定节点。</p><h2 id="基本方案"><a href="#基本方案" class="headerlink" title="基本方案"></a>基本方案</h2><p>一般来说，这种特定节点的负载均衡有两种基本方案：</p><ol><li>重定向</li><li>代理模式</li></ol><p>一起来看一下几个有状态服务的集群处理方式：</p><ul><li>Redis 在 6.0 以前是直接的采用 重定向 的方式，6.0 也提供了集群内代理的模式。 </li><li>Redis 的 codis 版集群，采用的是 代理模式。</li><li>Mycat 数据库代理采用的是 代理模式。</li><li>Mongodb cluster 采用的是 mongos 代理。</li><li>Kafka 采用的是客户端自定义的负载均衡方式，整体来看是 重定向方式 (根据 partition 的位置决定地址)。</li></ul><p>基本可以认为，负载均衡的这两种策略没有太大的优劣之分，只要实现好 client，对业务方来说，区别不大。</p><p>由于代理模式对机器资源的消耗更多，并且将来维护更加复杂，于是我选择先采用 重定向 的策略，这需要有两方面改动：</p><ol><li>所有节点均知道特定的 key 应该到哪一个具体的 节点。</li><li>返回的重定向数据，能够达到正确的节点。</li></ol><p>下面分别解决这两个问题。</p><h2 id="解决负载信息同步问题"><a href="#解决负载信息同步问题" class="headerlink" title="解决负载信息同步问题"></a>解决负载信息同步问题</h2><p>在业务侧，需要通过类似于 注册中心的机制，用于确定不同的 key 对应的 节点地址。这个注册中心有两种可供参考的模式： ① 无状态的包，所有状态通过中央存储( eg: redis/etcd ) 进行共享。② 状态交由特定的服务进行维护，其他 client 通过调用这个服务的接口获取信息。</p><p>第一种方案，类似于 k8s 的设计，所有源信息全在 etcd 中，各模块均通过监听 etcd 中的元信息变化做出自己的动作，这样做的好处是 轻量化，仅需要约定好数据结构即可，不用维护单独的服务，但为避免误用，需要提供 SDK。</p><p>第二种方案，类似于 mongodb 中的 config-server ，所有元信息交由 config-server 维护，其他节点 (mongos)通过本地缓存的方式提升性能。 这种方式的好处在于 权责分明，在没有太多精力维护 sdk 的情况下，这种方式更不容易出错。</p><p>其实，也可以认为还有第三种方案： 去中心化方案。类似于 redis 的集群通信方式，每个节点都存着一份整个集群的信息，并且通过一定的方式保证集群内数据一致性。但这种方式的实现更加复杂，也没有看到有什么更大的价值，暂不考虑。</p><p>在我的基本实现中，采用 抢占式 的模式，用 redis 做状态同步，整个流程类似于 “分布式锁” 的过程，可以达到负载到特定节点的目的，但整体比较粗糙，将来的可扩展性也不是很好。</p><p>不过值得参考的是，该实现中，采用了 redis 的 watch 机制，可以在各节点做本地缓存，有更新后也能更新缓存。这是一个很不错的技术点。</p><p>在将来要实现的版本中，应当是由一个服务来做负载均衡的策略，包括收集节点状态、新节点启动、老节点清理、数据迁移 等操作。 这部分可以更多参考 mongodb 的 config-server 相关设计。</p><p>在保证了注册中心机制后，就是网络路由问题了。</p><h2 id="解决-nginx-定向路由问题"><a href="#解决-nginx-定向路由问题" class="headerlink" title="解决 nginx 定向路由问题"></a>解决 nginx 定向路由问题</h2><p>由于服务是在内网中，也不能将内网服务的 ip 直接暴露在公网上，因此，要有从公网路由到内网特定节点的能力。</p><p>我们目前采用的是 k8s 的部署方式，网关处使用 nginx-ingress 进行路由 和 负载均衡。nginx-ingress 默认提供了 轮询、加权、hash、一致性hash 的负载均衡策略，且 hash 函数不是我们能指定的。因此，这些策略无法满足我们的需求。</p><p>不过 nginx-ingress 提供了自定义负载均衡策略的方式(通过 lua 脚本)，也就意味着我们能够自定义负载均衡策略。</p><p>以下是基本实现：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-comment">-- file longbalancer.lua</span><br><span class="hljs-keyword">local</span> util = <span class="hljs-built_in">require</span>(<span class="hljs-string">&quot;util&quot;</span>)<br><br><span class="hljs-keyword">local</span> string_format = <span class="hljs-built_in">string</span>.<span class="hljs-built_in">format</span><br><span class="hljs-keyword">local</span> ngx_log = ngx.<span class="hljs-built_in">log</span><br><span class="hljs-keyword">local</span> INFO = ngx.INFO<br><span class="hljs-keyword">local</span> _M = &#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.new</span><span class="hljs-params">(self, backend)</span></span><br>  <span class="hljs-keyword">local</span> o = &#123;<br>    name = <span class="hljs-string">&quot;longbalance&quot;</span><br>  &#125;<br>  o.addrs, o.addrList, o.nums = util.get_addrs(backend.endpoints)<br>  o.eps = util.get_nodes(backend.endpoints)<br>  o.nowLen = <span class="hljs-number">0</span><br><br>  <span class="hljs-built_in">setmetatable</span>(o, <span class="hljs-built_in">self</span>)<br><br>  <span class="hljs-built_in">self</span>.<span class="hljs-built_in">__index</span> = <span class="hljs-built_in">self</span><br>  <span class="hljs-keyword">return</span> o<br><span class="hljs-keyword">end</span><br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.sync</span><span class="hljs-params">(self, backend)</span></span><br><br>  <span class="hljs-keyword">local</span> eps = util.get_nodes(backend.endpoints)<br>  <span class="hljs-keyword">local</span> changed = <span class="hljs-keyword">not</span> util.deep_compare(<span class="hljs-built_in">self</span>.eps, eps)<br>  <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> changed <span class="hljs-keyword">then</span><br>    <span class="hljs-keyword">return</span><br>  <span class="hljs-keyword">end</span><br><br>  ngx_log(INFO, string_format(<span class="hljs-string">&quot;nodes have changed for backend %s&quot;</span>, backend.name))<br><br>  <span class="hljs-built_in">self</span>.addrs, <span class="hljs-built_in">self</span>.addrList, <span class="hljs-built_in">self</span>.nums= util.get_addrs(backend.endpoints)<br>  <span class="hljs-built_in">self</span>.eps = eps<br>  <span class="hljs-built_in">self</span>.nowLen = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">end</span><br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.balance</span><span class="hljs-params">(self)</span></span><br>  <span class="hljs-keyword">local</span> balance_by = ngx.var[<span class="hljs-string">&quot;balance_by&quot;</span>]<br>  <span class="hljs-keyword">if</span> balance_by == <span class="hljs-literal">nil</span> <span class="hljs-keyword">then</span><br>    balance_by = <span class="hljs-string">&quot;$docdoc&quot;</span><br>  <span class="hljs-keyword">end</span><br><br>  <span class="hljs-keyword">local</span> balance_val = util.lua_ngx_var(balance_by)<br><br>  ngx_log(INFO, string_format(<span class="hljs-string">&quot;balance key is : %s, val is : %s&quot;</span>, balance_by,balance_val))<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-built_in">self</span>.<span class="hljs-built_in">find</span>(<span class="hljs-built_in">self</span>, balance_val)<br><span class="hljs-keyword">end</span><br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.getnext</span><span class="hljs-params">(self)</span></span> <br>    <span class="hljs-keyword">local</span> addr = <span class="hljs-built_in">self</span>.addrList[<span class="hljs-built_in">self</span>.nowLen]<br><br>    <span class="hljs-built_in">self</span>.nowLen = <span class="hljs-built_in">self</span>.nowLen + <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">self</span>.nowLen == <span class="hljs-built_in">self</span>.nums <span class="hljs-keyword">then</span><br>      <span class="hljs-built_in">self</span>.nowLen = <span class="hljs-number">0</span>    <br>    <span class="hljs-keyword">end</span><br><br>    <span class="hljs-keyword">return</span> addr<br><span class="hljs-keyword">end</span><br><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.find</span><span class="hljs-params">(self, balance_val)</span></span><br>  <span class="hljs-keyword">local</span> addr<br><br>  <span class="hljs-keyword">if</span> balance_val == <span class="hljs-literal">nil</span> <span class="hljs-keyword">or</span> balance_val == <span class="hljs-string">&quot;&quot;</span> <span class="hljs-keyword">or</span> balance_val == <span class="hljs-number">0</span> <span class="hljs-keyword">then</span><br>    addr = <span class="hljs-built_in">self</span>.getnext(<span class="hljs-built_in">self</span>)  <br>    <span class="hljs-keyword">return</span> addr<br>  <span class="hljs-keyword">end</span><br><br>  addr = <span class="hljs-built_in">self</span>.addrs[balance_val]<br>  <span class="hljs-keyword">if</span> addr == <span class="hljs-literal">nil</span> <span class="hljs-keyword">then</span><br>    addr = <span class="hljs-built_in">self</span>.getnext(<span class="hljs-built_in">self</span>)  <br>  <span class="hljs-keyword">end</span><br><br>  <span class="hljs-keyword">return</span> addr<br><span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">return</span> _M<br><br><span class="hljs-comment">-- file util.lua</span><br><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">_M.get_addrs</span><span class="hljs-params">(endpoints)</span></span><br>  <span class="hljs-keyword">local</span> addrs = &#123;&#125;<br>  <span class="hljs-keyword">local</span> addrList = &#123;&#125;<br>  <span class="hljs-keyword">local</span> nums = <span class="hljs-number">0</span><br><br>  <span class="hljs-keyword">for</span> _, endpoint <span class="hljs-keyword">in</span> <span class="hljs-built_in">pairs</span>(endpoints) <span class="hljs-keyword">do</span><br>    addrs[endpoint.address] = endpoint.address .. <span class="hljs-string">&quot;:&quot;</span> .. endpoint.port<br>    addrList[nums] = endpoint.address .. <span class="hljs-string">&quot;:&quot;</span> .. endpoint.port<br>    nums = nums + <span class="hljs-number">1</span><br>  <span class="hljs-keyword">end</span><br><br>  <span class="hljs-keyword">return</span> addrs, addrList, nums<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>然后在 balancer.lua 文件中导入 longbalancer 即可。</p><p>另外，为了服务能够使用正确的负载均衡策略，需要在 服务的 ingress 中添加如下注解</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">nginx.ingress.kubernetes.io/configuration-snippet: |<br>      set $docdoc $arg_insip; # 设置负载均衡参数<br>nginx.ingress.kubernetes.io/load-balance: longbalance  # 选择负载均衡策略<br></code></pre></td></tr></table></figure><p>自此，nginx 拥有了根据特定的参数进行定向路由的能力。<br>[鼓掌 ！ 👏]</p><p>这里实际上是有优化空间的，有两个方向：</p><ol><li>添加 缓存 =&gt; documentID : insip 在nginx进行缓存，没有传 insip 的参数时，先通过缓存判断，没有再走轮询。</li><li>直接接入向 config-server 访问的能力，在网关层直接定位到确定的节点，而不是靠重定向。</li></ol><p>各有优劣，之后再做分析</p>]]></content>
    
    
    
    <tags>
      
      <tag>load balance</tag>
      
      <tag>stateful</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>grpc在k8s中的负载均衡问题</title>
    <link href="/longblog/posts/22_3_23_grpc_balancing_problem_in_k8s.html"/>
    <url>/longblog/posts/22_3_23_grpc_balancing_problem_in_k8s.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>因为 grpc 是基于 http2 的通信，而 http2 对单个 endpoint 默认仅建立一条 TCP 连接，这就导致在 k8s 中，一个 service 默认仅会有一条 grpc 连接，并且，对于该 grpc 的请求，也都会集中到其中一个 pod 上。</p><p>尽管 k8s 的 service 本身有着 round robin 的负载均衡方式，但那都是建立在 “多次建立连接” 的基础上，对于已经建立连接后，基于 四层网络通信 的 TCP，是无法做到负载均衡的。<br>这个问题在我们当前的服务中也存在，两个服务间通过 service name 进行调用时，则会出现负载不均问题。</p><p>之前一直没有太重视这个问题，主要原因在于 每个服务都会有多个 pod ，那么多个 pod 调用 多个 pod 时，一定程度上进行了负载均衡。但是这种负载均衡很不稳定，比较容易出现连接集中到其中几个 pod 上的情况，因此，需要用其他方式解决。</p><h2 id="解决过程"><a href="#解决过程" class="headerlink" title="解决过程"></a>解决过程</h2><p>经过阅读 grpc 代码，发现 grpc 本身有提供一定的机制解决负载均衡的问题，只是默认的方式在 k8s 中没有那么友好。<br>这其中涉及到 两个主要概念： resolver、balancer(picker)</p><p>resolver的作用，是解析一个服务地址对应多少 ip 地址，默认的方式是 passthrough，意味着透传服务地址，交由更底层的 transport 去处理。</p><p>还有一些其他的 resolver： ① DNS resolver  ② Manual  resolver ③ unix resolver</p><p>其中，DNS resolver 可以解析 DNS 中所挂载的 backend ips，这对于传统的基于 DNS 做负载均衡的方案比较好用，k8s 中的 statefulset 也可以大致基于这种模式。</p><p>Manual resolver 则是手动设置 backend ips，如果有自己的服务注册与服务发现机制，则用这种方式就比较方便。</p><p>Balancer 的作用，是从 resolver 解析的对应的 ip 地址池 选择特定的连接，其中核心的职能由 picker 承担，grpc 提供了大量的负载均衡策略，并且支持自定义策略，默认是 pick_first，还有一些例如：轮询、加权轮询、grpc远程lb、优先、rls(自适应？)。 甚至，grpc 提供了一些集群负载均衡的策略，例如一致性hash、CDS LB？等。</p><p>从上面分析来看，我们至少有这么两类解决方案：</p><ol><li>通过使用 grpc 本身提供的 resolver 机制 和 balancer 机制，实现基于 k8s 的服务发现机制(通过client-go 进行封装)，则能比较优雅地解决这个问题。</li><li>通过在 client 端实现 conn-pool 的方式，类似于通过多次 dial 的方式创建多个连接，然后自行实现一些 负载均衡的策略，例如 round-robin 或者随机，或者 sticky 的机制等。这个方案实现起来，从当前的技术复杂度上来看是最低的。但有三个问题： ① service 本身一定要更加“随机”，如果是 sticky 类机制，则此方式失效(k8s service默认是轮询机制)。 ② 每个遇到 grpc 负载均衡问题的 client ，都要改动其 client 包，以支持获取 conn 的方式(或者进行多一层封装，github.com/shimingyah/pool 就是采用的这种方式) 。③ 连接是在初始化过程建立的，初始化之后通过扩容形成的新pod很难被加入到连接池中。</li></ol><p>另外，服务网格也有一定的方式解决这个问题，这是代理工具做的优化，例如 envoy 和 nginx 都有针对 grpc 的优化，但这个方案太重(我们目前没有使用服务网格)，暂不考虑。</p><p>从目前来看，我认为第一种方式更优雅，对业务的侵入也更小，仅需要修改 grpc 的 dial options，以及导入一个包即可。 这个包的设计，最好将 服务发现 独立出来，专门用于 k8s 中的服务发现与动态监听。</p><p>值得一提的是，在 go-zero 以及 go-krotas 中，均有解决这个问题的方案，均是通过上述添加 k8s resolver 的方式解决的。如果要自行解决，可以参考。</p><h2 id="坑点"><a href="#坑点" class="headerlink" title="坑点"></a>坑点</h2><ol><li>如果要采用 k8s 的 list endpoints 和 watch endpoints 机制，则需要添加特定的 role，绑定相关的权限，否则会 panic。</li><li>在使用 k8s 的 sdk 时，要注意版本对应，否则可能会遇到奇怪的问题，甚至会有 golang 编译版本的问题 (最新甚至要求 1.17)。</li></ol><p>另外可以参考：<br><a href="https://zhuanlan.zhihu.com/p/258326212">Kubernetes中gRPC Load Balance分析和解决</a><br><a href="https://segmentfault.com/a/1190000004492447">负载均衡算法及手段</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>grpc</tag>
      
      <tag>load balance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于基于接口定义的开发流</title>
    <link href="/longblog/posts/22_03_21_develop_flow_based_on_interface_definition.html"/>
    <url>/longblog/posts/22_03_21_develop_flow_based_on_interface_definition.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>之前做前端开发，需要依赖后端同学的接口文档，涉及到一些老接口的时候，经常出现接口信息疏于维护的情况，然后找这个找那个的，依然很难做到让接口信息完整，当时就在想，为什么不再要修改一个接口的时候，把接口文档顺便维护了呢？心中甚是鄙夷。</p><p>后来做后端开发，经常出现一些要求快速完成进行联调的情况，更甚至有临时改变一些功能的情况，自己可能顺手就加上了，然后上到测试环境让前端同学调一下，然后……就没有然后了，因为运行起来没什么问题，也没有谁让把接口文档补全，就这样搁置了。</p><p>再后来后端开发也要兼顾接口测试，接口测试 的用例梳理，是基于接口定义，一方面找到接口的参数边界，另一方面测试完整的场景，这时候才发现，之前的接口文档写得是多么简陋。<br>于是，就开始探索更好的后端接口开发工作流。</p><h2 id="灵感来源及畅想"><a href="#灵感来源及畅想" class="headerlink" title="灵感来源及畅想"></a>灵感来源及畅想</h2><h3 id="灵感1"><a href="#灵感1" class="headerlink" title="灵感1"></a>灵感1</h3><p>接口文档的维护大体上分为两派，① 接口文档应当跟随代码，例如 swagger  ② 接口文档管理在专门的接口平台，例如 yapi。 这两派都有其拥护者。目前看到的，市场上很多企业还是走的第 ② 条路，主要原因，可能还是对后端人员来说上手简单，有好用的 UI，写接口就点点点几下；再加上给前端同学交付比较方便(仍一个链接过去)，带有 mock 功能，可能还有一些简单的 接口测试 功能，用起来很流畅。 用这种方式的一个弊端，可能就是 <code>容易疏于维护</code>。</p><p>基于代码的方案基本就是 swagger 的方式，在定义接口时，用 <code>注释</code> 或者 <code>装饰器</code> 等方式，将接口的元信息嵌入到代码中，这样就可以做到修改代码的时候，就可以顺便修改接口信息。 但这样的弊端就是： ① 部署不方便，yapi 可以独立部署，很稳定，基于代码的则可能随意改变，对使用方而言不够稳定。 ② mock 、test 等功能较弱，有些时候需要提供 这些功能时比较容易被要求更换。</p><h3 id="灵感2"><a href="#灵感2" class="headerlink" title="灵感2"></a>灵感2</h3><p>之前系统还不是很复杂时，主要对外提供 http 接口，后来，服务越来越多，服务间的通信则主要使用 rpc 方式，我们选择的 grpc 框架，该框架在创建接口时的方式，是基于 proto3 定义的接口，使用 protoc 直接生成对应的代码，将接口定义变成真正的 <code>接口</code>，然后由开发者自行实现该接口，达到提供真正的接口功能的目的。</p><p>我在想，http 和 rpc，都是远程通信的方式，从目的上看，本就没什么区别。看起来，只是 rpc 是基于自定义的 <code>数据格式</code> 及 <code>序列化方式</code>，而 http 整体看是个<code>通用的文本协议</code>。那么，是不是可以把 grpc 中的一些优点，应用到 http 的请求中来，甚至应用到 ws 等长链接协议中？</p><p>后来，看到 go-zero 这个项目中，脚手架工具的 go-ctl 就已经包含了这项功能，基于一个自定义的接口定义文档，生成一定模板下的基本代码。觉得十分好用。</p><h3 id="更多探索"><a href="#更多探索" class="headerlink" title="更多探索"></a>更多探索</h3><p>在探索的过程中，观摩了几个 web 开发框架，可以算得上是典型了：</p><ul><li> <a href="https://goframe.org/pages/viewpage.action?pageId=1114399">goframe</a></li><li> <a href="https://go-zero.dev/cn/">go-zero</a></li><li> <a href="https://go-kratos.dev/docs/">go-kratos</a></li></ul><p>他们分别有自己的开发工具体系。</p><p><code>goframe</code> 是采用 <code>将接口信息写在代码中</code> 的方式，通过解析 request 和 response 中的 meta，以及在注册路由时添加的一些额外信息，生成 openapi 格式的 json 文档，实际上，这也是生成 swagger 所需要的信息，然后直接在框架中继承了 swagger。 对于开发者而言，仅需要关注代码即可，在代码中通过 <code>tag</code> 或者 显式描述 的方式，即可保证接口文档与接口实现一致，改动成本较小，学习成本较低。</p><p><code>go-zero</code> 是自己实现了一套 接口定义 的语法，整体类似于 golang 和 proto3 的结合体，词法语法的解析均是自己实现的，这也就意味着，go-zero 可以完全掌控 接口定义文档 到代码的生成过程，因此，其脚手架工具 <code>go-ctl</code> 提供了 api 和 rpc 两种接口代码自动生成的方式，开发者仅需要写 接口定义文档 即可生成基本代码，然后自己补充业务逻辑即可。另外，生成的基本代码是根据 模板 确定的，这也就在一定程度上支持了自定义生成代码的功能，值得更多探索。另外，生态中也有将 接口定义 和 swagger 格式对接 的工具了，可以生成 swagger 文档。</p><p><code>go-kratos</code> 采用的是 grpc 的一套方案，grpc 的 语法解析 是 C++ 实现的，然后生成一套自定义 ast 的 <code>FileDescriptor</code> 结构体，这个结构体通过编码成二进制传递给其他程序；grpc 的代码生成是由各类 plugin 实现的，例如我们常用的 golang 的代码，则是由 <code>protoc-gen-go</code> 这个插件生成的(实际上有好几个常见的实现)。那么，也就意味着，只需要再实现一个将 proto3 的接口定义 转成一套 http 的代码的 plugin，也就可以实现和 grpc 一样的代码生成能力。 这也就是 go-kratos 采用的方案，插件的名字叫 <code>protoc-gen-go-http</code> 。 和 go-zero 类似，go-kratos 也提供了生成 swagger 的<a href="https://github.com/go-kratos/swagger-api">工具</a>。</p><p>基于接口定义，我们可以做很多事情，例如： ① 基本代码自动生成(server、client) ② 接口文档自动生成 ③ 基本接口测试代码自动生成 ④ 协议转换 ⑤ mock 。有了这些自动化手段，做开发时就可以很纯粹地关心业务逻辑即可，这对于降低开发的复杂度而言，有着巨大的价值。</p><h2 id="如何行动起来"><a href="#如何行动起来" class="headerlink" title="如何行动起来"></a>如何行动起来</h2><p>探索这些的原因，在于我们当前的 ws 通信，接口层是自定义的 <code>消息码</code>，前后端都需要维护一套必须一样的枚举值，并且前后端都要对每个消息码写一套大致相同的代码，十分繁琐。于是就想到，如果采用了和 grpc 一样的自动生成 服务端 和 客户端 代码的方式，那么 接口管理复杂度、代码复杂度、代码规范、健壮性、可调试性 等各方面都将得到很大的提升。</p><p>一切想法，要想产生真实的价值，就必须得要落地，而落地的方法，可以以实践为目标进行梳理，当有一定思路时，就赶紧行动起来。</p><p>目前，我可以先： ① 阅读 protobuff 的代码生产方式(c++写的，几乎完全没读懂)  ② 阅读 go-ctl 的代码生成方式 (自实现的 ast 解析，代码比较规范，读懂大概)  ③ 阅读 goframe 的接口文档生成方式 (自定义的结构以及转换，比较易懂)</p><p>然后： ④ 分析不同类型接口的差异 ⑤ 梳理 ws 生成的代码应该有些什么部分  ⑥ 以 ws 为例，开发一版基本代码</p><p>另外，补充一些其他维度的TODO：</p><ol><li>重新学习一遍编译原理，弄清楚 词法解析 和 语法解析，以及将自定义语法变成 elf 格式的过程。</li><li>学习使用 正则 和 有限状态机 的方式进行词法、语法解析。</li><li>对 go-frame、go-zero、go-kratos、gin、go-kit 这几个框架进行更深层次的对比，从他们提供的功能 以及 功能的实现方式 等方面进行对比。</li><li>从开发效率的角度，探索各类工具对效率的提升程度，包括维护成本在内。可以先看看：<ul><li> <a href="https://github.com/flipped-aurora/gin-vue-admin">gin-vue-admin</a></li><li> <a href="https://juejin.cn/post/7034813841833721893">6 个 golang 在线工具</a></li></ul></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>grpc</tag>
      
      <tag>go-kratos</tag>
      
      <tag>develop</tag>
      
      <tag>openapi</tag>
      
      <tag>go-zero</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记一次k3s环境搭建记录</title>
    <link href="/longblog/posts/21_12_26_a_record_of_k3s_run_up.html"/>
    <url>/longblog/posts/21_12_26_a_record_of_k3s_run_up.html</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>生产环境中，我们很早在使用 k8s 作为基础设施了，后来，企业项目要做私有化部署，就把目光转向 <code>k3s</code> 了。<br>k3s 是一个轻量级的 k8s，几乎实现了所有 k8s 的特性，除了一些边缘的场景，基本可以把 k3s 当做 k8s 去使用。</p><h3 id="一些备选方案"><a href="#一些备选方案" class="headerlink" title="一些备选方案"></a>一些备选方案</h3><p>早期部署 k8s 环境是十分繁杂的，各个组件都是二进制方式部署，如果遇到问题，排查起来需要的预备知识非常多，因此，大部分企业在使用 k8s 时，都是直接选择云服务商提供的 k8s 集群，阿里云、腾讯云、亚马逊等等都提供了非常完善的 k8s 集群。<br>那作为个人想要玩一玩 k8s ，我们可以怎么搞呢？ 其实社区已经出了非常多的用于简化 k8s 环境搭建的项目，下面列举一些：</p><ol><li>使用 ansible 等工具简化搭建，例如 <a href="https://github.com/kubernetes-sigs/kubespray">kubespray</a>、<a href="https://github.com/easzlab/kubeasz">kubeasz</a>、<a href="https://github.com/kubernetes/kops">Kops</a>、<a href="https://github.com/kubernetes/kubeadm">kubeadm</a></li><li><a href="https://github.com/kubernetes/minikube">minikube</a>、<a href="https://github.com/kubernetes-sigs/kind">kind</a>、<a href="https://github.com/ubuntu/microk8s">microk8s</a>、<a href="https://github.com/k3s-io/k3s">k3s</a> 等轻量级 k8s 实现。</li><li><a href="https://github.com/ubuntu/microk8s">rancher</a>、<a href="https://github.com/KubeOperator/KubeOperator">kubeoperator</a> 这类可视化操作方式</li><li>如果你只是想在自己电脑上玩一下，可以直接使用 docker 客户端提供的 k8s 集群，或者用 <a href="https://github.com/rancher/k3d">k3d</a> (k3s in docker) 、<a href="https://github.com/kubernetes/minikube">minikube</a>、<a href="https://github.com/kubernetes-sigs/kind">kind</a></li></ol><p>值得一提的是， k3s 和 microk8s 是为生成环境设计的 k8s 实现，是为了在资源有限的情况下使用 k8s 集群的一种方案，例如 边缘计算、iot 等场景。(可以搜索和 kubeedge 等结合的内容)</p><h3 id="搭建操作"><a href="#搭建操作" class="headerlink" title="搭建操作"></a>搭建操作</h3><p>因为更加看好 k3s 的生态，因此选用 k3s 作为基础设施。在 k3s 的搭建上，使用官方的搭建脚本已经比较简单了，不过还是有一些为了更加简化搭建过程而出现的项目，例如 <a href="https://github.com/alexellis/k3sup">k3sup</a> 、 <a href="https://github.com/cnrancher/autok3s">autok3s</a> 这两者都提供了远程安装 k3s 的能力，不过后者还有图形化界面。 从搭建难度上，这两者对我而言没啥差别，因此我直接选择了 k3sup。</p><ol><li>在本地下载 k3sup </li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">curl -sLS https://get.k3sup.dev | sh<br></code></pre></td></tr></table></figure><ol start="2"><li><p>在阿里云上开两台机器，并配置公钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ssh-copy-id root@xxx.xx.xx.xx<br></code></pre></td></tr></table></figure></li><li><p>在机器 1 上部署 master 节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">k3sup install --user root --ip xx.xx.xx.xx --k3s-version v1.21.1+k3s1  --k3s-extra-args &#x27;--no-deploy traefik --docker&#x27; --tls-san &quot;xx.xx.xx.xx&quot; --context k3s --merge<br></code></pre></td></tr></table></figure></li><li><p>在机器 2 上部署 slave 节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">k3sup join --user root --ip xx.xx.xx.xx --k3s-version v1.19.7+k3s1 --server-ip xx.xx.xx.xx<br></code></pre></td></tr></table></figure></li><li><p>查看结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longk3s001 ~]# kubectl  get node<br>NAME         STATUS   ROLES    AGE    VERSION<br>longk3s001   Ready    master   129m   v1.19.7+k3s1<br>longk3s002   Ready    &lt;none&gt;   112m   v1.19.7+k3s1<br></code></pre></td></tr></table></figure></li></ol><p>以上，基本的 k3s 环境就搭建完成成功了</p><p>可以设置几个常用的 kubectl 别名，方便使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &lt;&lt;eof &gt;&gt; ~/.bashrc<br>alias k=kubectl<br>alias ke=&quot;kubectl edit&quot;<br>alias ked=&quot;kubectl edit deploy&quot;<br>alias kg=&quot;kubectl get&quot;<br>alias kgp=&quot;kubectl get po&quot;<br>alias wp=&quot;watch kubectl get po&quot;<br>alias kd=&quot;kubectl delete&quot;<br>alias kdp=&quot;kubectl delete pod&quot;<br>alias klf=&quot;kubectl logs -f&quot;<br>alias krrd=&quot;kubectl rollout restart deploy &quot;<br>eof<br>bash<br><br></code></pre></td></tr></table></figure><h3 id="解决远程访问问题"><a href="#解决远程访问问题" class="headerlink" title="解决远程访问问题"></a>解决远程访问问题</h3><p>在集群外访问集群内的通用方案，基本可以分为： </p><ol><li>loadBalancer</li><li>nodePort</li><li>ingress</li><li>hostNetwork</li></ol><p>一般来说，云厂商提供的 k8s 集群，都是采用 loadBalancer 的方式，云厂商会自动提供公网 ip (当然也可以是内网 ip)。 而对于自建的 k8s 集群，则没有现成的 lb，要么使用其他方式，要么，自建 lb。</p><ol><li>自建 lb 可以采用 <a href="https://github.com/metallb/metallb">metalLB</a>， 另外，k3s 官方也提供了一个 lb 实现 <a href="https://github.com/k3s-io/klipper-lb">klipper-lb</a></li><li>使用 nodePort 是一个比较简便的方式，直接改 service 类型即可。但问题是要记各个服务的 nodePort 是多少，比较麻烦，服务多了之后，根本不记得哪个 port 对应哪个服务。</li><li>使用 ingress 是一个很不错的方式，相当于在所有服务前加了一个反向代理服务器，比如 nginx。ingress 的使用能比较好地解决端口复用问题，可以根据 二级域名、访问路径、header 等各种标识对流量进行分发，基本上可以认为，对于企业级项目，用 ingress 就对了。不过，ingress 的相关配置是一个需要学习的内容，尤其是关于 ssl 证书，之后专门出一篇文章记录一下。</li><li>使用 hostNetwork 相当于直接使用宿主机的网络，也就是说，一个服务若开了 8080 端口，则会直接在宿主机上监听 8080 端口。一般来说，hostNetwork 适用于一个集群仅服务于一个主服务的项目。但有一种很好的方式，可以解决 没有 lb 的问题，那就是 使用 ingress 作为流量分发，同时对 ingress 使用 hostNetwork，并且，对于 ingress 使用 daemonset 进行部署，这样就类似于将 ingress 作为 lb 来使用了。</li></ol><p>我直接采用 4 中的方案。相关的信息可以参考 <a href="https://github.com/kubernetes/ingress-nginx/blob/nginx-0.29.0/docs/deploy/baremetal.md">ingress-nginx</a></p><p>记录一下基本过程：</p><ol><li><p>进入到 nginx-ingress 的<a href="https://github.com/kubernetes/ingress-nginx/blob/nginx-0.29.0/docs/deploy/index.md">文档中</a></p></li><li><p>获取清单</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.29.0/deploy/static/mandatory.yaml<br></code></pre></td></tr></table></figure></li><li><p>修改 deployment 资源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 1. 修改 Deployment 为 DaemonSet</span><br><span class="hljs-meta">#</span><span class="bash"> 2. 去掉 spec.replicas</span><br><span class="hljs-meta">#</span><span class="bash"> 3. spec.template.spec 增加  hostNetwork: <span class="hljs-literal">true</span></span><br></code></pre></td></tr></table></figure></li><li><p>启用配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">kubectl apply -f mandatory.yaml<br></code></pre></td></tr></table></figure></li></ol><p>这之后就按照自己的需要，部署自己的服务即可。</p><h3 id="解决存储问题"><a href="#解决存储问题" class="headerlink" title="解决存储问题"></a>解决存储问题</h3><ul><li>使用默认的 本地存储 (local-path)。</li><li>使用 nfs 或其他远程存储方案，具体可以参见：<a href="https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner">nfs-provisioner</a></li><li>使用类似于 Longhorn 的分布式存储方案 (k3s 推荐方式)，具体可以参见：<a href="https://rancher.com/docs/k3s/latest/en/storage/">k3s storage</a></li></ul><h3 id="解决日志问题"><a href="#解决日志问题" class="headerlink" title="解决日志问题"></a>解决日志问题</h3><p>默认的日志是分布在各个节点上的，当节点被删除时，日志也就丢了，日志可以使用 fluentd 进行采集(或者 fluent-bit)，具体可以参见： <a href="https://docs.fluentd.org/">fluentd 官方文档</a></p><p>[TODO] 解决日志解析和查询问题 (重量和轻量)</p><h3 id="解决证书问题"><a href="#解决证书问题" class="headerlink" title="解决证书问题"></a>解决证书问题</h3><ol><li>解决集群内证书时长问题，虽然每年重启一次 k3s 即可自动更新证书，但一个稳定的服务扔在那里，谁记得啥时候要重启啊，可以通过改代码重新编译，变成100年就ok了。</li><li>解决 ssl 证书问题，可以参考 <a href="https://cert-manager.io/docs/">cert-manager</a></li></ol><h3 id="解决面板及管理工具"><a href="#解决面板及管理工具" class="headerlink" title="解决面板及管理工具"></a>解决面板及管理工具</h3><p>k8s 生态下已经有大量的面板，最基础的是官方的 dashboard，周边的还有：</p><ul><li>kubeboard</li><li>kubepi</li><li>kubesphere</li><li>rancher</li></ul><p>面板工具来看，整体差别不大，交互上有少量差别，日常使用完全够了，如果有多集群管理需求的话，个人使用不建议 kubeboard(超过3个收费) ，毕竟穷人不配(-.-!)。 kubesphere 和 kubeboard 的周边插件功能还是不错的，可以方便地集成一些常用的组件，并且提供了控制面板。</p><p>客户端还有 lens， 命令行还有 k9s ，都是非常不错的工具。尤其是 <code>k9s</code> ，熟悉了快捷键后，十分方便。</p><h3 id="解决-CD-问题"><a href="#解决-CD-问题" class="headerlink" title="解决 CD 问题"></a>解决 CD 问题</h3><p>对于 k8s 的自动发布，最基础的方式自然是在原有的 CD 脚本中，写一些 kubectl 的命令。但这样不够优雅，主要是将来维护比较麻烦，对于不够熟练 kubectl 的同学而言，有一定学习成本。</p><p>如果要采用更加成熟的方案，可以考虑 jenkins (x) ，社区也有很多针对 k8s 的脚本。 也可以采用 argoCD ，和 k8s 的生态结合得比较紧密。 droneCI 也是一个不错的选择。</p><p>还有一些备选方案： skaffold、devspace 等，这些是可以在本地打包，然后部署到 k8s 的方式。</p><p>如果，企业级使用的话，spinnaker 是一个非常不错选择。</p><p>[TODO] 补一些 CD 相关的文档</p><h3 id="解决监控问题"><a href="#解决监控问题" class="headerlink" title="解决监控问题"></a>解决监控问题</h3><p>机器的监控，比较轻量的方式可以使用 netdata。另外可以用 datadog，生态应该也是很不错的，不过我没怎么做更多的探索。<br>grafana + promethues 是一个更加通用的方案，社区也提供了大量的面板模板，不论是 node exporter 还是 pod exporter，都有比较成熟的面板。推荐使用。 </p><h3 id="解决开发调试问题"><a href="#解决开发调试问题" class="headerlink" title="解决开发调试问题"></a>解决开发调试问题</h3><p>两个不错的方案：<br><a href="https://devspace.sh/cli/docs/introduction">devspace</a><br><a href="https://nocalhost.dev/docs/quick-start/">nocalhost</a></p><h3 id="其他可能的问题"><a href="#其他可能的问题" class="headerlink" title="其他可能的问题"></a>其他可能的问题</h3><ul><li>服务可视化 (tracing、metrics)</li><li>日志体系</li><li>告警体系</li><li>均衡问题 可以参考 <a href="https://github.com/kubernetes-sigs/descheduler">descheduler</a></li></ul><p>TODO:</p><ol><li>增加 k8s ssl相关配置操作记录</li><li>增加 k8s 日志、监控、追踪、告警 相关操作记录</li><li>增加对一个服务的相关操作</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>k8s</tag>
      
      <tag>enviroment</tag>
      
      <tag>develop</tag>
      
      <tag>k3s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何解决linux下的代理访问</title>
    <link href="/longblog/posts/21_12_12_how_to_resolve_proxy_in_linux.html"/>
    <url>/longblog/posts/21_12_12_how_to_resolve_proxy_in_linux.html</url>
    
    <content type="html"><![CDATA[<h3 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h3><p>想在 linux 上安装 helm，结果网速巨慢，于是想给服务器配个代理</p><h3 id="代理安装"><a href="#代理安装" class="headerlink" title="代理安装"></a>代理安装</h3><ol><li><p>配置pip源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &gt; /root/.pip/pip.conf &lt;&lt; eof<br>[global]<br>trusted-host =  pypi.douban.com<br>index-url = http://pypi.douban.com/simple<br>eof<br></code></pre></td></tr></table></figure></li><li><p>pip升个级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install python3 -y &amp;&amp; pip3 install --upgrade pip<br></code></pre></td></tr></table></figure></li><li><p>安装ss</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install shadowsocks<br></code></pre></td></tr></table></figure></li><li><p>创建ss-local配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir /etc/ss<br>cat &gt; /etc/ss/ss.json &lt;&lt; eof<br>&#123;<br>    &quot;server&quot;:&quot;ss 服务端 ip&quot;,<br>    &quot;server_port&quot;:&quot;ss 服务端端口&quot;,<br>    &quot;local_address&quot;: &quot;127.0.0.1&quot;,<br>    &quot;local_port&quot;:1080,<br>    &quot;password&quot;:&quot;ss 服务端密码&quot;,<br>    &quot;timeout&quot;:300,<br>    &quot;method&quot;:&quot;aes-256-cfb&quot;,<br>    &quot;fast_open&quot;: false,<br>    &quot;workers&quot;: 1<br>&#125;<br>eof<br></code></pre></td></tr></table></figure></li><li><p>创建ss service</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat &gt; /etc/systemd/system/ss.service &lt;&lt; eof<br>[Unit]<br>Description=ss<br>[Service]<br>TimeoutStartSec=0<br>Restart=always<br>RestartSec=30<br>ExecStart=/usr/local/bin/sslocal -c /etc/ss/ss.json start<br>ExecStop=/usr/bin/killall sslocal<br>[Install]<br>WantedBy=multi-user.target<br>eof<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> 如果没有 killall ，则执行</span><br>yum install psmisc -y<br></code></pre></td></tr></table></figure></li><li><p>自启动ss service</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl daemon-reload<br>systemctl enable ss.service<br>systemctl start ss.service<br>systemctl status ss<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"> 到此为止，已经可以使用 ss 代理了，验证一下</span><br>curl --socks5 127.0.0.1:1080 http://httpbin.org/ip<br></code></pre></td></tr></table></figure></li><li><p>安装privoxy (为了使用 http 代理)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install privoxy -y<br></code></pre></td></tr></table></figure></li><li><p>增加 privoxy 的配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 增加一条转发规则</span><br>echo &#x27;forward-socks5t   /               127.0.0.1:1080 .&#x27; &gt;&gt; /etc/privoxy/config<br><span class="hljs-meta">#</span><span class="bash"> 默认配置已经打开 listen-address  127.0.0.1:8118 (http代理端口)</span><br></code></pre></td></tr></table></figure></li><li><p>启动 privoxy 代理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl enable privoxy<br>systemctl restart privoxy<br>systemctl status privoxy<br></code></pre></td></tr></table></figure></li><li><p>安装 proxychains-ng (为了支持单个进程的代理)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install -y git<br>export http_proxy=http://127.0.0.1:8118; export https_proxy=https://127.0.0.1:8118; # 解决 git 慢的问题<br>git clone --depth=1 https://github.com/rofl0r/proxychains-ng<br>yum install gcc -y<br>cd proxychains-ng<br>./configure --prefix=/usr --sysconfdir=/etc<br>make &amp;&amp; make install &amp;&amp; make install-config<br></code></pre></td></tr></table></figure></li><li><p>修改 proxychains 配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim /etc/proxychains.conf<br><span class="hljs-meta">#</span><span class="bash"> 把最后一行的 socks4  127.0.0.1 9050 改成 socks5 127.0.0.1 1080</span><br></code></pre></td></tr></table></figure></li><li><p>起个别名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ln -s /usr/bin/proxychains4 /usr/bin/proxy<br></code></pre></td></tr></table></figure></li><li><p>测试一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">proxy curl www.google.com<br></code></pre></td></tr></table></figure></li></ol><p>自此以后，如果没法访问一些资源，则使用：<br>proxy + 要执行的命令</p><p>如果想在整个终端中使用 http 代理，则： (这是 privoxy 带来的)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export http_proxy=127.0.0.1:8118<br>export https_proxy=127.0.0.1:8118<br></code></pre></td></tr></table></figure><p>以下，终于可以不受限制地安装helm了。。。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">helm安装</span><br>wget https://get.helm.sh/helm-v3.2.4-linux-amd64.tar.gz <br><br>tar -zxvf helm-v3.2.4-linux-amd64.tar.gz<br><br>mv linux-amd64/helm /usr/local/bin/helm<br></code></pre></td></tr></table></figure><p>相关的程序也可以看下： polipo</p><h3 id="其他-ss-问题"><a href="#其他-ss-问题" class="headerlink" title="其他 ss 问题"></a>其他 ss 问题</h3><ol><li><p>如果希望使用多级 ss (一台机器 作为 另一台机器的 中转 ss)</p><ul><li>能够使用 ssh， 则参照 <a href="#">Post not found: 技术总结/反穿技术哪家强 反穿技术哪家强</a></li><li>能够使用 ss-tunnel，则 ① 中转机启动 ss-local (假设本地代理端口为 50000) ② 中转机启动 ss-server ③ 使用 <code>ss-tunnel -l 1080 -b 127.0.0.1 -L 127.0.0.1:50000</code> (监听本地 1080)。这种方案 和 ssh 的方案本质一样，都是转发本地端口到远端端口。</li><li>仅能使用 ss-local，则 ① 中转机启动 ss-local, 用于连接到上位ss  ② 中转机启动 ss-server, 用于承接 PC 上的连接  ③ 使用 proxy ssserver </li><li>如果中转机上使用的 ss-local , 那么任何能提供 <code>认证</code> 能力的 tunnel，都能满足需求，比如 <a href="https://github.com/ginuerzh/gost">gost</a>、<a href="https://github.com/ehang-io/nps">nps</a>、<a href="https://github.com/Dreamacro/clash">clash</a></li><li>最简单的方式，是直接用 iptables 转发即可，直接使用 <code>iptables -t nat -A PREROUTING -4 -p tcp --dport 50000 -j DNAT --to-destination xxx.xxx.xxx.xx:50001</code> 即可 (本地 50000 转发到 上位 ss 的 50001)<br>ps: 使用 iptables 有两个坑要注意下，① 要配置 内核参数允许转发 <code>net.ipv4.ip_forward = 1</code>  ② 要设置出网 ip 替换 <code>iptables -t nat -A POSTROUTING -4 -p tcp --dport 50001 -j MASQUERADE</code>，否则回包的地址就错了</li></ul></li><li><p>如果想用 ss 作为全局代理，可以使用 <code>redsocks + iptables</code> 的方案。</p></li><li><p>ssh 其实非常强大, 我们完全可以不用 ss-server 作为代理，直接使用 <code>ssh -D 1080 user@host</code>, 就能做到同样的事情。</p></li><li><p>调试网络的过程中，有几个很好用的工具</p><ul><li><code>ss</code> 查看 socket 相关信息，和 netstat 有重合的部分</li><li><code>netstat</code> 查看 socket 相关信息、路由信息</li><li><code>ip</code> 查看或修改 路由、网卡</li><li><code>ifconfig</code> 网卡信息查看及配置</li><li><code>tcpdump</code> tcp 抓包工具</li><li><code>telnet</code> 远程登录</li><li><code>nc</code> socket 转发</li><li><code>iptables</code> iptables 管理工具</li><li><code>ipvsadm</code> ipvs 管理工具</li><li><code>dig</code> / <code>nslookup</code> dns 查询</li><li><code>curl</code> 支持多种应用层协议的工具</li></ul></li><li><p>希望 ss 有认证能力，可以结合 RADIUS ，具体可以参考: <a href="http://ss5.sourceforge.net/configuration.htm">http://ss5.sourceforge.net/configuration.htm</a></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>proxy</tag>
      
      <tag>ssh</tag>
      
      <tag>helm</tag>
      
      <tag>proxychains</tag>
      
      <tag>radius</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>反穿技术哪家强</title>
    <link href="/longblog/posts/21_12_11_reverse_proxy_compares.html"/>
    <url>/longblog/posts/21_12_11_reverse_proxy_compares.html</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>有时候，因为种种原因，我们希望我们的机器能被其他一些原本访问不到我们的设备访问。<br>比如: </p><ol><li>做微信开发调试的时候，需要配置回调地址，也就是我们能访问微信的服务器，但微信的服务器需要访问我们时缺不行。</li><li>我们想要分享一些资料、文件、服务给不在同一个局域网的人。</li></ol><p>这些情况下，我们需要的技术方案，被称为 <code>内网穿透</code>。</p><h3 id="反穿可选方案"><a href="#反穿可选方案" class="headerlink" title="反穿可选方案"></a>反穿可选方案</h3><p>社区中，有很多这类工具。</p><h4 id="ssh"><a href="#ssh" class="headerlink" title="ssh"></a>ssh</h4><p>最简单的就是 ssh 的方案，只要开启了sshd，本地有ssh就能够实现，既然都在玩服务器了，又有几个没有 ssh 的呢。<br>使用起来非常简单：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> -R 和 -L 的差别只是翻转了，本身实现的效果是一样的</span><br>ssh -R 0.0.0.0:8081:0.0.0.0:8081 root@xx.xx.xx.xx<br></code></pre></td></tr></table></figure><p>上面这样，就把服务器的 8081 端口 代理到了本地的 8081。这个方案最大的优点就是 <code>简单</code> ，在调试时使用十分轻便。<br>问题有两个： 1. 不够稳定，容易断掉。 2. 只支持端口映射，更复杂的功能不好实现。</p><p>另外，ssh 其实是可以直接实现 socks 代理的，这样的目的在于，仅使用一个端口，就能实现对所有端口的访问：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> -f 为后台运行 -N 为不运行任何命令 -D 为动态代理  -q 为 quiet 模式</span><br>ssh  -qfND 0.0.0.0:1080 root@xxx.xx.xx.xx<br></code></pre></td></tr></table></figure><h4 id="autossh"><a href="#autossh" class="headerlink" title="autossh"></a>autossh</h4><p>对于ssh方案而言，最难搞的问题还是 <code>不稳定</code>，于是可以用 autossh 的方案解决。使用起来和 ssh 类似，不过多了一个监听端口：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">autossh -M 8082 -fNR 0.0.0.0:8081:0.0.0.0:8081 root@xx.xx.xx.xx<br></code></pre></td></tr></table></figure><p>这个方案最大的优势就是 解决了 ssh 断线重连的问题。因此，在开发调试时更加好用，而且 <code>-f</code> 参数支持了后台运行，比较优雅地解决了需要维持终端持续打开的问题。</p><p>基本上，在有一些临时性的穿透需求时，这个方案已经十分够用了。对于复杂功能的需求实际上不是这个工具要解决的问题，例如 udp、http、端口复用 等等。</p><h4 id="frp"><a href="#frp" class="headerlink" title="frp"></a>frp</h4><p>上面说的两种方案，主要是临时使用比较方便，但在功能的丰富度上还是十分不足的，毕竟 ssh 的主业是做加密登录的，端口映射只是副业。 而 frp 是则专门做内网穿透的。<br>如果希望提供比较稳定的内网穿透服务，那么选择 frp 就是比较好的选择了。</p><p>frp 分为 服务端 和 客户端，需要两端部署。通过 <code>.ini</code> 配置文件进行管理。支持 tcp、udp、http、ssl-tcp、ssl-udp、p2p 的配置，还对 http 代理做了一些优化(类似于 nginx 的一些功能)。</p><p>关于frp，官方文档介绍的肯定比我详细，可以参考 <a href="https://gofrp.org/docs/">frp文档</a></p><h4 id="nps"><a href="#nps" class="headerlink" title="nps"></a>nps</h4><p>nps 和 frp 是同样定位的应用，两者在功能上也几乎一致，不过值得一提的是，nps自带官方的可视化管理页面，这点比frp在易用性上增加了不少(当然frp也有几个简单的社区版可视化工具)。</p><p>同样，详细可以参考 <a href="https://ehang-io.github.io/nps/">nps文档</a></p><p>实际上，类似的工具还挺多，在 github 上还扒到另一个项目： <a href="https://github.com/mmatczuk/go-http-tunnel">https://github.com/mmatczuk/go-http-tunnel</a> , 再比如和 nps 类似的 <a href="https://github.com/inconshreveable/ngrok">ngrok</a> (ps: 这个项目1.0是开源的，2.0搞成商业项目了，然后1.0就不开发了，有nps代替基本可以不用关注这个项目了)</p><h3 id="一些其他的想法"><a href="#一些其他的想法" class="headerlink" title="一些其他的想法"></a>一些其他的想法</h3><p>上面说的 内网穿透，是解决网络通路的其中一种场景，除了上面这些方案，还有一些其他的方向，举些栗子：</p><h4 id="NAT映射"><a href="#NAT映射" class="headerlink" title="NAT映射"></a>NAT映射</h4><p>这种解决网络通路的方案，通常用在 <code>网关</code> 处，可以根据 网卡、ip、端口 做响应的转发。</p><h4 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h4><p>反向代理最常见的就是充当 <code>应用网关</code>，通过对 协议、域名、路径、header 等等做匹配，转发到内网中的不同服务上去。对于提供网络应用的软件来说，这种方式几乎是必然的。</p><p>传统应用中，最广泛的反向代理服务器就是 <code>nginx</code>。在云原生逐渐成长起来之后，ambassador、envoy、kong 等应用网关也顺势起飞了。</p><h4 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h4><p>对大众而言，最常接触到的解决网络通路的场景，还是 <code>代理</code>，为了和反向代理区分，我们不妨叫它 <code>正向代理</code>。</p><p>使用正向代理的场景很明确： 当我们的机器 A 无法访问机器 C，但是另一台机器 B 能访问机器 C，同时我们的机器 A 能访问机器 B，那么，机器 A 就可以让机器 B 代理 A 的请求，访问机器 C。</p><p>大众最常见的例子是，在国内，想要用手机看油管的视频，就需要安装代理软件。这个场景中，手机就是 机器A，油管的服务器就是机器 C，代理软件连接的服务端就是机器 B。</p><p>举个开发场景的例子：<br>  公司开发环境的服务器A在公司内网，并且做了网络白名单，仅有特殊的网段能够访问，你的电脑不在这个特殊网段内，有一台机器B就在这个网段，你能访问这台机器 B，那么你就能通过机器 B 访问开发环境的服务器 A。通常，这个机器 B 可能是一个 <code>跳板机</code>，或者是一个 <code>vpn</code>。</p><p>我们通常认为，代理是为了解决 <code>网络不可达</code> 问题的，有些时候，代理也为了解决 <code>不那么可达</code> 的问题 ，俗称 <code>网速慢</code>。</p><p>比如在玩游戏这件事上，一些国外服的游戏，在国内玩起来就很慢，类似的还有看视频等场景。这种时候的代理，都是为了 <code>加速</code>，往往会采用 <code>udp</code> 的方案，可以参考 <a href="https://github.com/wangyu-/UDPspeeder/blob/branch_libev/doc/README.zh-cn.md">UDPspeeder</a></p><p>如果要自己建立网络代理服务，最常见的方案是 <code>ss</code> 、<code>open VPN</code> , 这相关的资料网络上十分丰富，就不多说。<br>在 mac/windows/iphone/android 上安装代理客户端比较简单，但是在 linux 上安装代理客户端就相对不那么常见了，之前为了安装 helm，解决过在服务器上安装客户端的问题，详情可参考 <a href="#">Post not found: 技术总结/如何解决linux下的代理访问 如何解决linux下的代理访问</a></p><h3 id="网络相关的内容"><a href="#网络相关的内容" class="headerlink" title="网络相关的内容"></a>网络相关的内容</h3><p>网络连通性还有一些其他方面的，平常可能用得比较少。</p><h4 id="p2p"><a href="#p2p" class="headerlink" title="p2p"></a>p2p</h4><p>是 <code>peer to peer</code> 的缩写，现在最多的应用场景是 <code>p2p内容分发网络</code>，比如大家说的 <code>种子下载</code>。另外，在区块链上，也使用了相同的技术。另一种比较大众的应用场景，就是 <code>语音电话</code>、<code>视频电话</code> 。</p><p>p2p 用在私有领域，可以用来作为 安全通信 的技术方案，例如私有部署的即时通信。除了通信，还可以作为安全文件传输的方案，相关信息可以参考 <a href="https://magic-wormhole.readthedocs.io/en/latest/welcome.html">magic-wormhole</a></p><h4 id="k8s-开发网络代理"><a href="#k8s-开发网络代理" class="headerlink" title="k8s 开发网络代理"></a>k8s 开发网络代理</h4><p>一般我们认为，要访问 k8s 中的服务，有这样几种方案：</p><ol><li>nodeport</li><li>loadbalancer</li><li>ingress</li></ol><p>在开发调试阶段，我们有时候想直接访问 k8s 中的服务，但是这个服务在 k8s 中仅有 ClusterIP，单独为这个服务创建 LB 也划不来，这时候可以使用 <code>kubectl port-forward [podname] [local port]:[pod port]</code>，如果遇到需要 port-forward 的数量比较多的时候，这种方式就比较麻烦了，此时需要批量转发，可以参考 <a href="https://github.com/txn2/kubefwd">kubefwd</a>，也可以参考可视化的项目 <a href="https://github.com/pixel-point/kube-forwarder">kube-forwarder</a></p><p>除了想在本地直接访问集群中的服务，有时候我们也想把集群中某个服务所收到的流量，转发到我们本地端口，这样就可以实现方便地调试。</p><p>我们目前使用的方案是 devspace，具体信息可以查看 <a href="https://devspace.sh/cli/docs/introduction">devspace</a></p><p>其他可以考虑的方案可以查看</p><ul><li><a href="https://github.com/telepresenceio/telepresence">telepresence</a></li><li><a href="https://github.com/omrikiei/ktunnel">ktunnel</a></li><li><a href="https://nocalhost.dev/zh-CN/">nocalhost</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
      <tag>proxy</tag>
      
      <tag>ssh</tag>
      
      <tag>frp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>穷人才会用的nas方案</title>
    <link href="/longblog/posts/21_12_02_a_nas_solution_used_by_poor.html"/>
    <url>/longblog/posts/21_12_02_a_nas_solution_used_by_poor.html</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近手机开始报存储空间快满了的问题，不知道有些什么文件占用了这么多空间，基本的解决办法是：把我将来需要的文件进行转移。例如之前的照片、视频等。自然而然想到了文件服务器。</p><h2 id="可选方案"><a href="#可选方案" class="headerlink" title="可选方案"></a>可选方案</h2><h3 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h3><p>采用现有的公有网盘，例如 百度网盘，阿里网盘，方便直接。<br>问题： 百度网盘太慢了，会员又太贵了，划不来。阿里网盘现在的客户端还很不完善。另外，可能还会有资料隐私问题、莫名关停服务等问题(参考360网盘)。<br>结论：对于一些公共资料可以采用这种方案，例如一些课程学习资料等。等阿里网盘发育一段时间再存一些公共资料。</p><h3 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h3><p>采用OSS，自建私有网盘，保证安全私密性。<br>问题：贵。oss存储费用 + 流量费，对于可能需要长期存储的文件来说，成本太高了。<br>结论：不行不行，穷。</p><h3 id="方案三"><a href="#方案三" class="headerlink" title="方案三"></a>方案三</h3><p>采用自有硬盘，搭建文件服务器，成本低，私密性高。<br>问题：</p><ol><li> 搭建和维护相对复杂。</li><li>存储安全性需要考虑。</li></ol><p>由于成本问题以及私密性问题，最终采用方案三。</p><h2 id="具体可选实施方案"><a href="#具体可选实施方案" class="headerlink" title="具体可选实施方案"></a>具体可选实施方案</h2><h3 id="购买成熟系统"><a href="#购买成熟系统" class="headerlink" title="购买成熟系统"></a>购买成熟系统</h3><p>现在市场上关于 家庭NAS 系统，主要有 威联通、群晖、铁威马 这些。<br>优点就是 简单、方便、功能齐全。缺点就是 价格贵！<br><img src="https://static.longalong.cn/img/tieweima_nas_price.png" alt="群晖、威联通价格"></p><p><img src="https://static.longalong.cn/img/xishu_nas_price.png" alt="西部数据价格"></p><p>其实直接购买的方式优势还是非常明显的，一个群晖，不仅可以作为文件服务器，还可以用作下载机、家庭影院、简单办公系统，由于其本质是一个linux系统的封装，因此也可以跑很多的服务(例如docker)，类似于买了一台家用服务器，而文件存储服务只是这个服务器的一个小服务而已。</p><h3 id="使用塔式-家用主机"><a href="#使用塔式-家用主机" class="headerlink" title="使用塔式/家用主机"></a>使用塔式/家用主机</h3><p>和直接购买群晖这类机器类似的另一种方案，就是直接使用家用主机。<br>家用主机的好处就是，大部分家庭中都有现有的设备，也就不需要单独花钱了，多配一块硬盘就可以了。</p><h3 id="使用树莓派"><a href="#使用树莓派" class="headerlink" title="使用树莓派"></a>使用树莓派</h3><p>使用主机作为文件服务器有一个弊端，就是能耗太高了，一个家用主机至少也是80W以上，常年开机的话，也不是一个环保的方式(主要可能还是成本太高)。<br>如果使用树莓派的话，则更加轻量，树莓派的运行功耗仅 5W ，放在某个小角落，一年下来问题也不大。<br>另外，树莓派可以提供的服务也可以非常非常多，甚至可以用来做智能家居控制器。</p><h3 id="使用路由器"><a href="#使用路由器" class="headerlink" title="使用路由器"></a>使用路由器</h3><p>在考虑树莓派的网络拓扑时，想到了为何不直接使用路由器作为文件服务器？<br>由于路由器的内核也是类unix系统，因此也是可以直接作为文件服务器的。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>考虑到成本，最终选择使用 路由器 作为文件服务器的处理器。</p><h2 id="具体操作方案"><a href="#具体操作方案" class="headerlink" title="具体操作方案"></a>具体操作方案</h2><h3 id="购买硬盘架、硬盘"><a href="#购买硬盘架、硬盘" class="headerlink" title="购买硬盘架、硬盘"></a>购买硬盘架、硬盘</h3><p>要将路由器作为文件服务器，首先就要挂载硬盘。同时，考虑到文件安全的问题，需要采用冗余存储的方式，因此，需要至少2块硬盘。<br>要达到目标，有两种方案：</p><ul><li>使用usb hub + usb 转接口 + 串口硬盘</li><li>使用usb hub + usb接口磁盘</li></ul><p>由于usb接口的磁盘价格都比较高(例如u盘、ssd等)，因此选择第一种方案。<br>去淘宝搜了一下，一个usb hub大约16元，一个usb转接口大约27元 * 2，一个硬盘大约60元(500g) * 2，成本为190元。但这样有一个问题，用usb转接口的话，线太多了，得有两个12v的供电线以及2个sata转usb数据线，而且硬盘还是散乱的。<br>最终一狠心，花了150块大洋买了个双盘位硬盘架，这样就省去了usb hub和usb转接口的钱，最终算下来花了 270元。</p><h3 id="安装同步软件"><a href="#安装同步软件" class="headerlink" title="安装同步软件"></a>安装同步软件</h3><p>软件方面，有syncthing，非常合适，拥有多个操作系统的客户端。<br>参考官网： Syncthing</p><h3 id="连接同步"><a href="#连接同步" class="headerlink" title="连接同步"></a>连接同步</h3><p>路由器上和手机上都安装了syncthing后，进行两端绑定并共享文件夹。<br>然后设置同步策略为每小时扫描一次。</p><h3 id="啥也不用管了"><a href="#啥也不用管了" class="headerlink" title="啥也不用管了"></a>啥也不用管了</h3><p>然后就去睡觉吧，保证syncthing后台进程，你就几个月都不用管他，如果哪天手机空间不足了，就去看看是否最新同步的，如果是，就把手机上的文件都清空吧。</p><h2 id="PS-回头补一些图片"><a href="#PS-回头补一些图片" class="headerlink" title="PS: 回头补一些图片"></a>PS: 回头补一些图片</h2>]]></content>
    
    
    
    <tags>
      
      <tag>nas</tag>
      
      <tag>syncthing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用lvm实现raid能力</title>
    <link href="/longblog/posts/21_12_02_operation_of_raid_with_lvm.html"/>
    <url>/longblog/posts/21_12_02_operation_of_raid_with_lvm.html</url>
    
    <content type="html"><![CDATA[<h3 id="lvm是什么？"><a href="#lvm是什么？" class="headerlink" title="lvm是什么？"></a>lvm是什么？</h3><p>LVM 是 Logical Volume Manager（逻辑卷管理）的简写，它是Linux环境下对磁盘分区进行管理的一种机制，它由Heinz Mauelshagen在Linux 2.4内核上实现，最新版本为：稳定版1.0.5，开发版 1.1.0-rc2，以及LVM2开发版。Linux用户安装Linux操作系统时遇到的一个常见的难以决定的问题就是如何正确地评估各分区大小，以分配合适的硬盘空间。普通的磁盘分区管理方式在逻辑分区划分好之后就无法改变其大小，当一个逻辑分区存放不下某个文件时，这个文件因为受上层文件系统的限制，也不能跨越多个分区来存放，所以也不能同时放到别的磁盘上。而遇到出现某个分区空间耗尽时，解决的方法通常是使用符号链接，或者使用调整分区大小的工具，但这只是暂时解决办法，没有从根本上解决问题。随着Linux的逻辑卷管理功能的出现，这些问题都迎刃而解，用户在无需停机的情况下可以方便地调整各个分区大小。</p><h3 id="实验操作"><a href="#实验操作" class="headerlink" title="实验操作"></a>实验操作</h3><p>创建设备<br><img src="./../static/img/ali_ecs_lvm.png" alt="阿里云ecs"></p><h4 id="查看磁盘状态"><a href="#查看磁盘状态" class="headerlink" title="查看磁盘状态"></a>查看磁盘状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# fdisk -l<br><br>磁盘 /dev/vda：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br>磁盘标签类型：dos<br>磁盘标识符：0x000bb9c1<br><br>   设备 Boot      Start         End      Blocks   Id  System<br>/dev/vda1   *        2048    41943039    20970496   83  Linux<br><br>磁盘 /dev/vdb：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br><br><br>磁盘 /dev/vdc：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br><br><br>磁盘 /dev/vdd：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br></code></pre></td></tr></table></figure><h4 id="升级yum"><a href="#升级yum" class="headerlink" title="升级yum"></a>升级yum</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# yum update -y<br></code></pre></td></tr></table></figure><h4 id="安装lvm2"><a href="#安装lvm2" class="headerlink" title="安装lvm2"></a>安装lvm2</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# yum install lvm2 -y<br></code></pre></td></tr></table></figure><h4 id="创建物理卷"><a href="#创建物理卷" class="headerlink" title="创建物理卷"></a>创建物理卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvcreate /dev/vdb /dev/vdc<br>  Physical volume &quot;/dev/vdb&quot; successfully created.<br>  Physical volume &quot;/dev/vdc&quot; successfully created.<br></code></pre></td></tr></table></figure><h4 id="查看物理卷"><a href="#查看物理卷" class="headerlink" title="查看物理卷"></a>查看物理卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvdisplay<br>  &quot;/dev/vdc&quot; is a new physical volume of &quot;20.00 GiB&quot;<br>  --- NEW Physical volume ---<br>  PV Name               /dev/vdc<br>  VG Name<br>  PV Size               20.00 GiB<br>  Allocatable           NO<br>  PE Size               0<br>  Total PE              0<br>  Free PE               0<br>  Allocated PE          0<br>  PV UUID               avPba4-Z0J5-bhWC-4poS-x5oG-qt4P-4xUJnn<br><br>  &quot;/dev/vdb&quot; is a new physical volume of &quot;20.00 GiB&quot;<br>  --- NEW Physical volume ---<br>  PV Name               /dev/vdb<br>  VG Name<br>  PV Size               20.00 GiB<br>  Allocatable           NO<br>  PE Size               0<br>  Total PE              0<br>  Free PE               0<br>  Allocated PE          0<br>  PV UUID               exRn9W-AQKP-7rTc-EwAf-YtsK-MW0O-HHJ0sk<br></code></pre></td></tr></table></figure><h4 id="查看物理卷简要信息"><a href="#查看物理卷简要信息" class="headerlink" title="查看物理卷简要信息"></a>查看物理卷简要信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvs<br>  PV         VG Fmt  Attr PSize  PFree<br>  /dev/vdb      lvm2 ---  20.00g 20.00g<br>  /dev/vdc      lvm2 ---  20.00g 20.00g<br></code></pre></td></tr></table></figure><h4 id="查看物理卷简要信息-1"><a href="#查看物理卷简要信息-1" class="headerlink" title="查看物理卷简要信息"></a>查看物理卷简要信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvscan<br>  PV /dev/vdc                      lvm2 [20.00 GiB]<br>  PV /dev/vdb                      lvm2 [20.00 GiB]<br>  Total: 2 [40.00 GiB] / in use: 0 [0   ] / in no VG: 2 [40.00 GiB]<br></code></pre></td></tr></table></figure><h4 id="创建逻辑卷组"><a href="#创建逻辑卷组" class="headerlink" title="创建逻辑卷组"></a>创建逻辑卷组</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgcreate vglong /dev/vdc /dev/vdb<br>  Volume group &quot;vglong&quot; successfully created<br></code></pre></td></tr></table></figure><p>查看逻辑卷组信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgdisplay<br>  --- Volume group ---<br>  VG Name               vglong<br>  System ID<br>  Format                lvm2<br>  Metadata Areas        2<br>  Metadata Sequence No  1<br>  VG Access             read/write<br>  VG Status             resizable<br>  MAX LV                0<br>  Cur LV                0<br>  Open LV               0<br>  Max PV                0<br>  Cur PV                2<br>  Act PV                2<br>  VG Size               39.99 GiB<br>  PE Size               4.00 MiB<br>  Total PE              10238<br>  Alloc PE / Size       0 / 0<br>  Free  PE / Size       10238 / 39.99 GiB<br>  VG UUID               4flIRX-1oVR-MBy5-I2YT-gY2R-Eqaf-PmFq7b<br></code></pre></td></tr></table></figure><h4 id="查看逻辑卷组简要信息"><a href="#查看逻辑卷组简要信息" class="headerlink" title="查看逻辑卷组简要信息"></a>查看逻辑卷组简要信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgs<br>  VG     #PV #LV #SN Attr   VSize  VFree<br>  vglong   2   0   0 wz--n- 39.99g 39.99g<br></code></pre></td></tr></table></figure><h4 id="创建逻辑卷"><a href="#创建逻辑卷" class="headerlink" title="创建逻辑卷"></a>创建逻辑卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# lvcreate -L 30G -n lvlong vglong<br>  Logical volume &quot;lvlong&quot; created.<br></code></pre></td></tr></table></figure><h4 id="查看逻辑卷"><a href="#查看逻辑卷" class="headerlink" title="查看逻辑卷"></a>查看逻辑卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# lvdisplay<br>  --- Logical volume ---<br>  LV Path                /dev/vglong/lvlong<br>  LV Name                lvlong<br>  VG Name                vglong<br>  LV UUID                x7iFjg-QSem-vzfu-jAkV-V0lI-50P3-tHD3Hz<br>  LV Write Access        read/write<br>  LV Creation host, time longtestlvm, 2021-10-12 14:00:09 +0800<br>  LV Status              available<br><span class="hljs-meta">  #</span><span class="bash"> open                 0</span><br>  LV Size                30.00 GiB<br>  Current LE             7680<br>  Segments               2<br>  Allocation             inherit<br>  Read ahead sectors     auto<br>  - currently set to     8192<br>  Block device           252:0<br></code></pre></td></tr></table></figure><h4 id="查看逻辑卷简要信息"><a href="#查看逻辑卷简要信息" class="headerlink" title="查看逻辑卷简要信息"></a>查看逻辑卷简要信息</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# lvs<br>  LV     VG     Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert<br>  lvlong vglong -wi-a----- 30.00g<br></code></pre></td></tr></table></figure><h4 id="查看磁盘"><a href="#查看磁盘" class="headerlink" title="查看磁盘"></a>查看磁盘</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# fdisk -l<br><br>磁盘 /dev/vda：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br>磁盘标签类型：dos<br>磁盘标识符：0x000bb9c1<br><br>   设备 Boot      Start         End      Blocks   Id  System<br>/dev/vda1   *        2048    41943039    20970496   83  Linux<br><br>磁盘 /dev/vdb：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br><br><br>磁盘 /dev/vdc：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br><br><br>磁盘 /dev/vdd：21.5 GB, 21474836480 字节，41943040 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br><br><br>磁盘 /dev/mapper/vglong-lvlong：32.2 GB, 32212254720 字节，62914560 个扇区<br>Units = 扇区 of 1 * 512 = 512 bytes<br>扇区大小(逻辑/物理)：512 字节 / 512 字节<br>I/O 大小(最小/最佳)：512 字节 / 512 字节<br></code></pre></td></tr></table></figure><h4 id="格式化虚拟磁盘"><a href="#格式化虚拟磁盘" class="headerlink" title="格式化虚拟磁盘"></a>格式化虚拟磁盘</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# mkfs.ext4 /dev/vglong/lvlong<br>mke2fs 1.42.9 (28-Dec-2013)<br>文件系统标签=<br>OS type: Linux<br>块大小=4096 (log=2)<br>分块大小=4096 (log=2)<br>Stride=0 blocks, Stripe width=0 blocks<br>1966080 inodes, 7864320 blocks<br>393216 blocks (5.00%) reserved for the super user<br>第一个数据块=0<br>Maximum filesystem blocks=2155872256<br>240 block groups<br>32768 blocks per group, 32768 fragments per group<br>8192 inodes per group<br>Superblock backups stored on blocks:<br>        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,<br>        4096000<br><br>Allocating group tables: 完成<br>正在写入inode表: 完成<br>Creating journal (32768 blocks): 完成<br>Writing superblocks and filesystem accounting information: 完成<br></code></pre></td></tr></table></figure><h4 id="挂载磁盘"><a href="#挂载磁盘" class="headerlink" title="挂载磁盘"></a>挂载磁盘</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm mnt]# mkdir longtestlvm<br><br>[root@longtestlvm mnt]# mount /dev/mapper/vglong-lvlong /mnt/longtestlvm/<br></code></pre></td></tr></table></figure><h4 id="创建一个文件试试"><a href="#创建一个文件试试" class="headerlink" title="创建一个文件试试"></a>创建一个文件试试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm longtestlvm]# mkdir -p /mnt/longtestlvm/longtest<br><br>[root@longtestlvm longtestlvm]# echo &#x27;hello world \n nihao a&#x27; &gt; /mnt/longtestlvm/longtest/a.txt<br></code></pre></td></tr></table></figure><h4 id="查看磁盘挂载"><a href="#查看磁盘挂载" class="headerlink" title="查看磁盘挂载"></a>查看磁盘挂载</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm mnt]# df -h<br>文件系统                   容量  已用  可用 已用% 挂载点<br>devtmpfs                   3.9G     0  3.9G    0% /dev<br>tmpfs                      3.9G     0  3.9G    0% /dev/shm<br>tmpfs                      3.9G  572K  3.9G    1% /run<br>tmpfs                      3.9G     0  3.9G    0% /sys/fs/cgroup<br>/dev/vda1                   20G  2.4G   17G   13% /<br>tmpfs                      783M     0  783M    0% /run/user/0<br>/dev/mapper/vglong-lvlong   30G   45M   28G    1% /mnt/longtestlvm<br></code></pre></td></tr></table></figure><h4 id="查看文件大小"><a href="#查看文件大小" class="headerlink" title="查看文件大小"></a>查看文件大小</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm mnt]# du -ah<br>4.0K        ./longtestlvm/longtest/a.txt<br>8.0K        ./longtestlvm/longtest<br>16K        ./longtestlvm/lost+found<br>28K        ./longtestlvm<br>32K        .<br></code></pre></td></tr></table></figure><h4 id="扩展逻辑卷容量"><a href="#扩展逻辑卷容量" class="headerlink" title="扩展逻辑卷容量"></a>扩展逻辑卷容量</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# lvextend -L +4G /dev/vglong/lvlong<br>  Size of logical volume vglong/lvlong changed from 30.00 GiB (7680 extents) to 34.00 GiB (8704 extents).<br>  Logical volume vglong/lvlong successfully resized.<br></code></pre></td></tr></table></figure><h4 id="resize逻辑卷"><a href="#resize逻辑卷" class="headerlink" title="resize逻辑卷"></a>resize逻辑卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# resize2fs /dev/vglong/lvlong<br>resize2fs 1.42.9 (28-Dec-2013)<br>Filesystem at /dev/vglong/lvlong is mounted on /mnt/longtestlvm; on-line resizing required<br>old_desc_blocks = 4, new_desc_blocks = 5<br>The filesystem on /dev/vglong/lvlong is now 8912896 blocks long.<br></code></pre></td></tr></table></figure><h4 id="扩展逻辑卷组"><a href="#扩展逻辑卷组" class="headerlink" title="扩展逻辑卷组"></a>扩展逻辑卷组</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgextend vglong /dev/vdd<br>  Physical volume &quot;/dev/vdd&quot; successfully created.<br>  Volume group &quot;vglong&quot; successfully extended<br></code></pre></td></tr></table></figure><h4 id="缩减逻辑卷"><a href="#缩减逻辑卷" class="headerlink" title="缩减逻辑卷"></a>缩减逻辑卷</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# umount /mnt/longtestlvm<br><br>[root@longtestlvm ~]# e2fsck -f /dev/vglong/lvlong<br>e2fsck 1.42.9 (28-Dec-2013)<br>第一步: 检查inode,块,和大小<br>第二步: 检查目录结构<br>第3步: 检查目录连接性<br>Pass 4: Checking reference counts<br>第5步: 检查簇概要信息<br>/dev/vglong/lvlong: 13/2228224 files (0.0% non-contiguous), 184932/8912896 blocks<br><br><br>[root@longtestlvm ~]#  resize2fs /dev/vglong/lvlong  10G<br>resize2fs 1.42.9 (28-Dec-2013)<br>Resizing the filesystem on /dev/vglong/lvlong to 2621440 (4k) blocks.<br>The filesystem on /dev/vglong/lvlong is now 2621440 blocks long.<br><br><br>[root@longtestlvm ~]# lvresize -L 10G /dev/vglong/lvlong<br>  WARNING: Reducing active logical volume to 10.00 GiB.<br>  THIS MAY DESTROY YOUR DATA (filesystem etc.)<br>Do you really want to reduce vglong/lvlong? [y/n]: y<br>  Size of logical volume vglong/lvlong changed from 34.00 GiB (8704 extents) to 10.00 GiB (2560 extents).<br>  Logical volume vglong/lvlong successfully resized.<br></code></pre></td></tr></table></figure><h4 id="缩减逻辑卷组"><a href="#缩减逻辑卷组" class="headerlink" title="缩减逻辑卷组"></a>缩减逻辑卷组</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgreduce vglong /dev/vdd<br></code></pre></td></tr></table></figure><h4 id="查看逻辑卷组"><a href="#查看逻辑卷组" class="headerlink" title="查看逻辑卷组"></a>查看逻辑卷组</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgdisplay<br>  --- Volume group ---<br>  VG Name               vglong<br>  System ID<br>  Format                lvm2<br>  Metadata Areas        2<br>  Metadata Sequence No  10<br>  VG Access             read/write<br>  VG Status             resizable<br>  MAX LV                0<br>  Cur LV                1<br>  Open LV               0<br>  Max PV                0<br>  Cur PV                2<br>  Act PV                2<br>  VG Size               39.99 GiB<br>  PE Size               4.00 MiB<br>  Total PE              10238<br>  Alloc PE / Size       2560 / 10.00 GiB<br>  Free  PE / Size       7678 / 29.99 GiB<br>  VG UUID               4flIRX-1oVR-MBy5-I2YT-gY2R-Eqaf-PmFq7b<br></code></pre></td></tr></table></figure><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# lvremove /dev/vglong/lvlong<br>Do you really want to remove active logical volume vglong/lvlong? [y/n]: y<br>  Logical volume &quot;lvlong&quot; successfully removed<br><br>[root@longtestlvm ~]# vgremove vglong<br>  Volume group &quot;vglong&quot; successfully removed<br>  <br>[root@longtestlvm ~]# pvremove /dev/vdb /dev/vdc /dev/vdd<br>  Labels on physical volume &quot;/dev/vdb&quot; successfully wiped.<br>  Labels on physical volume &quot;/dev/vdc&quot; successfully wiped.<br>  Labels on physical volume &quot;/dev/vdd&quot; successfully wiped.<br></code></pre></td></tr></table></figure><h4 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvmove /dev/vdb /dev/vdc<br></code></pre></td></tr></table></figure><h4 id="一些其他的内容"><a href="#一些其他的内容" class="headerlink" title="一些其他的内容"></a>一些其他的内容</h4><p>disk相关命令<br>fdisk 、 mkfs 、du 、 df 、dump2fs</p><h4 id="一些问题记录"><a href="#一些问题记录" class="headerlink" title="一些问题记录"></a>一些问题记录</h4><ol><li>已经将某个物理磁盘加入到 vg 中后，再将该物理盘进行分区<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# pvs<br>  WARNING: Device for PV cSASFg-dS4S-lrIP-hD3V-aJSR-EnzC-5bYp4B not found or rejected by a filter.<br>  Couldn&#x27;t find device with uuid cSASFg-dS4S-lrIP-hD3V-aJSR-EnzC-5bYp4B.<br>  PV         VG     Fmt  Attr PSize   PFree<br>  /dev/vdb   vglong lvm2 a--  &lt;20.00g &lt;20.00g<br>  /dev/vdc   vglong lvm2 a--  &lt;20.00g &lt;20.00g<br>  /dev/vdd1         lvm2 ---  100.00m 100.00m<br>  /dev/vdd2         lvm2 ---  100.00m 100.00m<br>  [unknown]  vglong lvm2 a-m  &lt;20.00g &lt;20.00g<br></code></pre></td></tr></table></figure></li></ol><p>解决办法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@longtestlvm ~]# vgreduce --removemissing vglong --force<br>  Volume group &quot;vglong&quot; is already consistent.<br>  <br><br>[root@longtestlvm ~]# pvs<br>  PV         VG     Fmt  Attr PSize   PFree<br>  /dev/vdb   vglong lvm2 a--  &lt;20.00g &lt;20.00g<br>  /dev/vdc   vglong lvm2 a--  &lt;20.00g &lt;20.00g<br>  /dev/vdd1         lvm2 ---  100.00m 100.00m<br>  /dev/vdd2         lvm2 ---  100.00m 100.00m<br></code></pre></td></tr></table></figure><h4 id="整体的一些想法"><a href="#整体的一些想法" class="headerlink" title="整体的一些想法"></a>整体的一些想法</h4><p>对于 lvm，可以用于多个磁盘组合成一个磁盘，且提供 raid 能力，这给存储提供了超大容量的可能性，可以考虑作为NAS的一种实现。</p>]]></content>
    
    
    
    <tags>
      
      <tag>raid</tag>
      
      <tag>lvm</tag>
      
      <tag>disk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何做好压测</title>
    <link href="/longblog/posts/21_12_02_how_to_do_load_test.html"/>
    <url>/longblog/posts/21_12_02_how_to_do_load_test.html</url>
    
    <content type="html"><![CDATA[<h3 id="压测的目标是什么？"><a href="#压测的目标是什么？" class="headerlink" title="压测的目标是什么？"></a>压测的目标是什么？</h3><p>压测的目标有两个：</p><ol><li>通过对模块的压测，找到模块的性能瓶颈，分析其资源耗用合理性、架构可扩展性，找到优化方向。</li><li>通过对链路的压测，找到链路的性能瓶颈，回答线上资源容量。 ^20d5ad</li></ol><h3 id="压测的技能栈有什么？"><a href="#压测的技能栈有什么？" class="headerlink" title="压测的技能栈有什么？"></a>压测的技能栈有什么？</h3><p>压测的技能栈要求非常广泛，整体来说，需要具备这些技能：</p><ol><li>测试人员的思维习惯和方法论。找到合适的测试模型，并准备好/管理好这些数据。</li><li>运维人员的对系统的认识。能够根据需要配置合适的系统资源，能够一定程度上进行系统问题排查。</li><li>开发人员的开发能力。往往在数据准备过程、测试过程中，需要有较多的工具类开发。</li><li>数据分析人员的分析能力。在数据准备和压测过程中，需要提前预规划各类指标与数据，用于分析系统状态，有时需要比较强的数据分析能力。</li><li>对业务系统熟悉。能够在一定程度上进行问题排查。</li><li>对常用的中间件熟悉。能够进行常规中间件的性能评估与异常分析，例如 <code>kafka</code>、<code>mongodb</code>、<code>mysql</code>、<code>redis</code> 等。</li></ol><p>具体的技能，需要根据业务情况而定。但也有一些通用的技能：</p><ol><li>工作规划能力。由于压测的工作往往十分庞杂，因此要能规划好工作内容，各个阶段的安排要合理。</li><li>文档书写能力。压测的过程十分庞杂，因此每个阶段的工作都应该有比较好的记录和分析，用于指导下一环节的工作。常写的文档包括： 1.  压测规划书  2. 压测结果记录   3. 压测分析报告  4. 系统结构分析图。</li><li>沟通能力。由于压测涉及到的范围很广，尤其是一个比较大的链路压测时，压测人员基本无法对整个系统有较强的掌控能力，需要 1. 市场/运营人员  2. 模块开发负责人员  3. 运维人员  的参与，因此协调这些人员的工作就会十分重要。</li></ol><h3 id="压测的形态是怎样的？"><a href="#压测的形态是怎样的？" class="headerlink" title="压测的形态是怎样的？"></a>压测的形态是怎样的？</h3><ol><li>压测可以分为基准测试和链路测试。基准测试是对单个模块的压测。链路压测是对一条业务流程的压测。</li><li>对于一个常规的压测流程，应当先对模块进行基准测试，在得到每个模块的性能指标后，再进行链路压测。</li></ol><h3 id="压测的结论有哪些？"><a href="#压测的结论有哪些？" class="headerlink" title="压测的结论有哪些？"></a>压测的结论有哪些？</h3><ol><li>回答压测的模型是怎样的，说明为什么选择这样的压测模型</li><li>回答在目标QPS下，当前的系统瓶颈是什么</li><li>给出压测过程中发现的不合理之处</li></ol><h3 id="压测的流程是怎样的？"><a href="#压测的流程是怎样的？" class="headerlink" title="压测的流程是怎样的？"></a>压测的流程是怎样的？</h3><ol><li>分析业务形态，系统形态</li><li>根据业务需求，确定合适的压测模型</li><li>准备压测环境</li><li>准备压测数据、压测工具</li><li>确定系统可观测性，确定测试终止条件</li><li>压测执行，处理过程中的问题</li><li>根据压测过程，形成压测报告</li><li>根据压测报告进行分析，形成分析报告</li></ol><h3 id="压测的工程化实践"><a href="#压测的工程化实践" class="headerlink" title="压测的工程化实践"></a>压测的工程化实践</h3><p>业务系统的压测(从链路来看)，往往可以分为这两类：</p><ol><li>http 请求</li><li>其他类 TCP 请求</li></ol><p>由于业务系统主要面向用户，因此对于 http 请求的压测是最多的，这也是市场上生态最好的类型。常规的例如 <code>jmeter</code>、<code>locust</code>、<code>k6</code>、<code>PTS</code>、<code>loadrunner</code> ，这是用于系统性压测的工具。另外，在开发人员保障的性能测试中，<code>ab</code> 、<code>wrk</code> 、<code>go-stress-testing</code>  这几个工具被经常使用，用于快速验证。<br>其他类的请求相对较少，例如 <code>rpc</code>、<code>websocket</code> 这类。即使有一些实现，但真正结合到业务中时，会发现各种不满足需求。实际上，这类测试最好还是自己根据业务情况写项目实现。<br>压测项目是一个比较具有通用性的项目，因此可以考虑将其平台化，但目前来看，在最通用的 http 压测上，是比较容易平台化的，市场上也有很多，例如上面提到的 <code>jmeter</code>、<code>loadrunner</code> 等。不过，市面上的这类工具基本都是用来进行 压力管理 的，而测试计划、测试脚本、测试报告 等方面的管理是比较弱的，因此，也有企业在开始做云端化的压测管理平台，比如 <code>metersphere</code>，现在做得也基本可用了。</p><p>对于接口类的测试，通用性是非常强的，例如和 接口管理 结合，可以实现类似于：<code>自动化生成测试用例</code>、<code>流量录制</code>、<code>测试跟踪(bug管理等)</code>、<code>基于接口测试的性能测试</code>等等。实际上，这些功能 <code>metersphere</code> 也支持了，不过有部分是企业版的(如项目管理平台集成)。<br>对于接口类测试，我们当前使用的是自己开发的一个项目 <code>super-apitest</code> ，这个项目的最大亮点在于 基于json的模板化用例 ，这点可以认为和 jmeter 的 jmx 格式类比，不过基于 json 的格式，对开发者更加友好。<br>现在这个项目仅有一些简单的功能，例如适配了简单的触发界面、结果报告、结果通知，但想要真正做到平台化，还有非常长的路要走。<br>当前来看，这个项目可以在一定程度上进行平台化，主要的功能点有 3 个：</p><ol><li>支持所有用例使用数据库管理 =&gt; 一切演进的前提</li><li>支持测试用例录制 =&gt; 极大简化用例生成方式</li><li>支持测试用例通过率统计 =&gt; 极大增强测试跟踪</li></ol><p>如果做到这 3 点，这个接口测试平台已经基本可用了。</p><p>对于其他类型的功能测试，主要包括</p><ol><li>工具库的单测和覆盖度测试</li><li>模块的功能测试</li><li>非 http 类的接口测试 (例如 rpc、ws、异步消息)</li></ol><p>这些测试基本不具备很好的通用性，平台化的效率比较低，对于这类测试，平台的作用其实主要有:</p><ol><li>测试触发</li><li>测试用例元信息管理</li><li>测试结果展示</li></ol><p>基于此，可以认为，平台仅需要提供特定的接口，由各测试项目自行实现测试触发、测试结果反馈即可。</p><p>对于性能测试，如果全为 http 类接口，则平台化的效率较高，可以直接和 接口测试 模块相结合，由接口测试提供用例，由性能测试模块提供压测控制。<br>同样，对于非 http 类接口而言，性能测试的通用性就比较弱了，比如各个项目的性能。那么平台依然可以提供测试管理接口，由平台来做触发和结果采集，实际的测试执行由各业务项目自行处理。</p><h3 id="功能测试和性能测试的关系"><a href="#功能测试和性能测试的关系" class="headerlink" title="功能测试和性能测试的关系"></a>功能测试和性能测试的关系</h3><p>功能测试的目的在于保证功能的正确性，有时会有比较复杂的校验逻辑，测试用例集的组织形式经常为一个功能。<br>性能测试的目的在于摸清一些功能或场景的最大(合适)并发度，用于排查性能瓶颈和做线上资源容量规划，校验逻辑往往比较轻量，着重在压力 ，测试用例集的组织形式尝尝是一系列场景，并且十分关注各场景的比例，目的模拟真实用户的请求。</p><h3 id="压测项目的价值有多大"><a href="#压测项目的价值有多大" class="headerlink" title="压测项目的价值有多大"></a>压测项目的价值有多大</h3><p>根据压测的两大目标来看： 1. 发现系统瓶颈，提供优化建议  2. 回答线上容量问题<br>对于第 1 点，这是项目开发时需要的，例如开发一个通用的库，需要根据压测的结果进行优化。实际上，这是任何一个开发工程师都需要具备的能力，尤其是写中间件的工程师。<br>这种情况下，压测基本上是驱动这个项目进化的源动力之一。也是业务方评判这个项目的优劣及适用性的一个很重要的标准，业界流行的 <code>redis</code>、<code>kafka</code>、<code>mongo</code>、<code>mysql</code>等这类中间件，都是直接在发行版中自带 benchmark 工具。<br>对打第 2 个问题，大多数时候需要链路压测。最常见的系统压测是基于 http 这类 “request/response” 的，而这也是测试工程师最常接触的。目标在于找到整个链路的性能峰值。<br>毫无疑问，在项目开发过程中，我们需要回答第 1 个问题，而往往这个问题需要研发工程师自己回答。但从实际的情况来看，对于大多数业务场景，这类问题是比较基础的问题，如果项目中有比较高级一些的研发工程师在技术评审时下点功夫，基本就能将这些问题扼杀在摇篮里。<br>也就意味着，业务系统做这类压测，原因往往有两个： 1. 技术管理体系不成熟，代码质量得不到保障。 2. 跟其他业务有所关联，需要自证。<br>如果要回答第 2 个问题，就需要链路压测，这也是最被大家所熟悉的压测，这类压测往往需要一个团队来执行，主要包含： 1. <code>测试工程师</code>  2. <code>运维工程师</code>  3. <code>研发工程师</code>  4. <code>业务人员(运营/产品)</code>。 在新项目上线、大促活动等情况下，一般需要做这类测试，用于保障线上不会被打垮。</p><h3 id="业界做的比较好的容量是怎样的"><a href="#业界做的比较好的容量是怎样的" class="headerlink" title="业界做的比较好的容量是怎样的"></a>业界做的比较好的容量是怎样的</h3><p>根据一些公开资料，有了解到使用机器学习的方式，得出各条件下对于机器资源的需求量。机器学习的来源，一方面是通过多次(很多)压测得到，另一方面，是通过线上实际数据反馈进行修正。<br>这样一套容量的机器学习方案确实是一个不错的选择，尤其是对于业务较多的企业，还是有不错的收益，例如阿里的本地生活就有这么一套。</p><h3 id="性能保障的职责"><a href="#性能保障的职责" class="headerlink" title="性能保障的职责"></a>性能保障的职责</h3><ol><li>由测试人员</li><li>由运维人员(sre)</li><li>由开发人员</li><li>由架构师</li></ol><p>对于常规的 http 请求的压测，可以由测试人员负责，凭借测试人员对业务场景的理解，可以构造出符合需求的测试脚本，再使用特定的压测工具，则可进行压测，压测的结果也比较清晰，可以直接交给相关项目的开发人员去进行接口优化。<br>针对特殊项目的压测，和普通意义上我们认为的测试工程师所做的工作不太一样，常规认为的测试工程师，大多凭借对业务场景的理解，加上对测试(功能/性能)工具的掌握，能做针对业务场景的测试/压测。这种项目的性能测试需要对这个项目本身比较熟悉，往往需要自行开发一些压测的工具来进行压测，从上述描述的测试工程师所擅长的技能来看，不能很好匹配。<br>对于链路压测，一般来说需要准备的内容比较复杂，包含 <code>压测目标确定</code>、<code>环境准备</code>、<code>压测场景构建</code>、<code>压测脚本</code>、<code>压测过程控制</code>、<code>项目配置/环境配置调整</code>、<code>压测资源监控</code>、<code>压测报告</code>、<code>压测结果分析</code> 等一系列环节。<br>这些环节过于复杂，对于任意一个工程师而言，都是几乎无法完成的。因此，往往需要一个团队来配合。团队内的分工大致如下：</p><ol><li>业务人员(产品/运营)，负责压测目标的确定(业务侧视角)。</li><li>测试人员，负责压测场景梳理、压测数据准备(协同研发人员)、压测执行、压测结果收集、压测报告</li><li>研发人员，负责standby问题排查、环境配置调整</li><li>运维人员，负责环境准备、协助排查资源问题</li><li>架构师/高级开发人员，负责压测结果报告分析、优化方案</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>load test</tag>
      
      <tag>压测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>梳理一下要做的重要的事</title>
    <link href="/longblog/posts/21_09_30_to_think_what_is_the_important_things.html"/>
    <url>/longblog/posts/21_09_30_to_think_what_is_the_important_things.html</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>时光飞逝，转眼就来到了季度的末尾，工作上，一般会在季末时进行季度总结，我觉得还挺有价值，自己也同样需要做这类季度总结，当然，更重要的，是梳理清楚自己下个季度有哪些重要的事要做。</p><h2 id="上个季度"><a href="#上个季度" class="headerlink" title="上个季度"></a>上个季度</h2><p>工作上，主要做私有化部署的整套内容，包含依赖摘除、工具链调研、环境搭建等诸多事，整体打分 60 分。</p><p><strong>【私有化】完成的事：</strong></p><ol><li>调研了多种私有化部署方案，例如 <code>k8s</code>、<code>micro kube</code>、<code>k3s</code> 等，最后基于多方面考虑，选择了 <code>k3s</code></li><li>调研了数个文件存储方案，例如 <code>glusterFS</code>、<code>minio</code>，最后选择了 <code>minio</code></li><li>为私有化部署开发了 <code>license server</code> 项目</li><li>部署脚本采用 <code>ansible</code> 管理方案</li></ol><p><strong>【私有化】未完成的事：</strong></p><ol><li>私有化的扩缩容方案</li><li>私有化的数据冷热备方案</li><li>私有化的升级迁移方案</li><li>私有化的权限控制方案</li><li>私有化后台[业务需求不明]</li></ol><p><strong>【质量与性能】完成的事：</strong></p><ol><li>调研多个性能压测工具，例如 <code>ab</code>、 <code>locust</code>、 <code>jmeter</code>、 <code>PTS</code> 、 <code>wrk</code>、<code>go-stress-testing</code>、<code>meter-sphere</code>、<code>k6</code> 等，由于主要是为 websocket 测试，未找到合适轮子，于是自己写，基于 <code>gorilla/websocket</code> 写的强业务耦合测试代码。</li><li>接口测试方面，接口测试框架经调研未发现好用的工具，主要调研了 <code>yapi</code>、 <code>postman</code>、 <code>swagger</code>、 <code>metersphere</code> ，于是依然使用自己造的接口测试轮子，改了部分 bug。</li><li>websocket 压测，阶段性瓶颈在于 <code>mongodb</code>，经部分调整，提升最大并发量 10 倍，瓶颈依然在 <code>mongodb</code>，下一阶段计划重新进行数据库选型。</li><li>代码质量方面，部分项目集成 <code>golangci-lint</code>，同时调研了多个代码质量保证方面的工具链，例如 <code>Covergates</code>、 <code>goc</code>、<code>gitlab pages</code> 等。</li></ol><p><strong>【质量与性能】未完成的事：</strong></p><ol><li>未能对压测进行系统性总结</li><li>未能对调研的各类工具做实操性文档</li><li>对于 <code>mongodb</code> 的性能瓶颈未能做更高层次的思考与总结</li><li>测试框架未能支持 rpc 测试</li><li>测试框架未能支持 延迟 操作</li><li>测试框架未能支持 form-data 支持</li><li>测试框架未能支持 数据库 存储</li><li>测试框架未能支持 录制 接口与自动化测试用例生成</li><li>代码质量保证还未推广到所有 golang 项目</li></ol><p><strong>【其他】完成的事：</strong></p><ol><li>完成了截图服务器开发和部署，为视觉感知测试铺了路</li><li>开始学习 计算机基础 类知识<ul><li>操作系统</li><li>计算机网络</li><li>序列化方案</li></ul></li><li>开始重新写博客</li></ol><p><strong>【其他】未完成的事：</strong></p><ol><li>视觉感知测试还没有做过比较细致的分析</li><li>计算机基础类知识没有记成笔记</li><li>博客内容规划还不够细致</li></ol><h2 id="这个季度"><a href="#这个季度" class="headerlink" title="这个季度"></a>这个季度</h2><p><strong>【质量与性能】要做的事：</strong></p><ol><li>充分调研 <code>nosql</code> 数据库, 结合业务需求，全面梳理适用场景<ul><li>mongodb</li><li>redis</li><li>groupcache</li><li>levelDB</li><li>cassandra</li><li>……</li></ul></li><li>形成基本完备的压测工具链体系<ul><li>解决 rpc 压测支持</li><li>解决 ws 压测自动化</li><li>解决 api 压测自动化</li><li>完成 接口测试 协议设计，最好能支持部分协议转换</li></ul></li><li>代码质量保证<ul><li>所有项目添加 代码静态检查 golangci-lint</li><li>工具库项目全部添加 测试覆盖度报告</li><li>所有有自动化测试的项目添加覆盖度 ci</li></ul></li><li>初步形成对第三方中间件的benchmark工具链<ul><li>redis</li><li>mongodb</li><li>mysql</li><li>kafka</li></ul></li></ol><p><strong>【私有化】要做的事：</strong></p><ol><li>私有化的扩缩容方案</li><li>私有化的数据冷热备方案</li><li>私有化的升级迁移方案</li><li>私有化的权限控制方案</li><li>私有化后台[业务需求不明]</li></ol><p><strong>【其他】要做的事：</strong></p><ol><li>把学习的内容进行梳理整合，并形成博客 * 30</li><li>刷 leetcode 题目 * 60</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>要做的事情非常多，因此每天的时间要做好规划，不能 <code>什么堆到眼前再做什么</code>，每天要做好当天的事情总结。<br>加油。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>收拾一下，重新出发</title>
    <link href="/longblog/posts/21_09_20_new_start.html"/>
    <url>/longblog/posts/21_09_20_new_start.html</url>
    
    <content type="html"><![CDATA[<h3 id="预"><a href="#预" class="headerlink" title="预"></a>预</h3><p>前两天，收到腾讯网站备案人员的电话，说我的网站底部没有添加备案号，让补一下，我这才想起自己的博客已经很多年没更新了=.=!。</p><p>早上很早就醒了，也不想看手边的那些大部头技术书，于是就打开了我的博客，浏览了一遍自己曾经写下的文字。没想到，看到有些文章时竟忍不住产生一丝丝感动，回想起了自己一路走来的历程：</p><h3 id="前缘"><a href="#前缘" class="headerlink" title="前缘"></a>前缘</h3><ul><li>毕业前的实习是做的审计，半年左右的审计经历让我意识到，我在财会这条路上，走不远</li><li>于是开始问自己，我喜欢什么？</li><li>摇摆很久，最终选定试一下 编程</li><li>毫无任何头绪地学习技术，从 C、单片机、arduino 开始玩，也不知道能做啥</li><li>接触了树莓派，艰难地在 linux 环境上挣扎</li><li>前端的所见即所得让我看到一丝光亮，开始学习 html、css、js、jq、vue</li><li>不知道自己学得咋样了，模仿写了 网易云课堂 和 B站</li><li>听了老爸的话: “不知道行不行没关系，去试试看，不试试永远不知道行不行”，鼓了鼓劲去面试</li></ul><h3 id="中上篇"><a href="#中上篇" class="headerlink" title="中上篇"></a>中上篇</h3><ul><li>去了 极客邦 做前端开发工程师。距毕业过去了 4 个月</li><li>学习前端的知识，主要是 vue 生态中的种种</li><li>js 熟练了些，就学 nodejs，mysql</li><li>工作之余写点前后端的项目玩一下，例如时间胶囊(一个web记事本)</li><li>觉得在审美上没啥天赋，考虑看看后端</li><li>迷茫，简单学了 python、java、lua，套开源框架写 demo，主要是 web 开发</li></ul><h3 id="中下篇"><a href="#中下篇" class="headerlink" title="中下篇"></a>中下篇</h3><ul><li>朋友做自媒体收益不错，想去挣点钱，就提了离职。此时，差一天就满半年了</li><li>自媒体一直没上路，没啥思路，在家挣扎了几个月，觉得自己可能积淀不够，还是需要先去历练</li><li>又重新评估了 java 和 python，最后选了 go，陆陆续续学了 2 个月</li><li>之前用 nodejs 和 python 写过小项目，但对真实的企业开发完全没概念，没信心</li><li>内心十分不安，在爱人的鼓励下，终于还是投出去了一些简历</li><li>去了蓝湖，做后端开发。此时，据离开上家公司已经 6 个月</li></ul><h3 id="梦初醒"><a href="#梦初醒" class="headerlink" title="梦初醒"></a>梦初醒</h3><ul><li>这么久以来，我的学习环境都是自己搭的，逐渐也有了些熟练度，渐渐对 linux 系统比较感兴趣</li><li>学习运维的东西，主要是 docker、k8s、ansible、shell 这些</li><li>对服务器有种奇妙的感觉，于是买了一台24核的Dell服务器，用于平常测试</li><li>团队中有些跟运维接触比较多的事，都是我在做，比如 私有化部署、性能测试、集成测试 等等</li><li>做开发以来，一直后悔自己大学几年没有学相关知识，跟科班的同学相比，我起步几乎晚了半个世纪</li><li>也认识到自己在计算机基础上需要补补，于是开始看一些书，主要是 网络、操作系统、计算机组成、编译原理 这些</li><li>不仅在基础上不足，在经验上也十分欠缺，于是开始看一些有点深度的知识，主要是一些厉害的开源项目的源码 这些</li></ul><h3 id="脚下的路"><a href="#脚下的路" class="headerlink" title="脚下的路"></a>脚下的路</h3><p>到现在，距离来蓝湖已经 10 个月了，时光飞逝，令人不住感慨，现在是中秋的前一天，印象中正是秋高气爽之时，然而北京这两日阴雨连绵，天色昏沉，不经意间，也生出了些惆怅的情绪……</p><p>以前博客写的很少，学东西都是靠在脑海里留下一些印象，时间稍微一长就容易忘记，这样不好。作为程序员，写博客其实应该是基本功，和 算法、数学、计算机原理、设计模式 这些是一个层次的，属于那种具有长远价值的东西，我也应当多下功夫。</p><p>我重开这个博客，目的就是把我在技术学习时的一些收获进行总结梳理，用技术文章的方式，把对应的知识加工输出，一来，可以加深自己对一些问题的认识，二来，如果这些文章也能有那么一丝的作用，让来我的小站逛逛的同学们感到有所收获，那也算是推进了社会进步，哈哈哈哈。</p><p>将来的一段时间，我会把精力主要放在 第 26 和 第 27 这两条内容上，因此博客会记录一些： 计算机网络、操作系统、编译原理、数据库原理、分布式架构、服务治理 等这些方面的内容，也会看情况分享一些读书笔记、源码阅读感受等内容。</p><p>最后，希望未来越来越好，我们。</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
